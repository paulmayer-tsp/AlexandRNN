{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "AlexandRNN_pytorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5LqrlD34g3m"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ACLXSw4g3s"
      },
      "source": [
        "### Tools for data processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D83zYN44g3s"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "from collections import Counter\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urQQ5WEI4g3s"
      },
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "        self.counter = {}\n",
        "        self.total = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "            self.counter.setdefault(word, 0)\n",
        "        self.counter[word] += 1\n",
        "        self.total += 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG6rsEQB4g3t"
      },
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        # We create an object Dictionary associated to Corpus\n",
        "        self.dictionary = Dictionary()\n",
        "        # We go through all files, adding all words to the dictionary\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "        \n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file, knowing the dictionary, in order to tranform it into a list of indexes\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r') as f:\n",
        "            tokens = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "                tokens += len(words)\n",
        "        \n",
        "        # Once done, go through the file a second time and fill a Torch Tensor with the associated indexes \n",
        "        with open(path, 'r') as f:\n",
        "            ids = torch.LongTensor(tokens)\n",
        "            token = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    ids[token] = self.dictionary.word2idx[word]\n",
        "                    token += 1\n",
        "        return ids"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytRgixof4g3t"
      },
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "data = './corpus/'\n",
        "corpus = Corpus(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHf1bA7C4g3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd1632f-2993-42b7-be2c-f7c377a85649"
      },
      "source": [
        "print(corpus.dictionary.total)\n",
        "print(len(corpus.dictionary.idx2word))\n",
        "print(len(corpus.dictionary.word2idx))\n",
        "\n",
        "print(corpus.train.shape)\n",
        "print(corpus.train[0:7])\n",
        "print([corpus.dictionary.idx2word[corpus.train[i]] for i in range(7)])\n",
        "\n",
        "print(corpus.valid.shape)\n",
        "print(corpus.valid[0:7])\n",
        "print([corpus.dictionary.idx2word[corpus.valid[i]] for i in range(7)])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1076937\n",
            "23244\n",
            "23244\n",
            "torch.Size([773840])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6])\n",
            "['Oui', ',', 'je', 'viens', 'dans', 'son', 'Temple']\n",
            "torch.Size([135984])\n",
            "tensor([  33,    2, 1176,  104,   21, 1218,   41])\n",
            "['Que', 'je', 'sens', 'à', 'la', 'fois', 'de']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIWjBwFj4g3t"
      },
      "source": [
        "# We now have data under a very long list of indexes: the text is as one sequence.\n",
        "# The idea now is to create batches from this. Note that this is absolutely not the best\n",
        "# way to proceed with large quantities of data (where we'll try not to store huge tensors\n",
        "# in memory but read them from file as we go) !\n",
        "# Here, we are looking for simplicity and efficiency with regards to computation time.\n",
        "# That is why we will ignore sentence separations and treat the data as one long stream that\n",
        "# we will cut arbitrarily as we need.\n",
        "# With the alphabet being our data, we currently have the sequence:\n",
        "# [a b c d e f g h i j k l m n o p q r s t u v w x y z]\n",
        "# We want to reorganize it as independant batches that will be processed independantly by the model !\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get the 4 following sequences:\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘\n",
        "# with the last two elements being lost.\n",
        "# Again, these columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient processing.\n",
        "\n",
        "def batchify(data, batch_size, cuda = False):\n",
        "    # Cut the elements that are unnecessary\n",
        "    nbatch = data.size(0) // batch_size\n",
        "    data = data.narrow(0, 0, nbatch * batch_size)\n",
        "    # Reorganize the data\n",
        "    data = data.view(batch_size, -1).t().contiguous()\n",
        "    # If we can use a GPU, let's tranfer the tensor to it\n",
        "    return data.to(device)\n",
        "\n",
        "# get_batch subdivides the source data into chunks of the appropriate length.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a sequence length (seq_len) of 3, we'd get the following two variables:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# | b h n t | | c i o u │\n",
        "# └ c i o u ┘ └ d j p v ┘\n",
        "# The first variable contains the letters input to the network, while the second\n",
        "# contains the one we want the network to predict (b for a, h for g, v for u, etc..)\n",
        "# Note that despite the name of the function, we are cutting the data in the\n",
        "# temporal dimension, since we already divided data into batches in the previous\n",
        "# function. \n",
        "\n",
        "def get_batch(source, i, seq_len, evaluation=False):\n",
        "    # Deal with the possibility that there's not enough data left for a full sequence\n",
        "    seq_len = min(seq_len, len(source) - 1 - i)\n",
        "    # Take the input data\n",
        "    data = source[i:i+seq_len]\n",
        "    # Shift by one for the target data\n",
        "    target = source[i+1:i+1+seq_len]\n",
        "    return data, target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMeQ0gjzUOLd"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwfqKiMJ4g3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508b06da-4dcf-4d56-a958-694bd1272e8c"
      },
      "source": [
        "batch_size = 100\n",
        "eval_batch_size = 4\n",
        "train_data = batchify(corpus.train, batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(val_data.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7738, 100])\n",
            "torch.Size([33996, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9OVIoVJ4g3u"
      },
      "source": [
        "### LSTM Cells in pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztKrssh84g3u"
      },
      "source": [
        "### Creating our own LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD0K9CQ14g3u"
      },
      "source": [
        "# Models are usually implemented as custom nn.Module subclass\n",
        "# We need to redefine the __init__ method, which creates the object\n",
        "# We also need to redefine the forward method, which transform the input into outputs\n",
        "# We can also add any method that we need: here, in order to initiate weights in the model\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        # Create a dropout object to use on layers for regularization\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        # Create an encoder - which is an embedding layer\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        # Create the LSTM layers - find out how to stack them !\n",
        "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)\n",
        "        # Create what we call the decoder: a linear transformation to map the hidden state into scores for all words in the vocabulary\n",
        "        # (Note that the softmax application function will be applied out of the model)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "        \n",
        "        # Initialize non-reccurent weights \n",
        "        self.init_weights()\n",
        "\n",
        "        self.ninp = ninp\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "        \n",
        "    def init_weights(self):\n",
        "        # Initialize the encoder and decoder weights with the uniform distribution\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.fill_(0)\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        # Initialize the hidden state and cell state to zero, with the right sizes\n",
        "        weight = next(self.parameters())\n",
        "        return (weight.new_zeros(self.nlayers, batch_size, self.nhid),\n",
        "                weight.new_zeros(self.nlayers, batch_size, self.nhid))    \n",
        "\n",
        "    def forward(self, input, hidden, return_h=False):\n",
        "        # Process the input\n",
        "        emb = self.drop(self.encoder(input))   \n",
        "        \n",
        "        # Apply the LSTMs\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        \n",
        "        # Decode into scores\n",
        "        output = self.drop(output)      \n",
        "        decoded = self.decoder(output)\n",
        "        return decoded, hidden"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucXMYksR4g3u"
      },
      "source": [
        "### Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL-vvLGm4g3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2cbc34-7de2-45c5-f61d-20795232b798"
      },
      "source": [
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f05f4e37180>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S147j0Dx4g3u"
      },
      "source": [
        "embedding_size = 200\n",
        "hidden_size = 200\n",
        "layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "vocab_size = len(corpus.dictionary)\n",
        "model = LSTMModel(vocab_size, embedding_size, hidden_size, layers, dropout).to(device)\n",
        "params = list(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2X8VHG4g3v"
      },
      "source": [
        "lr = 10.0\n",
        "optimizer = 'sgd'\n",
        "wdecay = 1.2e-6\n",
        "# For gradient clipping\n",
        "clip = 0.25\n",
        "\n",
        "if optimizer == 'sgd':\n",
        "    optim = torch.optim.SGD(params, lr=lr, weight_decay=wdecay)\n",
        "if optimizer == 'adam':\n",
        "    optim = torch.optim.Adam(params, lr=lr, weight_decay=wdecay)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fGlrwME4g3v"
      },
      "source": [
        "# Let's think about gradient propagation:\n",
        "# We plan to keep the second ouput of the LSTM layer (the hidden/cell states) to initialize\n",
        "# the next call to LSTM. In this way, we can back-propagate the gradient for as long as we want.\n",
        "# However, this put a huge strain on the memory used by the model, since it implies retaining\n",
        "# a always-growing number of tensors of gradients in the cache.\n",
        "# We decide to not backpropagate through time beyond the current sequence ! \n",
        "# We use a specific function to cut the 'hidden/state cell' states from their previous dependencies\n",
        "# before using them to initialize the next call to the LSTM.\n",
        "# This is done with the .detach() function.\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4CGuudp4g3v"
      },
      "source": [
        "# Other global parameters\n",
        "epochs = 100\n",
        "seq_len = 30\n",
        "log_interval = 10\n",
        "save = 'model.pt'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx6UKwTO4g3v"
      },
      "source": [
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, seq_len):\n",
        "            data, targets = get_batch(data_source, i, seq_len)\n",
        "            output, hidden = model(data, hidden)\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output.view(-1, vocab_size), targets.view(-1)).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EhuQglX4g3v"
      },
      "source": [
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, seq_len)):\n",
        "        data, targets = get_batch(train_data, i, seq_len)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        optim.zero_grad()\n",
        "        \n",
        "        output, hidden = model(data, hidden)\n",
        "        loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(params, clip)\n",
        "        optim.step()\n",
        "        \n",
        "        total_loss += loss.data\n",
        "\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, batch, len(train_data) // seq_len, lr,\n",
        "                elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN0gBRgf4g3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef7118a-fb09-4305-f1d6-ba496b5e8d73"
      },
      "source": [
        "# Loop over epochs.\n",
        "best_val_loss = None\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train()\n",
        "        val_loss = evaluate(val_data)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 4.0\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "    # after load the rnn params are not a continuous chunk of memory\n",
        "    # this makes them a continuous chunk, and will speed up forward pass\n",
        "    model.rnn.flatten_parameters()\n",
        "\n",
        "# Run on test data.\n",
        "test_loss = evaluate(test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |    10/  257 batches | lr 10.00 | ms/batch 69.94 | loss 10.01 | ppl 22163.15\n",
            "| epoch   1 |    20/  257 batches | lr 10.00 | ms/batch 47.47 | loss  7.99 | ppl  2936.72\n",
            "| epoch   1 |    30/  257 batches | lr 10.00 | ms/batch 47.66 | loss  7.54 | ppl  1874.41\n",
            "| epoch   1 |    40/  257 batches | lr 10.00 | ms/batch 47.60 | loss  7.33 | ppl  1526.34\n",
            "| epoch   1 |    50/  257 batches | lr 10.00 | ms/batch 47.49 | loss  7.26 | ppl  1428.74\n",
            "| epoch   1 |    60/  257 batches | lr 10.00 | ms/batch 47.31 | loss  7.12 | ppl  1235.36\n",
            "| epoch   1 |    70/  257 batches | lr 10.00 | ms/batch 47.75 | loss  7.12 | ppl  1240.68\n",
            "| epoch   1 |    80/  257 batches | lr 10.00 | ms/batch 47.42 | loss  7.09 | ppl  1199.11\n",
            "| epoch   1 |    90/  257 batches | lr 10.00 | ms/batch 47.55 | loss  7.06 | ppl  1159.92\n",
            "| epoch   1 |   100/  257 batches | lr 10.00 | ms/batch 47.56 | loss  6.94 | ppl  1029.84\n",
            "| epoch   1 |   110/  257 batches | lr 10.00 | ms/batch 47.42 | loss  6.87 | ppl   959.19\n",
            "| epoch   1 |   120/  257 batches | lr 10.00 | ms/batch 47.88 | loss  6.95 | ppl  1044.24\n",
            "| epoch   1 |   130/  257 batches | lr 10.00 | ms/batch 47.58 | loss  6.83 | ppl   924.29\n",
            "| epoch   1 |   140/  257 batches | lr 10.00 | ms/batch 47.72 | loss  6.80 | ppl   896.76\n",
            "| epoch   1 |   150/  257 batches | lr 10.00 | ms/batch 47.53 | loss  6.77 | ppl   872.31\n",
            "| epoch   1 |   160/  257 batches | lr 10.00 | ms/batch 47.60 | loss  6.72 | ppl   832.16\n",
            "| epoch   1 |   170/  257 batches | lr 10.00 | ms/batch 47.66 | loss  6.73 | ppl   838.69\n",
            "| epoch   1 |   180/  257 batches | lr 10.00 | ms/batch 47.50 | loss  6.72 | ppl   829.39\n",
            "| epoch   1 |   190/  257 batches | lr 10.00 | ms/batch 47.63 | loss  6.72 | ppl   828.12\n",
            "| epoch   1 |   200/  257 batches | lr 10.00 | ms/batch 47.48 | loss  6.65 | ppl   770.88\n",
            "| epoch   1 |   210/  257 batches | lr 10.00 | ms/batch 47.65 | loss  6.66 | ppl   777.78\n",
            "| epoch   1 |   220/  257 batches | lr 10.00 | ms/batch 47.87 | loss  6.64 | ppl   762.54\n",
            "| epoch   1 |   230/  257 batches | lr 10.00 | ms/batch 47.70 | loss  6.62 | ppl   746.53\n",
            "| epoch   1 |   240/  257 batches | lr 10.00 | ms/batch 47.64 | loss  6.60 | ppl   732.06\n",
            "| epoch   1 |   250/  257 batches | lr 10.00 | ms/batch 47.53 | loss  6.61 | ppl   743.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 14.60s | valid loss  6.71 | valid ppl   820.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |    10/  257 batches | lr 10.00 | ms/batch 51.55 | loss  7.20 | ppl  1340.71\n",
            "| epoch   2 |    20/  257 batches | lr 10.00 | ms/batch 48.05 | loss  6.43 | ppl   619.49\n",
            "| epoch   2 |    30/  257 batches | lr 10.00 | ms/batch 47.57 | loss  6.27 | ppl   528.45\n",
            "| epoch   2 |    40/  257 batches | lr 10.00 | ms/batch 47.89 | loss  6.22 | ppl   504.54\n",
            "| epoch   2 |    50/  257 batches | lr 10.00 | ms/batch 48.55 | loss  6.14 | ppl   466.01\n",
            "| epoch   2 |    60/  257 batches | lr 10.00 | ms/batch 47.89 | loss  6.10 | ppl   443.89\n",
            "| epoch   2 |    70/  257 batches | lr 10.00 | ms/batch 47.56 | loss  6.06 | ppl   426.55\n",
            "| epoch   2 |    80/  257 batches | lr 10.00 | ms/batch 48.02 | loss  5.97 | ppl   389.88\n",
            "| epoch   2 |    90/  257 batches | lr 10.00 | ms/batch 47.90 | loss  6.00 | ppl   401.43\n",
            "| epoch   2 |   100/  257 batches | lr 10.00 | ms/batch 47.65 | loss  5.98 | ppl   397.15\n",
            "| epoch   2 |   110/  257 batches | lr 10.00 | ms/batch 48.11 | loss  5.86 | ppl   350.68\n",
            "| epoch   2 |   120/  257 batches | lr 10.00 | ms/batch 48.02 | loss  5.90 | ppl   364.12\n",
            "| epoch   2 |   130/  257 batches | lr 10.00 | ms/batch 47.85 | loss  5.90 | ppl   365.39\n",
            "| epoch   2 |   140/  257 batches | lr 10.00 | ms/batch 47.95 | loss  5.83 | ppl   341.38\n",
            "| epoch   2 |   150/  257 batches | lr 10.00 | ms/batch 48.11 | loss  5.83 | ppl   340.47\n",
            "| epoch   2 |   160/  257 batches | lr 10.00 | ms/batch 47.90 | loss  5.79 | ppl   328.10\n",
            "| epoch   2 |   170/  257 batches | lr 10.00 | ms/batch 47.91 | loss  5.76 | ppl   315.95\n",
            "| epoch   2 |   180/  257 batches | lr 10.00 | ms/batch 47.91 | loss  5.77 | ppl   319.74\n",
            "| epoch   2 |   190/  257 batches | lr 10.00 | ms/batch 48.28 | loss  5.74 | ppl   309.87\n",
            "| epoch   2 |   200/  257 batches | lr 10.00 | ms/batch 48.00 | loss  5.66 | ppl   286.81\n",
            "| epoch   2 |   210/  257 batches | lr 10.00 | ms/batch 48.00 | loss  5.63 | ppl   279.36\n",
            "| epoch   2 |   220/  257 batches | lr 10.00 | ms/batch 47.81 | loss  5.65 | ppl   284.87\n",
            "| epoch   2 |   230/  257 batches | lr 10.00 | ms/batch 48.07 | loss  5.63 | ppl   279.71\n",
            "| epoch   2 |   240/  257 batches | lr 10.00 | ms/batch 47.84 | loss  5.63 | ppl   277.88\n",
            "| epoch   2 |   250/  257 batches | lr 10.00 | ms/batch 48.16 | loss  5.60 | ppl   270.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 14.53s | valid loss  5.60 | valid ppl   269.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |    10/  257 batches | lr 10.00 | ms/batch 52.44 | loss  6.16 | ppl   472.82\n",
            "| epoch   3 |    20/  257 batches | lr 10.00 | ms/batch 48.83 | loss  5.51 | ppl   247.70\n",
            "| epoch   3 |    30/  257 batches | lr 10.00 | ms/batch 48.35 | loss  5.53 | ppl   251.94\n",
            "| epoch   3 |    40/  257 batches | lr 10.00 | ms/batch 48.28 | loss  5.43 | ppl   228.42\n",
            "| epoch   3 |    50/  257 batches | lr 10.00 | ms/batch 48.43 | loss  5.52 | ppl   249.69\n",
            "| epoch   3 |    60/  257 batches | lr 10.00 | ms/batch 48.43 | loss  5.41 | ppl   223.85\n",
            "| epoch   3 |    70/  257 batches | lr 10.00 | ms/batch 48.19 | loss  5.42 | ppl   226.90\n",
            "| epoch   3 |    80/  257 batches | lr 10.00 | ms/batch 48.65 | loss  5.39 | ppl   218.62\n",
            "| epoch   3 |    90/  257 batches | lr 10.00 | ms/batch 48.39 | loss  5.43 | ppl   227.49\n",
            "| epoch   3 |   100/  257 batches | lr 10.00 | ms/batch 48.27 | loss  5.39 | ppl   219.96\n",
            "| epoch   3 |   110/  257 batches | lr 10.00 | ms/batch 48.40 | loss  5.35 | ppl   211.47\n",
            "| epoch   3 |   120/  257 batches | lr 10.00 | ms/batch 48.02 | loss  5.33 | ppl   207.17\n",
            "| epoch   3 |   130/  257 batches | lr 10.00 | ms/batch 48.29 | loss  5.37 | ppl   215.56\n",
            "| epoch   3 |   140/  257 batches | lr 10.00 | ms/batch 48.43 | loss  5.31 | ppl   201.85\n",
            "| epoch   3 |   150/  257 batches | lr 10.00 | ms/batch 48.58 | loss  5.29 | ppl   198.51\n",
            "| epoch   3 |   160/  257 batches | lr 10.00 | ms/batch 48.48 | loss  5.31 | ppl   201.65\n",
            "| epoch   3 |   170/  257 batches | lr 10.00 | ms/batch 48.49 | loss  5.30 | ppl   200.19\n",
            "| epoch   3 |   180/  257 batches | lr 10.00 | ms/batch 48.87 | loss  5.30 | ppl   200.63\n",
            "| epoch   3 |   190/  257 batches | lr 10.00 | ms/batch 48.51 | loss  5.28 | ppl   196.67\n",
            "| epoch   3 |   200/  257 batches | lr 10.00 | ms/batch 48.41 | loss  5.24 | ppl   187.80\n",
            "| epoch   3 |   210/  257 batches | lr 10.00 | ms/batch 48.45 | loss  5.19 | ppl   179.31\n",
            "| epoch   3 |   220/  257 batches | lr 10.00 | ms/batch 48.36 | loss  5.20 | ppl   181.59\n",
            "| epoch   3 |   230/  257 batches | lr 10.00 | ms/batch 48.61 | loss  5.21 | ppl   183.80\n",
            "| epoch   3 |   240/  257 batches | lr 10.00 | ms/batch 48.54 | loss  5.21 | ppl   183.25\n",
            "| epoch   3 |   250/  257 batches | lr 10.00 | ms/batch 48.82 | loss  5.21 | ppl   182.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 14.64s | valid loss  5.33 | valid ppl   205.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |    10/  257 batches | lr 10.00 | ms/batch 53.24 | loss  5.74 | ppl   310.54\n",
            "| epoch   4 |    20/  257 batches | lr 10.00 | ms/batch 49.33 | loss  5.18 | ppl   177.20\n",
            "| epoch   4 |    30/  257 batches | lr 10.00 | ms/batch 48.71 | loss  5.15 | ppl   172.60\n",
            "| epoch   4 |    40/  257 batches | lr 10.00 | ms/batch 49.03 | loss  5.15 | ppl   172.91\n",
            "| epoch   4 |    50/  257 batches | lr 10.00 | ms/batch 48.93 | loss  5.15 | ppl   171.85\n",
            "| epoch   4 |    60/  257 batches | lr 10.00 | ms/batch 48.96 | loss  5.11 | ppl   166.01\n",
            "| epoch   4 |    70/  257 batches | lr 10.00 | ms/batch 48.52 | loss  5.12 | ppl   167.65\n",
            "| epoch   4 |    80/  257 batches | lr 10.00 | ms/batch 49.10 | loss  5.08 | ppl   161.17\n",
            "| epoch   4 |    90/  257 batches | lr 10.00 | ms/batch 48.89 | loss  5.12 | ppl   167.12\n",
            "| epoch   4 |   100/  257 batches | lr 10.00 | ms/batch 48.96 | loss  5.12 | ppl   166.85\n",
            "| epoch   4 |   110/  257 batches | lr 10.00 | ms/batch 48.75 | loss  5.05 | ppl   155.98\n",
            "| epoch   4 |   120/  257 batches | lr 10.00 | ms/batch 48.99 | loss  5.07 | ppl   158.43\n",
            "| epoch   4 |   130/  257 batches | lr 10.00 | ms/batch 49.64 | loss  5.07 | ppl   158.88\n",
            "| epoch   4 |   140/  257 batches | lr 10.00 | ms/batch 49.10 | loss  4.99 | ppl   147.29\n",
            "| epoch   4 |   150/  257 batches | lr 10.00 | ms/batch 49.17 | loss  5.00 | ppl   148.92\n",
            "| epoch   4 |   160/  257 batches | lr 10.00 | ms/batch 48.90 | loss  5.02 | ppl   150.96\n",
            "| epoch   4 |   170/  257 batches | lr 10.00 | ms/batch 49.16 | loss  5.06 | ppl   158.21\n",
            "| epoch   4 |   180/  257 batches | lr 10.00 | ms/batch 48.91 | loss  5.02 | ppl   150.96\n",
            "| epoch   4 |   190/  257 batches | lr 10.00 | ms/batch 49.50 | loss  5.01 | ppl   150.04\n",
            "| epoch   4 |   200/  257 batches | lr 10.00 | ms/batch 49.15 | loss  4.96 | ppl   142.75\n",
            "| epoch   4 |   210/  257 batches | lr 10.00 | ms/batch 49.14 | loss  4.91 | ppl   136.27\n",
            "| epoch   4 |   220/  257 batches | lr 10.00 | ms/batch 49.12 | loss  4.97 | ppl   143.64\n",
            "| epoch   4 |   230/  257 batches | lr 10.00 | ms/batch 49.37 | loss  4.97 | ppl   143.43\n",
            "| epoch   4 |   240/  257 batches | lr 10.00 | ms/batch 49.25 | loss  4.92 | ppl   136.91\n",
            "| epoch   4 |   250/  257 batches | lr 10.00 | ms/batch 49.47 | loss  4.97 | ppl   143.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 14.81s | valid loss  5.06 | valid ppl   156.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |    10/  257 batches | lr 10.00 | ms/batch 53.77 | loss  5.46 | ppl   235.90\n",
            "| epoch   5 |    20/  257 batches | lr 10.00 | ms/batch 49.53 | loss  4.94 | ppl   140.05\n",
            "| epoch   5 |    30/  257 batches | lr 10.00 | ms/batch 49.66 | loss  4.92 | ppl   136.61\n",
            "| epoch   5 |    40/  257 batches | lr 10.00 | ms/batch 49.56 | loss  4.91 | ppl   136.30\n",
            "| epoch   5 |    50/  257 batches | lr 10.00 | ms/batch 49.52 | loss  4.94 | ppl   140.06\n",
            "| epoch   5 |    60/  257 batches | lr 10.00 | ms/batch 49.51 | loss  4.88 | ppl   131.36\n",
            "| epoch   5 |    70/  257 batches | lr 10.00 | ms/batch 49.90 | loss  4.85 | ppl   128.36\n",
            "| epoch   5 |    80/  257 batches | lr 10.00 | ms/batch 50.08 | loss  4.86 | ppl   129.26\n",
            "| epoch   5 |    90/  257 batches | lr 10.00 | ms/batch 49.76 | loss  4.90 | ppl   134.71\n",
            "| epoch   5 |   100/  257 batches | lr 10.00 | ms/batch 49.52 | loss  4.86 | ppl   129.63\n",
            "| epoch   5 |   110/  257 batches | lr 10.00 | ms/batch 49.56 | loss  4.85 | ppl   127.43\n",
            "| epoch   5 |   120/  257 batches | lr 10.00 | ms/batch 50.13 | loss  4.85 | ppl   128.04\n",
            "| epoch   5 |   130/  257 batches | lr 10.00 | ms/batch 49.91 | loss  4.87 | ppl   129.84\n",
            "| epoch   5 |   140/  257 batches | lr 10.00 | ms/batch 50.42 | loss  4.83 | ppl   125.57\n",
            "| epoch   5 |   150/  257 batches | lr 10.00 | ms/batch 50.05 | loss  4.83 | ppl   125.25\n",
            "| epoch   5 |   160/  257 batches | lr 10.00 | ms/batch 49.92 | loss  4.82 | ppl   123.86\n",
            "| epoch   5 |   170/  257 batches | lr 10.00 | ms/batch 49.86 | loss  4.84 | ppl   127.03\n",
            "| epoch   5 |   180/  257 batches | lr 10.00 | ms/batch 50.78 | loss  4.83 | ppl   124.68\n",
            "| epoch   5 |   190/  257 batches | lr 10.00 | ms/batch 50.34 | loss  4.82 | ppl   124.32\n",
            "| epoch   5 |   200/  257 batches | lr 10.00 | ms/batch 50.71 | loss  4.78 | ppl   118.61\n",
            "| epoch   5 |   210/  257 batches | lr 10.00 | ms/batch 49.60 | loss  4.74 | ppl   114.03\n",
            "| epoch   5 |   220/  257 batches | lr 10.00 | ms/batch 50.26 | loss  4.79 | ppl   120.56\n",
            "| epoch   5 |   230/  257 batches | lr 10.00 | ms/batch 50.19 | loss  4.78 | ppl   118.59\n",
            "| epoch   5 |   240/  257 batches | lr 10.00 | ms/batch 50.52 | loss  4.77 | ppl   118.48\n",
            "| epoch   5 |   250/  257 batches | lr 10.00 | ms/batch 50.63 | loss  4.80 | ppl   121.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 15.04s | valid loss  4.87 | valid ppl   129.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |    10/  257 batches | lr 10.00 | ms/batch 54.23 | loss  5.31 | ppl   202.42\n",
            "| epoch   6 |    20/  257 batches | lr 10.00 | ms/batch 50.73 | loss  4.76 | ppl   117.19\n",
            "| epoch   6 |    30/  257 batches | lr 10.00 | ms/batch 50.46 | loss  4.75 | ppl   115.61\n",
            "| epoch   6 |    40/  257 batches | lr 10.00 | ms/batch 50.69 | loss  4.75 | ppl   116.09\n",
            "| epoch   6 |    50/  257 batches | lr 10.00 | ms/batch 50.24 | loss  4.77 | ppl   118.27\n",
            "| epoch   6 |    60/  257 batches | lr 10.00 | ms/batch 51.08 | loss  4.76 | ppl   116.55\n",
            "| epoch   6 |    70/  257 batches | lr 10.00 | ms/batch 50.59 | loss  4.71 | ppl   111.60\n",
            "| epoch   6 |    80/  257 batches | lr 10.00 | ms/batch 50.61 | loss  4.70 | ppl   109.65\n",
            "| epoch   6 |    90/  257 batches | lr 10.00 | ms/batch 50.67 | loss  4.76 | ppl   117.09\n",
            "| epoch   6 |   100/  257 batches | lr 10.00 | ms/batch 50.48 | loss  4.74 | ppl   114.09\n",
            "| epoch   6 |   110/  257 batches | lr 10.00 | ms/batch 50.67 | loss  4.71 | ppl   110.56\n",
            "| epoch   6 |   120/  257 batches | lr 10.00 | ms/batch 50.76 | loss  4.73 | ppl   113.36\n",
            "| epoch   6 |   130/  257 batches | lr 10.00 | ms/batch 50.68 | loss  4.73 | ppl   113.59\n",
            "| epoch   6 |   140/  257 batches | lr 10.00 | ms/batch 50.75 | loss  4.67 | ppl   106.38\n",
            "| epoch   6 |   150/  257 batches | lr 10.00 | ms/batch 50.94 | loss  4.67 | ppl   106.48\n",
            "| epoch   6 |   160/  257 batches | lr 10.00 | ms/batch 50.37 | loss  4.70 | ppl   109.78\n",
            "| epoch   6 |   170/  257 batches | lr 10.00 | ms/batch 50.81 | loss  4.72 | ppl   112.42\n",
            "| epoch   6 |   180/  257 batches | lr 10.00 | ms/batch 50.47 | loss  4.69 | ppl   108.92\n",
            "| epoch   6 |   190/  257 batches | lr 10.00 | ms/batch 50.58 | loss  4.68 | ppl   107.90\n",
            "| epoch   6 |   200/  257 batches | lr 10.00 | ms/batch 50.46 | loss  4.64 | ppl   103.69\n",
            "| epoch   6 |   210/  257 batches | lr 10.00 | ms/batch 50.73 | loss  4.60 | ppl    99.85\n",
            "| epoch   6 |   220/  257 batches | lr 10.00 | ms/batch 50.35 | loss  4.67 | ppl   107.03\n",
            "| epoch   6 |   230/  257 batches | lr 10.00 | ms/batch 50.77 | loss  4.64 | ppl   103.37\n",
            "| epoch   6 |   240/  257 batches | lr 10.00 | ms/batch 50.54 | loss  4.66 | ppl   105.28\n",
            "| epoch   6 |   250/  257 batches | lr 10.00 | ms/batch 50.61 | loss  4.65 | ppl   104.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 15.20s | valid loss  4.75 | valid ppl   115.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |    10/  257 batches | lr 10.00 | ms/batch 54.48 | loss  5.15 | ppl   172.53\n",
            "| epoch   7 |    20/  257 batches | lr 10.00 | ms/batch 51.59 | loss  4.66 | ppl   105.64\n",
            "| epoch   7 |    30/  257 batches | lr 10.00 | ms/batch 50.63 | loss  4.64 | ppl   103.26\n",
            "| epoch   7 |    40/  257 batches | lr 10.00 | ms/batch 51.33 | loss  4.64 | ppl   103.31\n",
            "| epoch   7 |    50/  257 batches | lr 10.00 | ms/batch 50.79 | loss  4.65 | ppl   104.82\n",
            "| epoch   7 |    60/  257 batches | lr 10.00 | ms/batch 50.76 | loss  4.63 | ppl   102.26\n",
            "| epoch   7 |    70/  257 batches | lr 10.00 | ms/batch 50.51 | loss  4.60 | ppl    99.81\n",
            "| epoch   7 |    80/  257 batches | lr 10.00 | ms/batch 51.20 | loss  4.58 | ppl    97.55\n",
            "| epoch   7 |    90/  257 batches | lr 10.00 | ms/batch 50.93 | loss  4.64 | ppl   103.17\n",
            "| epoch   7 |   100/  257 batches | lr 10.00 | ms/batch 50.85 | loss  4.63 | ppl   102.99\n",
            "| epoch   7 |   110/  257 batches | lr 10.00 | ms/batch 51.36 | loss  4.60 | ppl    99.47\n",
            "| epoch   7 |   120/  257 batches | lr 10.00 | ms/batch 50.84 | loss  4.60 | ppl    99.38\n",
            "| epoch   7 |   130/  257 batches | lr 10.00 | ms/batch 50.52 | loss  4.63 | ppl   102.19\n",
            "| epoch   7 |   140/  257 batches | lr 10.00 | ms/batch 50.74 | loss  4.57 | ppl    96.36\n",
            "| epoch   7 |   150/  257 batches | lr 10.00 | ms/batch 51.40 | loss  4.56 | ppl    95.75\n",
            "| epoch   7 |   160/  257 batches | lr 10.00 | ms/batch 50.77 | loss  4.59 | ppl    98.51\n",
            "| epoch   7 |   170/  257 batches | lr 10.00 | ms/batch 50.56 | loss  4.62 | ppl   101.26\n",
            "| epoch   7 |   180/  257 batches | lr 10.00 | ms/batch 51.36 | loss  4.60 | ppl    99.26\n",
            "| epoch   7 |   190/  257 batches | lr 10.00 | ms/batch 51.05 | loss  4.59 | ppl    98.71\n",
            "| epoch   7 |   200/  257 batches | lr 10.00 | ms/batch 51.38 | loss  4.55 | ppl    94.85\n",
            "| epoch   7 |   210/  257 batches | lr 10.00 | ms/batch 50.62 | loss  4.51 | ppl    91.35\n",
            "| epoch   7 |   220/  257 batches | lr 10.00 | ms/batch 51.58 | loss  4.57 | ppl    96.82\n",
            "| epoch   7 |   230/  257 batches | lr 10.00 | ms/batch 50.97 | loss  4.55 | ppl    94.73\n",
            "| epoch   7 |   240/  257 batches | lr 10.00 | ms/batch 51.55 | loss  4.56 | ppl    95.74\n",
            "| epoch   7 |   250/  257 batches | lr 10.00 | ms/batch 51.52 | loss  4.58 | ppl    97.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 15.32s | valid loss  4.68 | valid ppl   107.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |    10/  257 batches | lr 10.00 | ms/batch 55.87 | loss  5.06 | ppl   157.97\n",
            "| epoch   8 |    20/  257 batches | lr 10.00 | ms/batch 53.07 | loss  4.57 | ppl    96.20\n",
            "| epoch   8 |    30/  257 batches | lr 10.00 | ms/batch 52.29 | loss  4.55 | ppl    94.36\n",
            "| epoch   8 |    40/  257 batches | lr 10.00 | ms/batch 52.19 | loss  4.56 | ppl    95.18\n",
            "| epoch   8 |    50/  257 batches | lr 10.00 | ms/batch 51.93 | loss  4.56 | ppl    95.65\n",
            "| epoch   8 |    60/  257 batches | lr 10.00 | ms/batch 52.85 | loss  4.53 | ppl    92.69\n",
            "| epoch   8 |    70/  257 batches | lr 10.00 | ms/batch 52.09 | loss  4.51 | ppl    90.69\n",
            "| epoch   8 |    80/  257 batches | lr 10.00 | ms/batch 52.64 | loss  4.51 | ppl    91.03\n",
            "| epoch   8 |    90/  257 batches | lr 10.00 | ms/batch 52.16 | loss  4.57 | ppl    96.40\n",
            "| epoch   8 |   100/  257 batches | lr 10.00 | ms/batch 52.76 | loss  4.55 | ppl    94.96\n",
            "| epoch   8 |   110/  257 batches | lr 10.00 | ms/batch 52.39 | loss  4.51 | ppl    90.98\n",
            "| epoch   8 |   120/  257 batches | lr 10.00 | ms/batch 52.64 | loss  4.52 | ppl    91.66\n",
            "| epoch   8 |   130/  257 batches | lr 10.00 | ms/batch 52.07 | loss  4.54 | ppl    93.44\n",
            "| epoch   8 |   140/  257 batches | lr 10.00 | ms/batch 52.68 | loss  4.48 | ppl    87.98\n",
            "| epoch   8 |   150/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.49 | ppl    88.80\n",
            "| epoch   8 |   160/  257 batches | lr 10.00 | ms/batch 53.15 | loss  4.51 | ppl    90.90\n",
            "| epoch   8 |   170/  257 batches | lr 10.00 | ms/batch 52.59 | loss  4.54 | ppl    93.34\n",
            "| epoch   8 |   180/  257 batches | lr 10.00 | ms/batch 53.11 | loss  4.52 | ppl    91.94\n",
            "| epoch   8 |   190/  257 batches | lr 10.00 | ms/batch 53.20 | loss  4.51 | ppl    91.15\n",
            "| epoch   8 |   200/  257 batches | lr 10.00 | ms/batch 53.32 | loss  4.48 | ppl    88.01\n",
            "| epoch   8 |   210/  257 batches | lr 10.00 | ms/batch 52.73 | loss  4.44 | ppl    84.58\n",
            "| epoch   8 |   220/  257 batches | lr 10.00 | ms/batch 53.53 | loss  4.51 | ppl    90.80\n",
            "| epoch   8 |   230/  257 batches | lr 10.00 | ms/batch 53.25 | loss  4.47 | ppl    87.06\n",
            "| epoch   8 |   240/  257 batches | lr 10.00 | ms/batch 53.06 | loss  4.47 | ppl    87.58\n",
            "| epoch   8 |   250/  257 batches | lr 10.00 | ms/batch 53.87 | loss  4.52 | ppl    91.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 15.74s | valid loss  4.62 | valid ppl   101.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |    10/  257 batches | lr 10.00 | ms/batch 57.25 | loss  5.01 | ppl   150.35\n",
            "| epoch   9 |    20/  257 batches | lr 10.00 | ms/batch 54.76 | loss  4.51 | ppl    90.49\n",
            "| epoch   9 |    30/  257 batches | lr 10.00 | ms/batch 52.94 | loss  4.48 | ppl    88.14\n",
            "| epoch   9 |    40/  257 batches | lr 10.00 | ms/batch 54.28 | loss  4.48 | ppl    88.08\n",
            "| epoch   9 |    50/  257 batches | lr 10.00 | ms/batch 52.85 | loss  4.49 | ppl    88.77\n",
            "| epoch   9 |    60/  257 batches | lr 10.00 | ms/batch 54.09 | loss  4.46 | ppl    86.88\n",
            "| epoch   9 |    70/  257 batches | lr 10.00 | ms/batch 53.33 | loss  4.45 | ppl    85.57\n",
            "| epoch   9 |    80/  257 batches | lr 10.00 | ms/batch 53.49 | loss  4.44 | ppl    84.70\n",
            "| epoch   9 |    90/  257 batches | lr 10.00 | ms/batch 53.05 | loss  4.50 | ppl    90.06\n",
            "| epoch   9 |   100/  257 batches | lr 10.00 | ms/batch 54.05 | loss  4.48 | ppl    88.08\n",
            "| epoch   9 |   110/  257 batches | lr 10.00 | ms/batch 53.43 | loss  4.45 | ppl    85.32\n",
            "| epoch   9 |   120/  257 batches | lr 10.00 | ms/batch 53.76 | loss  4.45 | ppl    85.86\n",
            "| epoch   9 |   130/  257 batches | lr 10.00 | ms/batch 53.43 | loss  4.48 | ppl    87.99\n",
            "| epoch   9 |   140/  257 batches | lr 10.00 | ms/batch 53.95 | loss  4.43 | ppl    83.70\n",
            "| epoch   9 |   150/  257 batches | lr 10.00 | ms/batch 53.33 | loss  4.42 | ppl    82.85\n",
            "| epoch   9 |   160/  257 batches | lr 10.00 | ms/batch 53.70 | loss  4.43 | ppl    84.00\n",
            "| epoch   9 |   170/  257 batches | lr 10.00 | ms/batch 52.73 | loss  4.47 | ppl    87.28\n",
            "| epoch   9 |   180/  257 batches | lr 10.00 | ms/batch 53.68 | loss  4.45 | ppl    85.96\n",
            "| epoch   9 |   190/  257 batches | lr 10.00 | ms/batch 52.98 | loss  4.44 | ppl    85.19\n",
            "| epoch   9 |   200/  257 batches | lr 10.00 | ms/batch 53.08 | loss  4.40 | ppl    81.85\n",
            "| epoch   9 |   210/  257 batches | lr 10.00 | ms/batch 52.62 | loss  4.36 | ppl    78.57\n",
            "| epoch   9 |   220/  257 batches | lr 10.00 | ms/batch 52.63 | loss  4.44 | ppl    84.56\n",
            "| epoch   9 |   230/  257 batches | lr 10.00 | ms/batch 52.67 | loss  4.41 | ppl    81.86\n",
            "| epoch   9 |   240/  257 batches | lr 10.00 | ms/batch 52.66 | loss  4.42 | ppl    83.14\n",
            "| epoch   9 |   250/  257 batches | lr 10.00 | ms/batch 52.75 | loss  4.45 | ppl    85.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 15.90s | valid loss  4.56 | valid ppl    95.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |    10/  257 batches | lr 10.00 | ms/batch 56.50 | loss  4.91 | ppl   135.19\n",
            "| epoch  10 |    20/  257 batches | lr 10.00 | ms/batch 53.49 | loss  4.44 | ppl    84.84\n",
            "| epoch  10 |    30/  257 batches | lr 10.00 | ms/batch 51.75 | loss  4.42 | ppl    83.41\n",
            "| epoch  10 |    40/  257 batches | lr 10.00 | ms/batch 52.27 | loss  4.43 | ppl    83.60\n",
            "| epoch  10 |    50/  257 batches | lr 10.00 | ms/batch 52.14 | loss  4.43 | ppl    83.63\n",
            "| epoch  10 |    60/  257 batches | lr 10.00 | ms/batch 52.64 | loss  4.40 | ppl    81.57\n",
            "| epoch  10 |    70/  257 batches | lr 10.00 | ms/batch 52.42 | loss  4.39 | ppl    80.83\n",
            "| epoch  10 |    80/  257 batches | lr 10.00 | ms/batch 51.94 | loss  4.37 | ppl    79.40\n",
            "| epoch  10 |    90/  257 batches | lr 10.00 | ms/batch 51.87 | loss  4.44 | ppl    85.08\n",
            "| epoch  10 |   100/  257 batches | lr 10.00 | ms/batch 52.40 | loss  4.42 | ppl    82.91\n",
            "| epoch  10 |   110/  257 batches | lr 10.00 | ms/batch 51.87 | loss  4.38 | ppl    80.06\n",
            "| epoch  10 |   120/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.40 | ppl    81.52\n",
            "| epoch  10 |   130/  257 batches | lr 10.00 | ms/batch 51.80 | loss  4.42 | ppl    83.31\n",
            "| epoch  10 |   140/  257 batches | lr 10.00 | ms/batch 51.68 | loss  4.36 | ppl    78.12\n",
            "| epoch  10 |   150/  257 batches | lr 10.00 | ms/batch 51.63 | loss  4.37 | ppl    78.69\n",
            "| epoch  10 |   160/  257 batches | lr 10.00 | ms/batch 52.49 | loss  4.38 | ppl    80.05\n",
            "| epoch  10 |   170/  257 batches | lr 10.00 | ms/batch 51.27 | loss  4.40 | ppl    81.42\n",
            "| epoch  10 |   180/  257 batches | lr 10.00 | ms/batch 51.66 | loss  4.38 | ppl    80.17\n",
            "| epoch  10 |   190/  257 batches | lr 10.00 | ms/batch 52.06 | loss  4.37 | ppl    79.09\n",
            "| epoch  10 |   200/  257 batches | lr 10.00 | ms/batch 52.05 | loss  4.36 | ppl    78.57\n",
            "| epoch  10 |   210/  257 batches | lr 10.00 | ms/batch 51.46 | loss  4.31 | ppl    74.66\n",
            "| epoch  10 |   220/  257 batches | lr 10.00 | ms/batch 51.65 | loss  4.39 | ppl    80.26\n",
            "| epoch  10 |   230/  257 batches | lr 10.00 | ms/batch 51.61 | loss  4.35 | ppl    77.79\n",
            "| epoch  10 |   240/  257 batches | lr 10.00 | ms/batch 51.63 | loss  4.36 | ppl    78.55\n",
            "| epoch  10 |   250/  257 batches | lr 10.00 | ms/batch 51.69 | loss  4.39 | ppl    80.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 15.59s | valid loss  4.53 | valid ppl    92.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |    10/  257 batches | lr 10.00 | ms/batch 54.72 | loss  4.85 | ppl   127.65\n",
            "| epoch  11 |    20/  257 batches | lr 10.00 | ms/batch 52.53 | loss  4.38 | ppl    80.15\n",
            "| epoch  11 |    30/  257 batches | lr 10.00 | ms/batch 50.67 | loss  4.38 | ppl    79.87\n",
            "| epoch  11 |    40/  257 batches | lr 10.00 | ms/batch 51.76 | loss  4.37 | ppl    78.97\n",
            "| epoch  11 |    50/  257 batches | lr 10.00 | ms/batch 51.68 | loss  4.37 | ppl    79.09\n",
            "| epoch  11 |    60/  257 batches | lr 10.00 | ms/batch 51.90 | loss  4.35 | ppl    77.74\n",
            "| epoch  11 |    70/  257 batches | lr 10.00 | ms/batch 51.21 | loss  4.34 | ppl    76.84\n",
            "| epoch  11 |    80/  257 batches | lr 10.00 | ms/batch 50.97 | loss  4.32 | ppl    75.50\n",
            "| epoch  11 |    90/  257 batches | lr 10.00 | ms/batch 51.20 | loss  4.37 | ppl    79.40\n",
            "| epoch  11 |   100/  257 batches | lr 10.00 | ms/batch 51.66 | loss  4.37 | ppl    79.19\n",
            "| epoch  11 |   110/  257 batches | lr 10.00 | ms/batch 51.40 | loss  4.35 | ppl    77.11\n",
            "| epoch  11 |   120/  257 batches | lr 10.00 | ms/batch 51.71 | loss  4.35 | ppl    77.54\n",
            "| epoch  11 |   130/  257 batches | lr 10.00 | ms/batch 51.46 | loss  4.37 | ppl    79.23\n",
            "| epoch  11 |   140/  257 batches | lr 10.00 | ms/batch 51.85 | loss  4.32 | ppl    75.23\n",
            "| epoch  11 |   150/  257 batches | lr 10.00 | ms/batch 51.53 | loss  4.31 | ppl    74.73\n",
            "| epoch  11 |   160/  257 batches | lr 10.00 | ms/batch 51.61 | loss  4.33 | ppl    75.71\n",
            "| epoch  11 |   170/  257 batches | lr 10.00 | ms/batch 51.20 | loss  4.34 | ppl    76.93\n",
            "| epoch  11 |   180/  257 batches | lr 10.00 | ms/batch 51.52 | loss  4.35 | ppl    77.11\n",
            "| epoch  11 |   190/  257 batches | lr 10.00 | ms/batch 51.77 | loss  4.36 | ppl    78.10\n",
            "| epoch  11 |   200/  257 batches | lr 10.00 | ms/batch 51.55 | loss  4.31 | ppl    74.60\n",
            "| epoch  11 |   210/  257 batches | lr 10.00 | ms/batch 51.64 | loss  4.26 | ppl    71.12\n",
            "| epoch  11 |   220/  257 batches | lr 10.00 | ms/batch 50.58 | loss  4.34 | ppl    76.63\n",
            "| epoch  11 |   230/  257 batches | lr 10.00 | ms/batch 52.03 | loss  4.31 | ppl    74.58\n",
            "| epoch  11 |   240/  257 batches | lr 10.00 | ms/batch 51.12 | loss  4.32 | ppl    75.48\n",
            "| epoch  11 |   250/  257 batches | lr 10.00 | ms/batch 51.66 | loss  4.34 | ppl    77.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 15.42s | valid loss  4.48 | valid ppl    88.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |    10/  257 batches | lr 10.00 | ms/batch 55.51 | loss  4.83 | ppl   124.71\n",
            "| epoch  12 |    20/  257 batches | lr 10.00 | ms/batch 53.59 | loss  4.34 | ppl    76.73\n",
            "| epoch  12 |    30/  257 batches | lr 10.00 | ms/batch 51.38 | loss  4.32 | ppl    75.51\n",
            "| epoch  12 |    40/  257 batches | lr 10.00 | ms/batch 52.03 | loss  4.33 | ppl    75.97\n",
            "| epoch  12 |    50/  257 batches | lr 10.00 | ms/batch 51.43 | loss  4.33 | ppl    76.17\n",
            "| epoch  12 |    60/  257 batches | lr 10.00 | ms/batch 52.13 | loss  4.32 | ppl    75.01\n",
            "| epoch  12 |    70/  257 batches | lr 10.00 | ms/batch 52.14 | loss  4.30 | ppl    73.51\n",
            "| epoch  12 |    80/  257 batches | lr 10.00 | ms/batch 51.59 | loss  4.28 | ppl    72.58\n",
            "| epoch  12 |    90/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.35 | ppl    77.63\n",
            "| epoch  12 |   100/  257 batches | lr 10.00 | ms/batch 51.59 | loss  4.33 | ppl    75.66\n",
            "| epoch  12 |   110/  257 batches | lr 10.00 | ms/batch 51.63 | loss  4.30 | ppl    73.34\n",
            "| epoch  12 |   120/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.30 | ppl    73.39\n",
            "| epoch  12 |   130/  257 batches | lr 10.00 | ms/batch 51.12 | loss  4.33 | ppl    75.90\n",
            "| epoch  12 |   140/  257 batches | lr 10.00 | ms/batch 52.26 | loss  4.28 | ppl    72.11\n",
            "| epoch  12 |   150/  257 batches | lr 10.00 | ms/batch 52.14 | loss  4.27 | ppl    71.31\n",
            "| epoch  12 |   160/  257 batches | lr 10.00 | ms/batch 51.78 | loss  4.29 | ppl    72.86\n",
            "| epoch  12 |   170/  257 batches | lr 10.00 | ms/batch 51.87 | loss  4.32 | ppl    75.23\n",
            "| epoch  12 |   180/  257 batches | lr 10.00 | ms/batch 52.51 | loss  4.31 | ppl    74.53\n",
            "| epoch  12 |   190/  257 batches | lr 10.00 | ms/batch 51.70 | loss  4.31 | ppl    74.25\n",
            "| epoch  12 |   200/  257 batches | lr 10.00 | ms/batch 51.68 | loss  4.26 | ppl    71.11\n",
            "| epoch  12 |   210/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.23 | ppl    68.71\n",
            "| epoch  12 |   220/  257 batches | lr 10.00 | ms/batch 51.82 | loss  4.28 | ppl    72.10\n",
            "| epoch  12 |   230/  257 batches | lr 10.00 | ms/batch 51.72 | loss  4.27 | ppl    71.27\n",
            "| epoch  12 |   240/  257 batches | lr 10.00 | ms/batch 52.43 | loss  4.28 | ppl    71.91\n",
            "| epoch  12 |   250/  257 batches | lr 10.00 | ms/batch 51.88 | loss  4.31 | ppl    74.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 15.55s | valid loss  4.46 | valid ppl    86.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |    10/  257 batches | lr 10.00 | ms/batch 56.36 | loss  4.76 | ppl   116.60\n",
            "| epoch  13 |    20/  257 batches | lr 10.00 | ms/batch 52.95 | loss  4.30 | ppl    73.53\n",
            "| epoch  13 |    30/  257 batches | lr 10.00 | ms/batch 51.67 | loss  4.29 | ppl    72.68\n",
            "| epoch  13 |    40/  257 batches | lr 10.00 | ms/batch 52.80 | loss  4.29 | ppl    72.87\n",
            "| epoch  13 |    50/  257 batches | lr 10.00 | ms/batch 51.71 | loss  4.30 | ppl    73.44\n",
            "| epoch  13 |    60/  257 batches | lr 10.00 | ms/batch 52.62 | loss  4.28 | ppl    71.90\n",
            "| epoch  13 |    70/  257 batches | lr 10.00 | ms/batch 52.24 | loss  4.26 | ppl    71.09\n",
            "| epoch  13 |    80/  257 batches | lr 10.00 | ms/batch 52.68 | loss  4.24 | ppl    69.58\n",
            "| epoch  13 |    90/  257 batches | lr 10.00 | ms/batch 52.34 | loss  4.31 | ppl    74.79\n",
            "| epoch  13 |   100/  257 batches | lr 10.00 | ms/batch 52.70 | loss  4.30 | ppl    73.36\n",
            "| epoch  13 |   110/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.25 | ppl    70.25\n",
            "| epoch  13 |   120/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.27 | ppl    71.19\n",
            "| epoch  13 |   130/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.29 | ppl    72.63\n",
            "| epoch  13 |   140/  257 batches | lr 10.00 | ms/batch 51.88 | loss  4.24 | ppl    69.16\n",
            "| epoch  13 |   150/  257 batches | lr 10.00 | ms/batch 52.52 | loss  4.24 | ppl    69.53\n",
            "| epoch  13 |   160/  257 batches | lr 10.00 | ms/batch 52.59 | loss  4.26 | ppl    70.52\n",
            "| epoch  13 |   170/  257 batches | lr 10.00 | ms/batch 52.51 | loss  4.26 | ppl    70.75\n",
            "| epoch  13 |   180/  257 batches | lr 10.00 | ms/batch 52.63 | loss  4.28 | ppl    72.09\n",
            "| epoch  13 |   190/  257 batches | lr 10.00 | ms/batch 52.32 | loss  4.26 | ppl    70.66\n",
            "| epoch  13 |   200/  257 batches | lr 10.00 | ms/batch 52.29 | loss  4.24 | ppl    69.21\n",
            "| epoch  13 |   210/  257 batches | lr 10.00 | ms/batch 52.54 | loss  4.18 | ppl    65.37\n",
            "| epoch  13 |   220/  257 batches | lr 10.00 | ms/batch 52.46 | loss  4.26 | ppl    70.59\n",
            "| epoch  13 |   230/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.23 | ppl    68.84\n",
            "| epoch  13 |   240/  257 batches | lr 10.00 | ms/batch 52.57 | loss  4.24 | ppl    69.74\n",
            "| epoch  13 |   250/  257 batches | lr 10.00 | ms/batch 52.65 | loss  4.27 | ppl    71.44\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 15.67s | valid loss  4.42 | valid ppl    83.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |    10/  257 batches | lr 10.00 | ms/batch 55.98 | loss  4.72 | ppl   112.45\n",
            "| epoch  14 |    20/  257 batches | lr 10.00 | ms/batch 54.44 | loss  4.27 | ppl    71.44\n",
            "| epoch  14 |    30/  257 batches | lr 10.00 | ms/batch 51.67 | loss  4.25 | ppl    69.78\n",
            "| epoch  14 |    40/  257 batches | lr 10.00 | ms/batch 52.87 | loss  4.25 | ppl    70.41\n",
            "| epoch  14 |    50/  257 batches | lr 10.00 | ms/batch 51.78 | loss  4.26 | ppl    70.87\n",
            "| epoch  14 |    60/  257 batches | lr 10.00 | ms/batch 53.07 | loss  4.23 | ppl    68.83\n",
            "| epoch  14 |    70/  257 batches | lr 10.00 | ms/batch 52.14 | loss  4.23 | ppl    68.53\n",
            "| epoch  14 |    80/  257 batches | lr 10.00 | ms/batch 52.45 | loss  4.20 | ppl    66.72\n",
            "| epoch  14 |    90/  257 batches | lr 10.00 | ms/batch 52.43 | loss  4.27 | ppl    71.83\n",
            "| epoch  14 |   100/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.26 | ppl    70.83\n",
            "| epoch  14 |   110/  257 batches | lr 10.00 | ms/batch 52.40 | loss  4.22 | ppl    68.32\n",
            "| epoch  14 |   120/  257 batches | lr 10.00 | ms/batch 52.38 | loss  4.23 | ppl    68.54\n",
            "| epoch  14 |   130/  257 batches | lr 10.00 | ms/batch 52.38 | loss  4.25 | ppl    70.36\n",
            "| epoch  14 |   140/  257 batches | lr 10.00 | ms/batch 52.58 | loss  4.20 | ppl    66.96\n",
            "| epoch  14 |   150/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.21 | ppl    67.58\n",
            "| epoch  14 |   160/  257 batches | lr 10.00 | ms/batch 52.55 | loss  4.22 | ppl    67.95\n",
            "| epoch  14 |   170/  257 batches | lr 10.00 | ms/batch 52.41 | loss  4.23 | ppl    68.83\n",
            "| epoch  14 |   180/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.23 | ppl    68.46\n",
            "| epoch  14 |   190/  257 batches | lr 10.00 | ms/batch 52.66 | loss  4.25 | ppl    69.85\n",
            "| epoch  14 |   200/  257 batches | lr 10.00 | ms/batch 52.13 | loss  4.20 | ppl    66.71\n",
            "| epoch  14 |   210/  257 batches | lr 10.00 | ms/batch 52.61 | loss  4.16 | ppl    63.96\n",
            "| epoch  14 |   220/  257 batches | lr 10.00 | ms/batch 51.83 | loss  4.22 | ppl    68.01\n",
            "| epoch  14 |   230/  257 batches | lr 10.00 | ms/batch 52.35 | loss  4.21 | ppl    67.07\n",
            "| epoch  14 |   240/  257 batches | lr 10.00 | ms/batch 52.27 | loss  4.21 | ppl    67.58\n",
            "| epoch  14 |   250/  257 batches | lr 10.00 | ms/batch 52.37 | loss  4.24 | ppl    69.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 15.69s | valid loss  4.40 | valid ppl    81.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |    10/  257 batches | lr 10.00 | ms/batch 55.75 | loss  4.69 | ppl   108.77\n",
            "| epoch  15 |    20/  257 batches | lr 10.00 | ms/batch 53.85 | loss  4.22 | ppl    68.27\n",
            "| epoch  15 |    30/  257 batches | lr 10.00 | ms/batch 51.82 | loss  4.21 | ppl    67.61\n",
            "| epoch  15 |    40/  257 batches | lr 10.00 | ms/batch 53.26 | loss  4.22 | ppl    68.13\n",
            "| epoch  15 |    50/  257 batches | lr 10.00 | ms/batch 51.73 | loss  4.23 | ppl    68.97\n",
            "| epoch  15 |    60/  257 batches | lr 10.00 | ms/batch 52.73 | loss  4.21 | ppl    67.21\n",
            "| epoch  15 |    70/  257 batches | lr 10.00 | ms/batch 52.39 | loss  4.20 | ppl    66.43\n",
            "| epoch  15 |    80/  257 batches | lr 10.00 | ms/batch 52.57 | loss  4.18 | ppl    65.12\n",
            "| epoch  15 |    90/  257 batches | lr 10.00 | ms/batch 51.75 | loss  4.25 | ppl    69.88\n",
            "| epoch  15 |   100/  257 batches | lr 10.00 | ms/batch 52.70 | loss  4.22 | ppl    68.14\n",
            "| epoch  15 |   110/  257 batches | lr 10.00 | ms/batch 52.13 | loss  4.19 | ppl    66.05\n",
            "| epoch  15 |   120/  257 batches | lr 10.00 | ms/batch 52.86 | loss  4.21 | ppl    67.34\n",
            "| epoch  15 |   130/  257 batches | lr 10.00 | ms/batch 52.85 | loss  4.22 | ppl    68.09\n",
            "| epoch  15 |   140/  257 batches | lr 10.00 | ms/batch 51.94 | loss  4.17 | ppl    64.65\n",
            "| epoch  15 |   150/  257 batches | lr 10.00 | ms/batch 52.32 | loss  4.17 | ppl    64.57\n",
            "| epoch  15 |   160/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.19 | ppl    65.75\n",
            "| epoch  15 |   170/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.22 | ppl    67.74\n",
            "| epoch  15 |   180/  257 batches | lr 10.00 | ms/batch 52.49 | loss  4.21 | ppl    67.24\n",
            "| epoch  15 |   190/  257 batches | lr 10.00 | ms/batch 52.18 | loss  4.21 | ppl    67.06\n",
            "| epoch  15 |   200/  257 batches | lr 10.00 | ms/batch 52.39 | loss  4.17 | ppl    64.51\n",
            "| epoch  15 |   210/  257 batches | lr 10.00 | ms/batch 52.18 | loss  4.12 | ppl    61.46\n",
            "| epoch  15 |   220/  257 batches | lr 10.00 | ms/batch 52.04 | loss  4.19 | ppl    65.96\n",
            "| epoch  15 |   230/  257 batches | lr 10.00 | ms/batch 52.62 | loss  4.18 | ppl    65.09\n",
            "| epoch  15 |   240/  257 batches | lr 10.00 | ms/batch 52.29 | loss  4.19 | ppl    66.03\n",
            "| epoch  15 |   250/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.20 | ppl    66.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 15.68s | valid loss  4.39 | valid ppl    80.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |    10/  257 batches | lr 10.00 | ms/batch 56.26 | loss  4.65 | ppl   104.52\n",
            "| epoch  16 |    20/  257 batches | lr 10.00 | ms/batch 53.47 | loss  4.21 | ppl    67.09\n",
            "| epoch  16 |    30/  257 batches | lr 10.00 | ms/batch 51.62 | loss  4.19 | ppl    66.21\n",
            "| epoch  16 |    40/  257 batches | lr 10.00 | ms/batch 52.63 | loss  4.19 | ppl    66.21\n",
            "| epoch  16 |    50/  257 batches | lr 10.00 | ms/batch 51.85 | loss  4.20 | ppl    66.66\n",
            "| epoch  16 |    60/  257 batches | lr 10.00 | ms/batch 52.35 | loss  4.17 | ppl    64.97\n",
            "| epoch  16 |    70/  257 batches | lr 10.00 | ms/batch 52.47 | loss  4.16 | ppl    64.39\n",
            "| epoch  16 |    80/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.15 | ppl    63.19\n",
            "| epoch  16 |    90/  257 batches | lr 10.00 | ms/batch 52.11 | loss  4.21 | ppl    67.16\n",
            "| epoch  16 |   100/  257 batches | lr 10.00 | ms/batch 52.35 | loss  4.20 | ppl    66.38\n",
            "| epoch  16 |   110/  257 batches | lr 10.00 | ms/batch 52.55 | loss  4.15 | ppl    63.69\n",
            "| epoch  16 |   120/  257 batches | lr 10.00 | ms/batch 52.01 | loss  4.17 | ppl    64.89\n",
            "| epoch  16 |   130/  257 batches | lr 10.00 | ms/batch 52.66 | loss  4.20 | ppl    66.53\n",
            "| epoch  16 |   140/  257 batches | lr 10.00 | ms/batch 52.43 | loss  4.14 | ppl    62.95\n",
            "| epoch  16 |   150/  257 batches | lr 10.00 | ms/batch 52.39 | loss  4.15 | ppl    63.53\n",
            "| epoch  16 |   160/  257 batches | lr 10.00 | ms/batch 51.77 | loss  4.16 | ppl    64.28\n",
            "| epoch  16 |   170/  257 batches | lr 10.00 | ms/batch 52.66 | loss  4.17 | ppl    64.75\n",
            "| epoch  16 |   180/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.17 | ppl    64.73\n",
            "| epoch  16 |   190/  257 batches | lr 10.00 | ms/batch 52.52 | loss  4.18 | ppl    65.14\n",
            "| epoch  16 |   200/  257 batches | lr 10.00 | ms/batch 52.41 | loss  4.14 | ppl    62.99\n",
            "| epoch  16 |   210/  257 batches | lr 10.00 | ms/batch 51.79 | loss  4.10 | ppl    60.57\n",
            "| epoch  16 |   220/  257 batches | lr 10.00 | ms/batch 52.24 | loss  4.16 | ppl    64.08\n",
            "| epoch  16 |   230/  257 batches | lr 10.00 | ms/batch 52.29 | loss  4.15 | ppl    63.42\n",
            "| epoch  16 |   240/  257 batches | lr 10.00 | ms/batch 51.90 | loss  4.15 | ppl    63.68\n",
            "| epoch  16 |   250/  257 batches | lr 10.00 | ms/batch 52.21 | loss  4.18 | ppl    65.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 15.63s | valid loss  4.36 | valid ppl    78.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |    10/  257 batches | lr 10.00 | ms/batch 55.94 | loss  4.63 | ppl   102.12\n",
            "| epoch  17 |    20/  257 batches | lr 10.00 | ms/batch 53.53 | loss  4.18 | ppl    65.23\n",
            "| epoch  17 |    30/  257 batches | lr 10.00 | ms/batch 51.74 | loss  4.15 | ppl    63.58\n",
            "| epoch  17 |    40/  257 batches | lr 10.00 | ms/batch 52.52 | loss  4.17 | ppl    64.61\n",
            "| epoch  17 |    50/  257 batches | lr 10.00 | ms/batch 51.51 | loss  4.17 | ppl    64.73\n",
            "| epoch  17 |    60/  257 batches | lr 10.00 | ms/batch 52.27 | loss  4.14 | ppl    63.00\n",
            "| epoch  17 |    70/  257 batches | lr 10.00 | ms/batch 52.06 | loss  4.14 | ppl    63.02\n",
            "| epoch  17 |    80/  257 batches | lr 10.00 | ms/batch 51.77 | loss  4.12 | ppl    61.65\n",
            "| epoch  17 |    90/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.19 | ppl    66.04\n",
            "| epoch  17 |   100/  257 batches | lr 10.00 | ms/batch 51.69 | loss  4.18 | ppl    65.15\n",
            "| epoch  17 |   110/  257 batches | lr 10.00 | ms/batch 52.62 | loss  4.13 | ppl    62.17\n",
            "| epoch  17 |   120/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.15 | ppl    63.23\n",
            "| epoch  17 |   130/  257 batches | lr 10.00 | ms/batch 52.53 | loss  4.17 | ppl    64.55\n",
            "| epoch  17 |   140/  257 batches | lr 10.00 | ms/batch 52.47 | loss  4.12 | ppl    61.58\n",
            "| epoch  17 |   150/  257 batches | lr 10.00 | ms/batch 52.83 | loss  4.12 | ppl    61.66\n",
            "| epoch  17 |   160/  257 batches | lr 10.00 | ms/batch 52.00 | loss  4.13 | ppl    62.07\n",
            "| epoch  17 |   170/  257 batches | lr 10.00 | ms/batch 52.69 | loss  4.16 | ppl    63.92\n",
            "| epoch  17 |   180/  257 batches | lr 10.00 | ms/batch 52.35 | loss  4.16 | ppl    63.83\n",
            "| epoch  17 |   190/  257 batches | lr 10.00 | ms/batch 52.37 | loss  4.16 | ppl    63.82\n",
            "| epoch  17 |   200/  257 batches | lr 10.00 | ms/batch 52.06 | loss  4.11 | ppl    61.18\n",
            "| epoch  17 |   210/  257 batches | lr 10.00 | ms/batch 52.57 | loss  4.07 | ppl    58.53\n",
            "| epoch  17 |   220/  257 batches | lr 10.00 | ms/batch 52.33 | loss  4.13 | ppl    62.47\n",
            "| epoch  17 |   230/  257 batches | lr 10.00 | ms/batch 52.66 | loss  4.12 | ppl    61.83\n",
            "| epoch  17 |   240/  257 batches | lr 10.00 | ms/batch 52.04 | loss  4.13 | ppl    62.31\n",
            "| epoch  17 |   250/  257 batches | lr 10.00 | ms/batch 52.50 | loss  4.15 | ppl    63.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 15.63s | valid loss  4.35 | valid ppl    77.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |    10/  257 batches | lr 10.00 | ms/batch 56.02 | loss  4.60 | ppl    99.08\n",
            "| epoch  18 |    20/  257 batches | lr 10.00 | ms/batch 53.59 | loss  4.16 | ppl    64.07\n",
            "| epoch  18 |    30/  257 batches | lr 10.00 | ms/batch 51.78 | loss  4.14 | ppl    62.59\n",
            "| epoch  18 |    40/  257 batches | lr 10.00 | ms/batch 52.75 | loss  4.14 | ppl    63.07\n",
            "| epoch  18 |    50/  257 batches | lr 10.00 | ms/batch 52.11 | loss  4.14 | ppl    62.85\n",
            "| epoch  18 |    60/  257 batches | lr 10.00 | ms/batch 52.38 | loss  4.11 | ppl    61.10\n",
            "| epoch  18 |    70/  257 batches | lr 10.00 | ms/batch 52.06 | loss  4.11 | ppl    61.13\n",
            "| epoch  18 |    80/  257 batches | lr 10.00 | ms/batch 52.76 | loss  4.10 | ppl    60.30\n",
            "| epoch  18 |    90/  257 batches | lr 10.00 | ms/batch 52.16 | loss  4.17 | ppl    64.44\n",
            "| epoch  18 |   100/  257 batches | lr 10.00 | ms/batch 52.29 | loss  4.15 | ppl    63.63\n",
            "| epoch  18 |   110/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.11 | ppl    60.65\n",
            "| epoch  18 |   120/  257 batches | lr 10.00 | ms/batch 52.49 | loss  4.13 | ppl    62.03\n",
            "| epoch  18 |   130/  257 batches | lr 10.00 | ms/batch 51.78 | loss  4.14 | ppl    62.73\n",
            "| epoch  18 |   140/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.09 | ppl    59.58\n",
            "| epoch  18 |   150/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.09 | ppl    59.94\n",
            "| epoch  18 |   160/  257 batches | lr 10.00 | ms/batch 51.91 | loss  4.11 | ppl    60.97\n",
            "| epoch  18 |   170/  257 batches | lr 10.00 | ms/batch 52.30 | loss  4.14 | ppl    62.58\n",
            "| epoch  18 |   180/  257 batches | lr 10.00 | ms/batch 51.92 | loss  4.12 | ppl    61.84\n",
            "| epoch  18 |   190/  257 batches | lr 10.00 | ms/batch 52.22 | loss  4.12 | ppl    61.65\n",
            "| epoch  18 |   200/  257 batches | lr 10.00 | ms/batch 52.72 | loss  4.09 | ppl    59.88\n",
            "| epoch  18 |   210/  257 batches | lr 10.00 | ms/batch 52.26 | loss  4.04 | ppl    57.05\n",
            "| epoch  18 |   220/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.10 | ppl    60.36\n",
            "| epoch  18 |   230/  257 batches | lr 10.00 | ms/batch 52.19 | loss  4.10 | ppl    60.05\n",
            "| epoch  18 |   240/  257 batches | lr 10.00 | ms/batch 52.51 | loss  4.11 | ppl    60.87\n",
            "| epoch  18 |   250/  257 batches | lr 10.00 | ms/batch 52.46 | loss  4.13 | ppl    62.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 15.64s | valid loss  4.33 | valid ppl    75.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |    10/  257 batches | lr 10.00 | ms/batch 55.97 | loss  4.57 | ppl    96.33\n",
            "| epoch  19 |    20/  257 batches | lr 10.00 | ms/batch 54.30 | loss  4.13 | ppl    62.36\n",
            "| epoch  19 |    30/  257 batches | lr 10.00 | ms/batch 51.76 | loss  4.11 | ppl    61.14\n",
            "| epoch  19 |    40/  257 batches | lr 10.00 | ms/batch 52.80 | loss  4.12 | ppl    61.49\n",
            "| epoch  19 |    50/  257 batches | lr 10.00 | ms/batch 51.63 | loss  4.12 | ppl    61.45\n",
            "| epoch  19 |    60/  257 batches | lr 10.00 | ms/batch 52.87 | loss  4.10 | ppl    60.37\n",
            "| epoch  19 |    70/  257 batches | lr 10.00 | ms/batch 52.39 | loss  4.09 | ppl    59.87\n",
            "| epoch  19 |    80/  257 batches | lr 10.00 | ms/batch 52.76 | loss  4.08 | ppl    59.06\n",
            "| epoch  19 |    90/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.15 | ppl    63.20\n",
            "| epoch  19 |   100/  257 batches | lr 10.00 | ms/batch 52.59 | loss  4.13 | ppl    61.94\n",
            "| epoch  19 |   110/  257 batches | lr 10.00 | ms/batch 52.61 | loss  4.09 | ppl    59.60\n",
            "| epoch  19 |   120/  257 batches | lr 10.00 | ms/batch 52.43 | loss  4.10 | ppl    60.35\n",
            "| epoch  19 |   130/  257 batches | lr 10.00 | ms/batch 52.33 | loss  4.11 | ppl    60.90\n",
            "| epoch  19 |   140/  257 batches | lr 10.00 | ms/batch 52.14 | loss  4.07 | ppl    58.57\n",
            "| epoch  19 |   150/  257 batches | lr 10.00 | ms/batch 52.34 | loss  4.07 | ppl    58.45\n",
            "| epoch  19 |   160/  257 batches | lr 10.00 | ms/batch 52.28 | loss  4.09 | ppl    59.76\n",
            "| epoch  19 |   170/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.11 | ppl    61.05\n",
            "| epoch  19 |   180/  257 batches | lr 10.00 | ms/batch 52.53 | loss  4.11 | ppl    60.88\n",
            "| epoch  19 |   190/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.10 | ppl    60.62\n",
            "| epoch  19 |   200/  257 batches | lr 10.00 | ms/batch 52.06 | loss  4.08 | ppl    58.87\n",
            "| epoch  19 |   210/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.02 | ppl    55.94\n",
            "| epoch  19 |   220/  257 batches | lr 10.00 | ms/batch 52.51 | loss  4.09 | ppl    59.69\n",
            "| epoch  19 |   230/  257 batches | lr 10.00 | ms/batch 52.69 | loss  4.08 | ppl    59.06\n",
            "| epoch  19 |   240/  257 batches | lr 10.00 | ms/batch 52.67 | loss  4.10 | ppl    60.16\n",
            "| epoch  19 |   250/  257 batches | lr 10.00 | ms/batch 52.26 | loss  4.11 | ppl    60.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 15.67s | valid loss  4.32 | valid ppl    75.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |    10/  257 batches | lr 10.00 | ms/batch 55.90 | loss  4.55 | ppl    94.17\n",
            "| epoch  20 |    20/  257 batches | lr 10.00 | ms/batch 53.94 | loss  4.11 | ppl    60.80\n",
            "| epoch  20 |    30/  257 batches | lr 10.00 | ms/batch 51.75 | loss  4.09 | ppl    60.01\n",
            "| epoch  20 |    40/  257 batches | lr 10.00 | ms/batch 53.19 | loss  4.09 | ppl    60.03\n",
            "| epoch  20 |    50/  257 batches | lr 10.00 | ms/batch 52.02 | loss  4.11 | ppl    60.71\n",
            "| epoch  20 |    60/  257 batches | lr 10.00 | ms/batch 52.50 | loss  4.07 | ppl    58.72\n",
            "| epoch  20 |    70/  257 batches | lr 10.00 | ms/batch 52.42 | loss  4.08 | ppl    59.43\n",
            "| epoch  20 |    80/  257 batches | lr 10.00 | ms/batch 52.57 | loss  4.05 | ppl    57.60\n",
            "| epoch  20 |    90/  257 batches | lr 10.00 | ms/batch 52.40 | loss  4.12 | ppl    61.62\n",
            "| epoch  20 |   100/  257 batches | lr 10.00 | ms/batch 52.68 | loss  4.11 | ppl    61.04\n",
            "| epoch  20 |   110/  257 batches | lr 10.00 | ms/batch 52.79 | loss  4.07 | ppl    58.40\n",
            "| epoch  20 |   120/  257 batches | lr 10.00 | ms/batch 52.74 | loss  4.08 | ppl    59.15\n",
            "| epoch  20 |   130/  257 batches | lr 10.00 | ms/batch 52.33 | loss  4.10 | ppl    60.43\n",
            "| epoch  20 |   140/  257 batches | lr 10.00 | ms/batch 52.57 | loss  4.05 | ppl    57.58\n",
            "| epoch  20 |   150/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.05 | ppl    57.22\n",
            "| epoch  20 |   160/  257 batches | lr 10.00 | ms/batch 52.23 | loss  4.07 | ppl    58.40\n",
            "| epoch  20 |   170/  257 batches | lr 10.00 | ms/batch 52.14 | loss  4.08 | ppl    59.22\n",
            "| epoch  20 |   180/  257 batches | lr 10.00 | ms/batch 52.73 | loss  4.09 | ppl    59.65\n",
            "| epoch  20 |   190/  257 batches | lr 10.00 | ms/batch 52.72 | loss  4.08 | ppl    59.40\n",
            "| epoch  20 |   200/  257 batches | lr 10.00 | ms/batch 52.39 | loss  4.06 | ppl    57.86\n",
            "| epoch  20 |   210/  257 batches | lr 10.00 | ms/batch 52.45 | loss  4.01 | ppl    55.02\n",
            "| epoch  20 |   220/  257 batches | lr 10.00 | ms/batch 51.96 | loss  4.06 | ppl    58.18\n",
            "| epoch  20 |   230/  257 batches | lr 10.00 | ms/batch 52.83 | loss  4.06 | ppl    57.95\n",
            "| epoch  20 |   240/  257 batches | lr 10.00 | ms/batch 52.42 | loss  4.07 | ppl    58.63\n",
            "| epoch  20 |   250/  257 batches | lr 10.00 | ms/batch 52.38 | loss  4.09 | ppl    59.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 15.68s | valid loss  4.30 | valid ppl    74.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |    10/  257 batches | lr 10.00 | ms/batch 55.70 | loss  4.52 | ppl    92.27\n",
            "| epoch  21 |    20/  257 batches | lr 10.00 | ms/batch 53.70 | loss  4.10 | ppl    60.30\n",
            "| epoch  21 |    30/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.07 | ppl    58.72\n",
            "| epoch  21 |    40/  257 batches | lr 10.00 | ms/batch 53.11 | loss  4.08 | ppl    59.26\n",
            "| epoch  21 |    50/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.08 | ppl    59.24\n",
            "| epoch  21 |    60/  257 batches | lr 10.00 | ms/batch 52.81 | loss  4.05 | ppl    57.55\n",
            "| epoch  21 |    70/  257 batches | lr 10.00 | ms/batch 51.88 | loss  4.06 | ppl    58.11\n",
            "| epoch  21 |    80/  257 batches | lr 10.00 | ms/batch 52.74 | loss  4.04 | ppl    56.76\n",
            "| epoch  21 |    90/  257 batches | lr 10.00 | ms/batch 52.10 | loss  4.10 | ppl    60.32\n",
            "| epoch  21 |   100/  257 batches | lr 10.00 | ms/batch 52.58 | loss  4.09 | ppl    59.60\n",
            "| epoch  21 |   110/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.05 | ppl    57.62\n",
            "| epoch  21 |   120/  257 batches | lr 10.00 | ms/batch 52.43 | loss  4.06 | ppl    58.01\n",
            "| epoch  21 |   130/  257 batches | lr 10.00 | ms/batch 52.18 | loss  4.08 | ppl    59.43\n",
            "| epoch  21 |   140/  257 batches | lr 10.00 | ms/batch 52.56 | loss  4.03 | ppl    56.45\n",
            "| epoch  21 |   150/  257 batches | lr 10.00 | ms/batch 52.58 | loss  4.04 | ppl    56.94\n",
            "| epoch  21 |   160/  257 batches | lr 10.00 | ms/batch 52.56 | loss  4.04 | ppl    57.06\n",
            "| epoch  21 |   170/  257 batches | lr 10.00 | ms/batch 52.27 | loss  4.07 | ppl    58.41\n",
            "| epoch  21 |   180/  257 batches | lr 10.00 | ms/batch 52.26 | loss  4.07 | ppl    58.46\n",
            "| epoch  21 |   190/  257 batches | lr 10.00 | ms/batch 52.54 | loss  4.06 | ppl    58.17\n",
            "| epoch  21 |   200/  257 batches | lr 10.00 | ms/batch 52.63 | loss  4.04 | ppl    56.86\n",
            "| epoch  21 |   210/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.99 | ppl    54.03\n",
            "| epoch  21 |   220/  257 batches | lr 10.00 | ms/batch 51.84 | loss  4.04 | ppl    57.00\n",
            "| epoch  21 |   230/  257 batches | lr 10.00 | ms/batch 52.63 | loss  4.04 | ppl    56.80\n",
            "| epoch  21 |   240/  257 batches | lr 10.00 | ms/batch 51.81 | loss  4.06 | ppl    57.69\n",
            "| epoch  21 |   250/  257 batches | lr 10.00 | ms/batch 52.42 | loss  4.07 | ppl    58.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 15.67s | valid loss  4.29 | valid ppl    73.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |    10/  257 batches | lr 10.00 | ms/batch 56.44 | loss  4.50 | ppl    90.42\n",
            "| epoch  22 |    20/  257 batches | lr 10.00 | ms/batch 54.15 | loss  4.07 | ppl    58.27\n",
            "| epoch  22 |    30/  257 batches | lr 10.00 | ms/batch 51.80 | loss  4.05 | ppl    57.58\n",
            "| epoch  22 |    40/  257 batches | lr 10.00 | ms/batch 52.86 | loss  4.06 | ppl    58.16\n",
            "| epoch  22 |    50/  257 batches | lr 10.00 | ms/batch 51.90 | loss  4.05 | ppl    57.53\n",
            "| epoch  22 |    60/  257 batches | lr 10.00 | ms/batch 53.17 | loss  4.04 | ppl    56.62\n",
            "| epoch  22 |    70/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.03 | ppl    56.26\n",
            "| epoch  22 |    80/  257 batches | lr 10.00 | ms/batch 53.07 | loss  4.02 | ppl    55.66\n",
            "| epoch  22 |    90/  257 batches | lr 10.00 | ms/batch 52.72 | loss  4.08 | ppl    59.04\n",
            "| epoch  22 |   100/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.07 | ppl    58.44\n",
            "| epoch  22 |   110/  257 batches | lr 10.00 | ms/batch 52.43 | loss  4.05 | ppl    57.12\n",
            "| epoch  22 |   120/  257 batches | lr 10.00 | ms/batch 52.62 | loss  4.05 | ppl    57.23\n",
            "| epoch  22 |   130/  257 batches | lr 10.00 | ms/batch 52.24 | loss  4.06 | ppl    58.23\n",
            "| epoch  22 |   140/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.00 | ppl    54.71\n",
            "| epoch  22 |   150/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.03 | ppl    56.04\n",
            "| epoch  22 |   160/  257 batches | lr 10.00 | ms/batch 52.45 | loss  4.03 | ppl    56.14\n",
            "| epoch  22 |   170/  257 batches | lr 10.00 | ms/batch 52.64 | loss  4.06 | ppl    57.69\n",
            "| epoch  22 |   180/  257 batches | lr 10.00 | ms/batch 52.58 | loss  4.06 | ppl    57.80\n",
            "| epoch  22 |   190/  257 batches | lr 10.00 | ms/batch 52.24 | loss  4.05 | ppl    57.24\n",
            "| epoch  22 |   200/  257 batches | lr 10.00 | ms/batch 52.53 | loss  4.02 | ppl    55.71\n",
            "| epoch  22 |   210/  257 batches | lr 10.00 | ms/batch 52.34 | loss  3.98 | ppl    53.30\n",
            "| epoch  22 |   220/  257 batches | lr 10.00 | ms/batch 52.24 | loss  4.02 | ppl    55.75\n",
            "| epoch  22 |   230/  257 batches | lr 10.00 | ms/batch 52.57 | loss  4.02 | ppl    55.81\n",
            "| epoch  22 |   240/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.03 | ppl    56.33\n",
            "| epoch  22 |   250/  257 batches | lr 10.00 | ms/batch 52.33 | loss  4.06 | ppl    57.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 15.71s | valid loss  4.29 | valid ppl    72.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |    10/  257 batches | lr 10.00 | ms/batch 55.80 | loss  4.49 | ppl    88.97\n",
            "| epoch  23 |    20/  257 batches | lr 10.00 | ms/batch 53.54 | loss  4.05 | ppl    57.60\n",
            "| epoch  23 |    30/  257 batches | lr 10.00 | ms/batch 51.90 | loss  4.04 | ppl    56.81\n",
            "| epoch  23 |    40/  257 batches | lr 10.00 | ms/batch 53.11 | loss  4.04 | ppl    56.98\n",
            "| epoch  23 |    50/  257 batches | lr 10.00 | ms/batch 52.19 | loss  4.04 | ppl    57.00\n",
            "| epoch  23 |    60/  257 batches | lr 10.00 | ms/batch 52.49 | loss  4.02 | ppl    55.47\n",
            "| epoch  23 |    70/  257 batches | lr 10.00 | ms/batch 52.36 | loss  4.02 | ppl    55.85\n",
            "| epoch  23 |    80/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.00 | ppl    54.86\n",
            "| epoch  23 |    90/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.06 | ppl    57.96\n",
            "| epoch  23 |   100/  257 batches | lr 10.00 | ms/batch 52.63 | loss  4.05 | ppl    57.58\n",
            "| epoch  23 |   110/  257 batches | lr 10.00 | ms/batch 52.29 | loss  4.02 | ppl    55.47\n",
            "| epoch  23 |   120/  257 batches | lr 10.00 | ms/batch 52.48 | loss  4.02 | ppl    55.91\n",
            "| epoch  23 |   130/  257 batches | lr 10.00 | ms/batch 52.65 | loss  4.05 | ppl    57.16\n",
            "| epoch  23 |   140/  257 batches | lr 10.00 | ms/batch 51.95 | loss  3.99 | ppl    54.08\n",
            "| epoch  23 |   150/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.99 | ppl    54.28\n",
            "| epoch  23 |   160/  257 batches | lr 10.00 | ms/batch 52.53 | loss  4.02 | ppl    55.55\n",
            "| epoch  23 |   170/  257 batches | lr 10.00 | ms/batch 52.59 | loss  4.03 | ppl    56.07\n",
            "| epoch  23 |   180/  257 batches | lr 10.00 | ms/batch 51.86 | loss  4.04 | ppl    56.64\n",
            "| epoch  23 |   190/  257 batches | lr 10.00 | ms/batch 52.67 | loss  4.03 | ppl    56.21\n",
            "| epoch  23 |   200/  257 batches | lr 10.00 | ms/batch 52.47 | loss  4.01 | ppl    54.97\n",
            "| epoch  23 |   210/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.95 | ppl    52.14\n",
            "| epoch  23 |   220/  257 batches | lr 10.00 | ms/batch 52.08 | loss  4.01 | ppl    54.99\n",
            "| epoch  23 |   230/  257 batches | lr 10.00 | ms/batch 52.49 | loss  4.01 | ppl    55.00\n",
            "| epoch  23 |   240/  257 batches | lr 10.00 | ms/batch 51.49 | loss  4.02 | ppl    55.78\n",
            "| epoch  23 |   250/  257 batches | lr 10.00 | ms/batch 52.91 | loss  4.04 | ppl    56.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 15.67s | valid loss  4.27 | valid ppl    71.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |    10/  257 batches | lr 10.00 | ms/batch 56.31 | loss  4.47 | ppl    87.44\n",
            "| epoch  24 |    20/  257 batches | lr 10.00 | ms/batch 53.86 | loss  4.04 | ppl    56.63\n",
            "| epoch  24 |    30/  257 batches | lr 10.00 | ms/batch 51.57 | loss  4.02 | ppl    55.68\n",
            "| epoch  24 |    40/  257 batches | lr 10.00 | ms/batch 52.79 | loss  4.02 | ppl    55.92\n",
            "| epoch  24 |    50/  257 batches | lr 10.00 | ms/batch 51.90 | loss  4.04 | ppl    56.58\n",
            "| epoch  24 |    60/  257 batches | lr 10.00 | ms/batch 52.72 | loss  4.00 | ppl    54.58\n",
            "| epoch  24 |    70/  257 batches | lr 10.00 | ms/batch 52.04 | loss  4.01 | ppl    54.99\n",
            "| epoch  24 |    80/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.99 | ppl    53.89\n",
            "| epoch  24 |    90/  257 batches | lr 10.00 | ms/batch 52.81 | loss  4.04 | ppl    57.06\n",
            "| epoch  24 |   100/  257 batches | lr 10.00 | ms/batch 52.68 | loss  4.03 | ppl    56.28\n",
            "| epoch  24 |   110/  257 batches | lr 10.00 | ms/batch 52.39 | loss  3.99 | ppl    54.12\n",
            "| epoch  24 |   120/  257 batches | lr 10.00 | ms/batch 51.86 | loss  4.01 | ppl    55.02\n",
            "| epoch  24 |   130/  257 batches | lr 10.00 | ms/batch 52.21 | loss  4.03 | ppl    56.29\n",
            "| epoch  24 |   140/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.98 | ppl    53.51\n",
            "| epoch  24 |   150/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.99 | ppl    53.93\n",
            "| epoch  24 |   160/  257 batches | lr 10.00 | ms/batch 52.83 | loss  3.99 | ppl    54.30\n",
            "| epoch  24 |   170/  257 batches | lr 10.00 | ms/batch 51.97 | loss  4.01 | ppl    55.16\n",
            "| epoch  24 |   180/  257 batches | lr 10.00 | ms/batch 52.59 | loss  4.02 | ppl    55.51\n",
            "| epoch  24 |   190/  257 batches | lr 10.00 | ms/batch 52.18 | loss  4.01 | ppl    55.08\n",
            "| epoch  24 |   200/  257 batches | lr 10.00 | ms/batch 52.50 | loss  4.00 | ppl    54.41\n",
            "| epoch  24 |   210/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.93 | ppl    50.96\n",
            "| epoch  24 |   220/  257 batches | lr 10.00 | ms/batch 52.42 | loss  4.00 | ppl    54.46\n",
            "| epoch  24 |   230/  257 batches | lr 10.00 | ms/batch 52.50 | loss  4.00 | ppl    54.36\n",
            "| epoch  24 |   240/  257 batches | lr 10.00 | ms/batch 52.22 | loss  3.99 | ppl    54.29\n",
            "| epoch  24 |   250/  257 batches | lr 10.00 | ms/batch 52.95 | loss  4.03 | ppl    56.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 15.69s | valid loss  4.26 | valid ppl    71.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |    10/  257 batches | lr 10.00 | ms/batch 55.79 | loss  4.45 | ppl    86.02\n",
            "| epoch  25 |    20/  257 batches | lr 10.00 | ms/batch 54.14 | loss  4.02 | ppl    55.79\n",
            "| epoch  25 |    30/  257 batches | lr 10.00 | ms/batch 51.97 | loss  4.01 | ppl    55.04\n",
            "| epoch  25 |    40/  257 batches | lr 10.00 | ms/batch 52.71 | loss  4.01 | ppl    54.93\n",
            "| epoch  25 |    50/  257 batches | lr 10.00 | ms/batch 51.68 | loss  4.01 | ppl    55.35\n",
            "| epoch  25 |    60/  257 batches | lr 10.00 | ms/batch 52.90 | loss  3.99 | ppl    53.91\n",
            "| epoch  25 |    70/  257 batches | lr 10.00 | ms/batch 52.37 | loss  3.99 | ppl    54.20\n",
            "| epoch  25 |    80/  257 batches | lr 10.00 | ms/batch 52.67 | loss  3.98 | ppl    53.25\n",
            "| epoch  25 |    90/  257 batches | lr 10.00 | ms/batch 52.20 | loss  4.03 | ppl    56.06\n",
            "| epoch  25 |   100/  257 batches | lr 10.00 | ms/batch 52.68 | loss  4.03 | ppl    56.45\n",
            "| epoch  25 |   110/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.99 | ppl    53.95\n",
            "| epoch  25 |   120/  257 batches | lr 10.00 | ms/batch 52.44 | loss  4.00 | ppl    54.67\n",
            "| epoch  25 |   130/  257 batches | lr 10.00 | ms/batch 52.71 | loss  4.01 | ppl    55.23\n",
            "| epoch  25 |   140/  257 batches | lr 10.00 | ms/batch 52.39 | loss  3.96 | ppl    52.71\n",
            "| epoch  25 |   150/  257 batches | lr 10.00 | ms/batch 52.30 | loss  3.96 | ppl    52.65\n",
            "| epoch  25 |   160/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.98 | ppl    53.73\n",
            "| epoch  25 |   170/  257 batches | lr 10.00 | ms/batch 52.04 | loss  4.00 | ppl    54.50\n",
            "| epoch  25 |   180/  257 batches | lr 10.00 | ms/batch 52.46 | loss  4.00 | ppl    54.67\n",
            "| epoch  25 |   190/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.99 | ppl    54.23\n",
            "| epoch  25 |   200/  257 batches | lr 10.00 | ms/batch 52.39 | loss  3.98 | ppl    53.39\n",
            "| epoch  25 |   210/  257 batches | lr 10.00 | ms/batch 52.55 | loss  3.92 | ppl    50.47\n",
            "| epoch  25 |   220/  257 batches | lr 10.00 | ms/batch 51.87 | loss  3.98 | ppl    53.53\n",
            "| epoch  25 |   230/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.98 | ppl    53.68\n",
            "| epoch  25 |   240/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.98 | ppl    53.59\n",
            "| epoch  25 |   250/  257 batches | lr 10.00 | ms/batch 52.62 | loss  4.01 | ppl    54.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 15.69s | valid loss  4.26 | valid ppl    70.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |    10/  257 batches | lr 10.00 | ms/batch 56.58 | loss  4.43 | ppl    83.70\n",
            "| epoch  26 |    20/  257 batches | lr 10.00 | ms/batch 53.19 | loss  4.01 | ppl    55.08\n",
            "| epoch  26 |    30/  257 batches | lr 10.00 | ms/batch 52.20 | loss  3.99 | ppl    54.33\n",
            "| epoch  26 |    40/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.99 | ppl    54.07\n",
            "| epoch  26 |    50/  257 batches | lr 10.00 | ms/batch 52.23 | loss  4.00 | ppl    54.53\n",
            "| epoch  26 |    60/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.98 | ppl    53.42\n",
            "| epoch  26 |    70/  257 batches | lr 10.00 | ms/batch 52.04 | loss  3.98 | ppl    53.39\n",
            "| epoch  26 |    80/  257 batches | lr 10.00 | ms/batch 52.79 | loss  3.96 | ppl    52.42\n",
            "| epoch  26 |    90/  257 batches | lr 10.00 | ms/batch 52.60 | loss  4.01 | ppl    55.35\n",
            "| epoch  26 |   100/  257 batches | lr 10.00 | ms/batch 52.38 | loss  4.01 | ppl    55.30\n",
            "| epoch  26 |   110/  257 batches | lr 10.00 | ms/batch 52.46 | loss  3.97 | ppl    52.87\n",
            "| epoch  26 |   120/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.99 | ppl    53.91\n",
            "| epoch  26 |   130/  257 batches | lr 10.00 | ms/batch 52.22 | loss  4.00 | ppl    54.74\n",
            "| epoch  26 |   140/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.95 | ppl    51.94\n",
            "| epoch  26 |   150/  257 batches | lr 10.00 | ms/batch 52.73 | loss  3.96 | ppl    52.63\n",
            "| epoch  26 |   160/  257 batches | lr 10.00 | ms/batch 52.27 | loss  3.97 | ppl    52.91\n",
            "| epoch  26 |   170/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.98 | ppl    53.32\n",
            "| epoch  26 |   180/  257 batches | lr 10.00 | ms/batch 52.32 | loss  3.99 | ppl    54.15\n",
            "| epoch  26 |   190/  257 batches | lr 10.00 | ms/batch 52.43 | loss  3.99 | ppl    54.03\n",
            "| epoch  26 |   200/  257 batches | lr 10.00 | ms/batch 52.19 | loss  3.96 | ppl    52.45\n",
            "| epoch  26 |   210/  257 batches | lr 10.00 | ms/batch 52.23 | loss  3.91 | ppl    49.86\n",
            "| epoch  26 |   220/  257 batches | lr 10.00 | ms/batch 52.04 | loss  3.97 | ppl    52.87\n",
            "| epoch  26 |   230/  257 batches | lr 10.00 | ms/batch 52.56 | loss  3.97 | ppl    52.82\n",
            "| epoch  26 |   240/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.98 | ppl    53.28\n",
            "| epoch  26 |   250/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.99 | ppl    54.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 15.66s | valid loss  4.25 | valid ppl    69.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |    10/  257 batches | lr 10.00 | ms/batch 55.82 | loss  4.42 | ppl    83.21\n",
            "| epoch  27 |    20/  257 batches | lr 10.00 | ms/batch 54.54 | loss  4.00 | ppl    54.45\n",
            "| epoch  27 |    30/  257 batches | lr 10.00 | ms/batch 51.80 | loss  3.98 | ppl    53.48\n",
            "| epoch  27 |    40/  257 batches | lr 10.00 | ms/batch 53.31 | loss  3.98 | ppl    53.37\n",
            "| epoch  27 |    50/  257 batches | lr 10.00 | ms/batch 52.08 | loss  3.99 | ppl    54.14\n",
            "| epoch  27 |    60/  257 batches | lr 10.00 | ms/batch 52.34 | loss  3.95 | ppl    52.19\n",
            "| epoch  27 |    70/  257 batches | lr 10.00 | ms/batch 52.02 | loss  3.96 | ppl    52.43\n",
            "| epoch  27 |    80/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.95 | ppl    51.71\n",
            "| epoch  27 |    90/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.99 | ppl    54.25\n",
            "| epoch  27 |   100/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.99 | ppl    53.84\n",
            "| epoch  27 |   110/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.96 | ppl    52.47\n",
            "| epoch  27 |   120/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.97 | ppl    52.77\n",
            "| epoch  27 |   130/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.99 | ppl    53.82\n",
            "| epoch  27 |   140/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.94 | ppl    51.32\n",
            "| epoch  27 |   150/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.94 | ppl    51.42\n",
            "| epoch  27 |   160/  257 batches | lr 10.00 | ms/batch 51.77 | loss  3.96 | ppl    52.52\n",
            "| epoch  27 |   170/  257 batches | lr 10.00 | ms/batch 52.46 | loss  3.97 | ppl    52.84\n",
            "| epoch  27 |   180/  257 batches | lr 10.00 | ms/batch 51.86 | loss  3.97 | ppl    53.21\n",
            "| epoch  27 |   190/  257 batches | lr 10.00 | ms/batch 52.36 | loss  3.98 | ppl    53.30\n",
            "| epoch  27 |   200/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.95 | ppl    52.02\n",
            "| epoch  27 |   210/  257 batches | lr 10.00 | ms/batch 52.07 | loss  3.90 | ppl    49.18\n",
            "| epoch  27 |   220/  257 batches | lr 10.00 | ms/batch 52.35 | loss  3.96 | ppl    52.64\n",
            "| epoch  27 |   230/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.96 | ppl    52.32\n",
            "| epoch  27 |   240/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.95 | ppl    52.12\n",
            "| epoch  27 |   250/  257 batches | lr 10.00 | ms/batch 52.19 | loss  3.97 | ppl    52.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 15.65s | valid loss  4.24 | valid ppl    69.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |    10/  257 batches | lr 10.00 | ms/batch 56.17 | loss  4.40 | ppl    81.65\n",
            "| epoch  28 |    20/  257 batches | lr 10.00 | ms/batch 53.85 | loss  3.98 | ppl    53.48\n",
            "| epoch  28 |    30/  257 batches | lr 10.00 | ms/batch 50.61 | loss  3.97 | ppl    52.83\n",
            "| epoch  28 |    40/  257 batches | lr 10.00 | ms/batch 53.05 | loss  3.97 | ppl    52.92\n",
            "| epoch  28 |    50/  257 batches | lr 10.00 | ms/batch 52.10 | loss  3.97 | ppl    53.05\n",
            "| epoch  28 |    60/  257 batches | lr 10.00 | ms/batch 52.84 | loss  3.94 | ppl    51.51\n",
            "| epoch  28 |    70/  257 batches | lr 10.00 | ms/batch 52.15 | loss  3.94 | ppl    51.50\n",
            "| epoch  28 |    80/  257 batches | lr 10.00 | ms/batch 52.93 | loss  3.94 | ppl    51.29\n",
            "| epoch  28 |    90/  257 batches | lr 10.00 | ms/batch 52.25 | loss  3.99 | ppl    54.11\n",
            "| epoch  28 |   100/  257 batches | lr 10.00 | ms/batch 52.21 | loss  3.99 | ppl    54.01\n",
            "| epoch  28 |   110/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.94 | ppl    51.50\n",
            "| epoch  28 |   120/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.96 | ppl    52.48\n",
            "| epoch  28 |   130/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.97 | ppl    52.97\n",
            "| epoch  28 |   140/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.92 | ppl    50.18\n",
            "| epoch  28 |   150/  257 batches | lr 10.00 | ms/batch 52.12 | loss  3.94 | ppl    51.41\n",
            "| epoch  28 |   160/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.95 | ppl    51.71\n",
            "| epoch  28 |   170/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.95 | ppl    52.07\n",
            "| epoch  28 |   180/  257 batches | lr 10.00 | ms/batch 52.27 | loss  3.96 | ppl    52.48\n",
            "| epoch  28 |   190/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.96 | ppl    52.39\n",
            "| epoch  28 |   200/  257 batches | lr 10.00 | ms/batch 52.36 | loss  3.94 | ppl    51.59\n",
            "| epoch  28 |   210/  257 batches | lr 10.00 | ms/batch 52.78 | loss  3.89 | ppl    48.76\n",
            "| epoch  28 |   220/  257 batches | lr 10.00 | ms/batch 52.17 | loss  3.94 | ppl    51.49\n",
            "| epoch  28 |   230/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.94 | ppl    51.54\n",
            "| epoch  28 |   240/  257 batches | lr 10.00 | ms/batch 52.41 | loss  3.95 | ppl    52.08\n",
            "| epoch  28 |   250/  257 batches | lr 10.00 | ms/batch 52.97 | loss  3.97 | ppl    52.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 15.67s | valid loss  4.23 | valid ppl    68.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |    10/  257 batches | lr 10.00 | ms/batch 56.43 | loss  4.39 | ppl    80.34\n",
            "| epoch  29 |    20/  257 batches | lr 10.00 | ms/batch 53.96 | loss  3.97 | ppl    52.86\n",
            "| epoch  29 |    30/  257 batches | lr 10.00 | ms/batch 51.65 | loss  3.94 | ppl    51.66\n",
            "| epoch  29 |    40/  257 batches | lr 10.00 | ms/batch 53.34 | loss  3.96 | ppl    52.46\n",
            "| epoch  29 |    50/  257 batches | lr 10.00 | ms/batch 51.61 | loss  3.97 | ppl    53.15\n",
            "| epoch  29 |    60/  257 batches | lr 10.00 | ms/batch 52.72 | loss  3.93 | ppl    51.09\n",
            "| epoch  29 |    70/  257 batches | lr 10.00 | ms/batch 52.43 | loss  3.93 | ppl    50.69\n",
            "| epoch  29 |    80/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.92 | ppl    50.34\n",
            "| epoch  29 |    90/  257 batches | lr 10.00 | ms/batch 52.41 | loss  3.99 | ppl    53.90\n",
            "| epoch  29 |   100/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.98 | ppl    53.39\n",
            "| epoch  29 |   110/  257 batches | lr 10.00 | ms/batch 52.32 | loss  3.94 | ppl    51.17\n",
            "| epoch  29 |   120/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.95 | ppl    51.97\n",
            "| epoch  29 |   130/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.96 | ppl    52.34\n",
            "| epoch  29 |   140/  257 batches | lr 10.00 | ms/batch 52.41 | loss  3.90 | ppl    49.54\n",
            "| epoch  29 |   150/  257 batches | lr 10.00 | ms/batch 52.39 | loss  3.92 | ppl    50.42\n",
            "| epoch  29 |   160/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.93 | ppl    50.67\n",
            "| epoch  29 |   170/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.94 | ppl    51.64\n",
            "| epoch  29 |   180/  257 batches | lr 10.00 | ms/batch 51.88 | loss  3.94 | ppl    51.57\n",
            "| epoch  29 |   190/  257 batches | lr 10.00 | ms/batch 52.68 | loss  3.95 | ppl    52.17\n",
            "| epoch  29 |   200/  257 batches | lr 10.00 | ms/batch 52.37 | loss  3.92 | ppl    50.54\n",
            "| epoch  29 |   210/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.87 | ppl    47.91\n",
            "| epoch  29 |   220/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.94 | ppl    51.30\n",
            "| epoch  29 |   230/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.92 | ppl    50.46\n",
            "| epoch  29 |   240/  257 batches | lr 10.00 | ms/batch 52.70 | loss  3.93 | ppl    51.09\n",
            "| epoch  29 |   250/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.95 | ppl    52.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 15.68s | valid loss  4.23 | valid ppl    68.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |    10/  257 batches | lr 10.00 | ms/batch 56.19 | loss  4.38 | ppl    79.55\n",
            "| epoch  30 |    20/  257 batches | lr 10.00 | ms/batch 53.42 | loss  3.96 | ppl    52.47\n",
            "| epoch  30 |    30/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.94 | ppl    51.28\n",
            "| epoch  30 |    40/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.95 | ppl    51.76\n",
            "| epoch  30 |    50/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.95 | ppl    51.85\n",
            "| epoch  30 |    60/  257 batches | lr 10.00 | ms/batch 52.28 | loss  3.93 | ppl    50.70\n",
            "| epoch  30 |    70/  257 batches | lr 10.00 | ms/batch 52.33 | loss  3.92 | ppl    50.54\n",
            "| epoch  30 |    80/  257 batches | lr 10.00 | ms/batch 52.67 | loss  3.90 | ppl    49.63\n",
            "| epoch  30 |    90/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.97 | ppl    52.81\n",
            "| epoch  30 |   100/  257 batches | lr 10.00 | ms/batch 52.09 | loss  3.96 | ppl    52.66\n",
            "| epoch  30 |   110/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.91 | ppl    50.01\n",
            "| epoch  30 |   120/  257 batches | lr 10.00 | ms/batch 52.34 | loss  3.94 | ppl    51.44\n",
            "| epoch  30 |   130/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.95 | ppl    51.84\n",
            "| epoch  30 |   140/  257 batches | lr 10.00 | ms/batch 52.70 | loss  3.90 | ppl    49.31\n",
            "| epoch  30 |   150/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.91 | ppl    49.69\n",
            "| epoch  30 |   160/  257 batches | lr 10.00 | ms/batch 52.62 | loss  3.92 | ppl    50.56\n",
            "| epoch  30 |   170/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.94 | ppl    51.35\n",
            "| epoch  30 |   180/  257 batches | lr 10.00 | ms/batch 52.14 | loss  3.94 | ppl    51.55\n",
            "| epoch  30 |   190/  257 batches | lr 10.00 | ms/batch 52.87 | loss  3.94 | ppl    51.29\n",
            "| epoch  30 |   200/  257 batches | lr 10.00 | ms/batch 52.48 | loss  3.92 | ppl    50.27\n",
            "| epoch  30 |   210/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.86 | ppl    47.41\n",
            "| epoch  30 |   220/  257 batches | lr 10.00 | ms/batch 52.83 | loss  3.92 | ppl    50.36\n",
            "| epoch  30 |   230/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.91 | ppl    49.86\n",
            "| epoch  30 |   240/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.92 | ppl    50.64\n",
            "| epoch  30 |   250/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.95 | ppl    51.74\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 15.70s | valid loss  4.23 | valid ppl    68.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  31 |    10/  257 batches | lr 10.00 | ms/batch 56.39 | loss  4.37 | ppl    79.19\n",
            "| epoch  31 |    20/  257 batches | lr 10.00 | ms/batch 53.80 | loss  3.94 | ppl    51.46\n",
            "| epoch  31 |    30/  257 batches | lr 10.00 | ms/batch 51.49 | loss  3.92 | ppl    50.42\n",
            "| epoch  31 |    40/  257 batches | lr 10.00 | ms/batch 52.82 | loss  3.93 | ppl    50.73\n",
            "| epoch  31 |    50/  257 batches | lr 10.00 | ms/batch 52.35 | loss  3.93 | ppl    50.69\n",
            "| epoch  31 |    60/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.91 | ppl    49.93\n",
            "| epoch  31 |    70/  257 batches | lr 10.00 | ms/batch 52.15 | loss  3.92 | ppl    50.26\n",
            "| epoch  31 |    80/  257 batches | lr 10.00 | ms/batch 52.92 | loss  3.91 | ppl    49.67\n",
            "| epoch  31 |    90/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.95 | ppl    51.85\n",
            "| epoch  31 |   100/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.96 | ppl    52.25\n",
            "| epoch  31 |   110/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.91 | ppl    49.88\n",
            "| epoch  31 |   120/  257 batches | lr 10.00 | ms/batch 52.62 | loss  3.93 | ppl    50.70\n",
            "| epoch  31 |   130/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.93 | ppl    51.13\n",
            "| epoch  31 |   140/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.89 | ppl    48.91\n",
            "| epoch  31 |   150/  257 batches | lr 10.00 | ms/batch 52.76 | loss  3.89 | ppl    48.83\n",
            "| epoch  31 |   160/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.91 | ppl    49.83\n",
            "| epoch  31 |   170/  257 batches | lr 10.00 | ms/batch 52.72 | loss  3.92 | ppl    50.64\n",
            "| epoch  31 |   180/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.93 | ppl    50.74\n",
            "| epoch  31 |   190/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.93 | ppl    50.98\n",
            "| epoch  31 |   200/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.90 | ppl    49.49\n",
            "| epoch  31 |   210/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.85 | ppl    47.13\n",
            "| epoch  31 |   220/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.91 | ppl    49.70\n",
            "| epoch  31 |   230/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.91 | ppl    49.83\n",
            "| epoch  31 |   240/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.91 | ppl    50.05\n",
            "| epoch  31 |   250/  257 batches | lr 10.00 | ms/batch 52.84 | loss  3.94 | ppl    51.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 15.70s | valid loss  4.22 | valid ppl    68.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |    10/  257 batches | lr 10.00 | ms/batch 55.95 | loss  4.35 | ppl    77.14\n",
            "| epoch  32 |    20/  257 batches | lr 10.00 | ms/batch 54.10 | loss  3.93 | ppl    51.13\n",
            "| epoch  32 |    30/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.92 | ppl    50.21\n",
            "| epoch  32 |    40/  257 batches | lr 10.00 | ms/batch 52.18 | loss  3.91 | ppl    50.08\n",
            "| epoch  32 |    50/  257 batches | lr 10.00 | ms/batch 52.68 | loss  3.93 | ppl    50.78\n",
            "| epoch  32 |    60/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.90 | ppl    49.53\n",
            "| epoch  32 |    70/  257 batches | lr 10.00 | ms/batch 52.69 | loss  3.90 | ppl    49.40\n",
            "| epoch  32 |    80/  257 batches | lr 10.00 | ms/batch 52.56 | loss  3.88 | ppl    48.65\n",
            "| epoch  32 |    90/  257 batches | lr 10.00 | ms/batch 52.75 | loss  3.93 | ppl    51.00\n",
            "| epoch  32 |   100/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.94 | ppl    51.29\n",
            "| epoch  32 |   110/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.90 | ppl    49.27\n",
            "| epoch  32 |   120/  257 batches | lr 10.00 | ms/batch 52.99 | loss  3.91 | ppl    50.00\n",
            "| epoch  32 |   130/  257 batches | lr 10.00 | ms/batch 52.27 | loss  3.93 | ppl    50.70\n",
            "| epoch  32 |   140/  257 batches | lr 10.00 | ms/batch 52.77 | loss  3.87 | ppl    47.82\n",
            "| epoch  32 |   150/  257 batches | lr 10.00 | ms/batch 52.56 | loss  3.89 | ppl    48.90\n",
            "| epoch  32 |   160/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.90 | ppl    49.40\n",
            "| epoch  32 |   170/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.91 | ppl    49.89\n",
            "| epoch  32 |   180/  257 batches | lr 10.00 | ms/batch 52.32 | loss  3.92 | ppl    50.46\n",
            "| epoch  32 |   190/  257 batches | lr 10.00 | ms/batch 52.04 | loss  3.91 | ppl    49.94\n",
            "| epoch  32 |   200/  257 batches | lr 10.00 | ms/batch 52.68 | loss  3.89 | ppl    48.94\n",
            "| epoch  32 |   210/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.85 | ppl    46.86\n",
            "| epoch  32 |   220/  257 batches | lr 10.00 | ms/batch 52.95 | loss  3.90 | ppl    49.32\n",
            "| epoch  32 |   230/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.90 | ppl    49.18\n",
            "| epoch  32 |   240/  257 batches | lr 10.00 | ms/batch 52.85 | loss  3.90 | ppl    49.39\n",
            "| epoch  32 |   250/  257 batches | lr 10.00 | ms/batch 52.48 | loss  3.93 | ppl    50.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 15.71s | valid loss  4.21 | valid ppl    67.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |    10/  257 batches | lr 10.00 | ms/batch 56.22 | loss  4.34 | ppl    76.75\n",
            "| epoch  33 |    20/  257 batches | lr 10.00 | ms/batch 53.39 | loss  3.93 | ppl    50.90\n",
            "| epoch  33 |    30/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.90 | ppl    49.65\n",
            "| epoch  33 |    40/  257 batches | lr 10.00 | ms/batch 52.77 | loss  3.92 | ppl    50.26\n",
            "| epoch  33 |    50/  257 batches | lr 10.00 | ms/batch 52.07 | loss  3.91 | ppl    50.12\n",
            "| epoch  33 |    60/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.89 | ppl    49.14\n",
            "| epoch  33 |    70/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.90 | ppl    49.29\n",
            "| epoch  33 |    80/  257 batches | lr 10.00 | ms/batch 52.67 | loss  3.88 | ppl    48.35\n",
            "| epoch  33 |    90/  257 batches | lr 10.00 | ms/batch 52.07 | loss  3.94 | ppl    51.42\n",
            "| epoch  33 |   100/  257 batches | lr 10.00 | ms/batch 52.36 | loss  3.92 | ppl    50.58\n",
            "| epoch  33 |   110/  257 batches | lr 10.00 | ms/batch 52.69 | loss  3.88 | ppl    48.56\n",
            "| epoch  33 |   120/  257 batches | lr 10.00 | ms/batch 51.95 | loss  3.91 | ppl    49.77\n",
            "| epoch  33 |   130/  257 batches | lr 10.00 | ms/batch 52.82 | loss  3.92 | ppl    50.31\n",
            "| epoch  33 |   140/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.87 | ppl    47.72\n",
            "| epoch  33 |   150/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.88 | ppl    48.46\n",
            "| epoch  33 |   160/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.89 | ppl    48.95\n",
            "| epoch  33 |   170/  257 batches | lr 10.00 | ms/batch 52.75 | loss  3.90 | ppl    49.31\n",
            "| epoch  33 |   180/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.91 | ppl    50.04\n",
            "| epoch  33 |   190/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.91 | ppl    49.66\n",
            "| epoch  33 |   200/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.89 | ppl    49.06\n",
            "| epoch  33 |   210/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.83 | ppl    46.00\n",
            "| epoch  33 |   220/  257 batches | lr 10.00 | ms/batch 51.88 | loss  3.89 | ppl    48.89\n",
            "| epoch  33 |   230/  257 batches | lr 10.00 | ms/batch 53.34 | loss  3.88 | ppl    48.62\n",
            "| epoch  33 |   240/  257 batches | lr 10.00 | ms/batch 52.11 | loss  3.90 | ppl    49.16\n",
            "| epoch  33 |   250/  257 batches | lr 10.00 | ms/batch 52.84 | loss  3.91 | ppl    49.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 15.70s | valid loss  4.21 | valid ppl    67.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |    10/  257 batches | lr 10.00 | ms/batch 56.20 | loss  4.32 | ppl    75.30\n",
            "| epoch  34 |    20/  257 batches | lr 10.00 | ms/batch 53.31 | loss  3.91 | ppl    49.68\n",
            "| epoch  34 |    30/  257 batches | lr 10.00 | ms/batch 52.28 | loss  3.90 | ppl    49.51\n",
            "| epoch  34 |    40/  257 batches | lr 10.00 | ms/batch 52.88 | loss  3.90 | ppl    49.42\n",
            "| epoch  34 |    50/  257 batches | lr 10.00 | ms/batch 51.91 | loss  3.90 | ppl    49.31\n",
            "| epoch  34 |    60/  257 batches | lr 10.00 | ms/batch 53.04 | loss  3.87 | ppl    48.13\n",
            "| epoch  34 |    70/  257 batches | lr 10.00 | ms/batch 52.34 | loss  3.89 | ppl    48.80\n",
            "| epoch  34 |    80/  257 batches | lr 10.00 | ms/batch 52.48 | loss  3.87 | ppl    47.99\n",
            "| epoch  34 |    90/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.91 | ppl    50.04\n",
            "| epoch  34 |   100/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.92 | ppl    50.45\n",
            "| epoch  34 |   110/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.87 | ppl    48.07\n",
            "| epoch  34 |   120/  257 batches | lr 10.00 | ms/batch 53.19 | loss  3.90 | ppl    49.18\n",
            "| epoch  34 |   130/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.90 | ppl    49.44\n",
            "| epoch  34 |   140/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.86 | ppl    47.29\n",
            "| epoch  34 |   150/  257 batches | lr 10.00 | ms/batch 52.37 | loss  3.86 | ppl    47.24\n",
            "| epoch  34 |   160/  257 batches | lr 10.00 | ms/batch 52.67 | loss  3.88 | ppl    48.34\n",
            "| epoch  34 |   170/  257 batches | lr 10.00 | ms/batch 52.45 | loss  3.88 | ppl    48.56\n",
            "| epoch  34 |   180/  257 batches | lr 10.00 | ms/batch 52.91 | loss  3.89 | ppl    48.98\n",
            "| epoch  34 |   190/  257 batches | lr 10.00 | ms/batch 52.29 | loss  3.90 | ppl    49.64\n",
            "| epoch  34 |   200/  257 batches | lr 10.00 | ms/batch 52.55 | loss  3.88 | ppl    48.29\n",
            "| epoch  34 |   210/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.83 | ppl    46.13\n",
            "| epoch  34 |   220/  257 batches | lr 10.00 | ms/batch 52.78 | loss  3.88 | ppl    48.60\n",
            "| epoch  34 |   230/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.88 | ppl    48.59\n",
            "| epoch  34 |   240/  257 batches | lr 10.00 | ms/batch 52.45 | loss  3.88 | ppl    48.47\n",
            "| epoch  34 |   250/  257 batches | lr 10.00 | ms/batch 52.72 | loss  3.90 | ppl    49.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 15.69s | valid loss  4.21 | valid ppl    67.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |    10/  257 batches | lr 10.00 | ms/batch 56.54 | loss  4.31 | ppl    74.69\n",
            "| epoch  35 |    20/  257 batches | lr 10.00 | ms/batch 54.62 | loss  3.90 | ppl    49.65\n",
            "| epoch  35 |    30/  257 batches | lr 10.00 | ms/batch 52.21 | loss  3.89 | ppl    48.73\n",
            "| epoch  35 |    40/  257 batches | lr 10.00 | ms/batch 52.99 | loss  3.90 | ppl    49.21\n",
            "| epoch  35 |    50/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.89 | ppl    48.96\n",
            "| epoch  35 |    60/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.88 | ppl    48.19\n",
            "| epoch  35 |    70/  257 batches | lr 10.00 | ms/batch 52.46 | loss  3.87 | ppl    47.87\n",
            "| epoch  35 |    80/  257 batches | lr 10.00 | ms/batch 52.75 | loss  3.86 | ppl    47.24\n",
            "| epoch  35 |    90/  257 batches | lr 10.00 | ms/batch 52.19 | loss  3.92 | ppl    50.15\n",
            "| epoch  35 |   100/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.91 | ppl    49.94\n",
            "| epoch  35 |   110/  257 batches | lr 10.00 | ms/batch 52.30 | loss  3.86 | ppl    47.54\n",
            "| epoch  35 |   120/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.88 | ppl    48.63\n",
            "| epoch  35 |   130/  257 batches | lr 10.00 | ms/batch 51.94 | loss  3.89 | ppl    49.11\n",
            "| epoch  35 |   140/  257 batches | lr 10.00 | ms/batch 52.46 | loss  3.85 | ppl    47.06\n",
            "| epoch  35 |   150/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.84 | ppl    46.75\n",
            "| epoch  35 |   160/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.87 | ppl    47.73\n",
            "| epoch  35 |   170/  257 batches | lr 10.00 | ms/batch 52.33 | loss  3.88 | ppl    48.18\n",
            "| epoch  35 |   180/  257 batches | lr 10.00 | ms/batch 52.79 | loss  3.89 | ppl    48.72\n",
            "| epoch  35 |   190/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.89 | ppl    48.73\n",
            "| epoch  35 |   200/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.86 | ppl    47.56\n",
            "| epoch  35 |   210/  257 batches | lr 10.00 | ms/batch 52.56 | loss  3.81 | ppl    45.27\n",
            "| epoch  35 |   220/  257 batches | lr 10.00 | ms/batch 52.70 | loss  3.87 | ppl    47.99\n",
            "| epoch  35 |   230/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.86 | ppl    47.65\n",
            "| epoch  35 |   240/  257 batches | lr 10.00 | ms/batch 52.66 | loss  3.87 | ppl    48.04\n",
            "| epoch  35 |   250/  257 batches | lr 10.00 | ms/batch 52.17 | loss  3.89 | ppl    48.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 15.71s | valid loss  4.20 | valid ppl    66.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |    10/  257 batches | lr 10.00 | ms/batch 56.36 | loss  4.30 | ppl    73.75\n",
            "| epoch  36 |    20/  257 batches | lr 10.00 | ms/batch 53.49 | loss  3.90 | ppl    49.54\n",
            "| epoch  36 |    30/  257 batches | lr 10.00 | ms/batch 51.80 | loss  3.88 | ppl    48.27\n",
            "| epoch  36 |    40/  257 batches | lr 10.00 | ms/batch 53.37 | loss  3.88 | ppl    48.51\n",
            "| epoch  36 |    50/  257 batches | lr 10.00 | ms/batch 52.29 | loss  3.89 | ppl    48.82\n",
            "| epoch  36 |    60/  257 batches | lr 10.00 | ms/batch 52.92 | loss  3.86 | ppl    47.42\n",
            "| epoch  36 |    70/  257 batches | lr 10.00 | ms/batch 52.17 | loss  3.86 | ppl    47.68\n",
            "| epoch  36 |    80/  257 batches | lr 10.00 | ms/batch 52.78 | loss  3.85 | ppl    46.86\n",
            "| epoch  36 |    90/  257 batches | lr 10.00 | ms/batch 52.36 | loss  3.90 | ppl    49.31\n",
            "| epoch  36 |   100/  257 batches | lr 10.00 | ms/batch 53.06 | loss  3.90 | ppl    49.35\n",
            "| epoch  36 |   110/  257 batches | lr 10.00 | ms/batch 52.34 | loss  3.85 | ppl    47.19\n",
            "| epoch  36 |   120/  257 batches | lr 10.00 | ms/batch 52.23 | loss  3.87 | ppl    48.15\n",
            "| epoch  36 |   130/  257 batches | lr 10.00 | ms/batch 52.81 | loss  3.89 | ppl    48.94\n",
            "| epoch  36 |   140/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.84 | ppl    46.47\n",
            "| epoch  36 |   150/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.84 | ppl    46.74\n",
            "| epoch  36 |   160/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.86 | ppl    47.54\n",
            "| epoch  36 |   170/  257 batches | lr 10.00 | ms/batch 52.10 | loss  3.87 | ppl    48.10\n",
            "| epoch  36 |   180/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.88 | ppl    48.41\n",
            "| epoch  36 |   190/  257 batches | lr 10.00 | ms/batch 52.85 | loss  3.88 | ppl    48.54\n",
            "| epoch  36 |   200/  257 batches | lr 10.00 | ms/batch 52.46 | loss  3.85 | ppl    47.13\n",
            "| epoch  36 |   210/  257 batches | lr 10.00 | ms/batch 51.89 | loss  3.81 | ppl    45.18\n",
            "| epoch  36 |   220/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.87 | ppl    47.87\n",
            "| epoch  36 |   230/  257 batches | lr 10.00 | ms/batch 52.70 | loss  3.86 | ppl    47.45\n",
            "| epoch  36 |   240/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.86 | ppl    47.67\n",
            "| epoch  36 |   250/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.89 | ppl    48.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 15.68s | valid loss  4.20 | valid ppl    66.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |    10/  257 batches | lr 10.00 | ms/batch 56.17 | loss  4.30 | ppl    73.35\n",
            "| epoch  37 |    20/  257 batches | lr 10.00 | ms/batch 53.43 | loss  3.88 | ppl    48.49\n",
            "| epoch  37 |    30/  257 batches | lr 10.00 | ms/batch 51.63 | loss  3.87 | ppl    47.98\n",
            "| epoch  37 |    40/  257 batches | lr 10.00 | ms/batch 52.82 | loss  3.86 | ppl    47.58\n",
            "| epoch  37 |    50/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.88 | ppl    48.31\n",
            "| epoch  37 |    60/  257 batches | lr 10.00 | ms/batch 52.67 | loss  3.85 | ppl    46.92\n",
            "| epoch  37 |    70/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.86 | ppl    47.33\n",
            "| epoch  37 |    80/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.84 | ppl    46.61\n",
            "| epoch  37 |    90/  257 batches | lr 10.00 | ms/batch 52.00 | loss  3.89 | ppl    49.09\n",
            "| epoch  37 |   100/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.89 | ppl    48.84\n",
            "| epoch  37 |   110/  257 batches | lr 10.00 | ms/batch 52.37 | loss  3.85 | ppl    46.78\n",
            "| epoch  37 |   120/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.87 | ppl    47.88\n",
            "| epoch  37 |   130/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.88 | ppl    48.31\n",
            "| epoch  37 |   140/  257 batches | lr 10.00 | ms/batch 52.62 | loss  3.83 | ppl    46.28\n",
            "| epoch  37 |   150/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.84 | ppl    46.38\n",
            "| epoch  37 |   160/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.85 | ppl    47.18\n",
            "| epoch  37 |   170/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.86 | ppl    47.42\n",
            "| epoch  37 |   180/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.87 | ppl    48.04\n",
            "| epoch  37 |   190/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.87 | ppl    47.79\n",
            "| epoch  37 |   200/  257 batches | lr 10.00 | ms/batch 52.27 | loss  3.85 | ppl    46.89\n",
            "| epoch  37 |   210/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.79 | ppl    44.46\n",
            "| epoch  37 |   220/  257 batches | lr 10.00 | ms/batch 53.07 | loss  3.85 | ppl    47.07\n",
            "| epoch  37 |   230/  257 batches | lr 10.00 | ms/batch 52.09 | loss  3.83 | ppl    46.29\n",
            "| epoch  37 |   240/  257 batches | lr 10.00 | ms/batch 52.70 | loss  3.86 | ppl    47.33\n",
            "| epoch  37 |   250/  257 batches | lr 10.00 | ms/batch 52.24 | loss  3.89 | ppl    48.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 15.67s | valid loss  4.20 | valid ppl    66.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |    10/  257 batches | lr 10.00 | ms/batch 55.98 | loss  4.29 | ppl    73.26\n",
            "| epoch  38 |    20/  257 batches | lr 10.00 | ms/batch 54.48 | loss  3.87 | ppl    48.05\n",
            "| epoch  38 |    30/  257 batches | lr 10.00 | ms/batch 51.68 | loss  3.86 | ppl    47.70\n",
            "| epoch  38 |    40/  257 batches | lr 10.00 | ms/batch 52.77 | loss  3.86 | ppl    47.67\n",
            "| epoch  38 |    50/  257 batches | lr 10.00 | ms/batch 51.65 | loss  3.87 | ppl    48.05\n",
            "| epoch  38 |    60/  257 batches | lr 10.00 | ms/batch 53.40 | loss  3.85 | ppl    46.81\n",
            "| epoch  38 |    70/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.84 | ppl    46.76\n",
            "| epoch  38 |    80/  257 batches | lr 10.00 | ms/batch 52.73 | loss  3.83 | ppl    46.08\n",
            "| epoch  38 |    90/  257 batches | lr 10.00 | ms/batch 52.46 | loss  3.88 | ppl    48.45\n",
            "| epoch  38 |   100/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.88 | ppl    48.55\n",
            "| epoch  38 |   110/  257 batches | lr 10.00 | ms/batch 52.01 | loss  3.84 | ppl    46.40\n",
            "| epoch  38 |   120/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.87 | ppl    47.73\n",
            "| epoch  38 |   130/  257 batches | lr 10.00 | ms/batch 52.45 | loss  3.87 | ppl    48.05\n",
            "| epoch  38 |   140/  257 batches | lr 10.00 | ms/batch 52.45 | loss  3.82 | ppl    45.76\n",
            "| epoch  38 |   150/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.83 | ppl    45.97\n",
            "| epoch  38 |   160/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.84 | ppl    46.62\n",
            "| epoch  38 |   170/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.85 | ppl    47.22\n",
            "| epoch  38 |   180/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.86 | ppl    47.30\n",
            "| epoch  38 |   190/  257 batches | lr 10.00 | ms/batch 52.25 | loss  3.86 | ppl    47.48\n",
            "| epoch  38 |   200/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.84 | ppl    46.43\n",
            "| epoch  38 |   210/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.79 | ppl    44.22\n",
            "| epoch  38 |   220/  257 batches | lr 10.00 | ms/batch 52.11 | loss  3.84 | ppl    46.48\n",
            "| epoch  38 |   230/  257 batches | lr 10.00 | ms/batch 52.23 | loss  3.84 | ppl    46.46\n",
            "| epoch  38 |   240/  257 batches | lr 10.00 | ms/batch 52.56 | loss  3.85 | ppl    47.16\n",
            "| epoch  38 |   250/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.87 | ppl    47.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 15.66s | valid loss  4.19 | valid ppl    66.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |    10/  257 batches | lr 10.00 | ms/batch 56.34 | loss  4.27 | ppl    71.71\n",
            "| epoch  39 |    20/  257 batches | lr 10.00 | ms/batch 53.63 | loss  3.87 | ppl    48.10\n",
            "| epoch  39 |    30/  257 batches | lr 10.00 | ms/batch 51.93 | loss  3.85 | ppl    47.09\n",
            "| epoch  39 |    40/  257 batches | lr 10.00 | ms/batch 53.13 | loss  3.86 | ppl    47.28\n",
            "| epoch  39 |    50/  257 batches | lr 10.00 | ms/batch 52.20 | loss  3.86 | ppl    47.31\n",
            "| epoch  39 |    60/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.84 | ppl    46.30\n",
            "| epoch  39 |    70/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.84 | ppl    46.30\n",
            "| epoch  39 |    80/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.82 | ppl    45.70\n",
            "| epoch  39 |    90/  257 batches | lr 10.00 | ms/batch 52.01 | loss  3.87 | ppl    47.85\n",
            "| epoch  39 |   100/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.88 | ppl    48.25\n",
            "| epoch  39 |   110/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.83 | ppl    46.25\n",
            "| epoch  39 |   120/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.85 | ppl    46.88\n",
            "| epoch  39 |   130/  257 batches | lr 10.00 | ms/batch 52.15 | loss  3.87 | ppl    47.76\n",
            "| epoch  39 |   140/  257 batches | lr 10.00 | ms/batch 52.15 | loss  3.81 | ppl    45.24\n",
            "| epoch  39 |   150/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.82 | ppl    45.43\n",
            "| epoch  39 |   160/  257 batches | lr 10.00 | ms/batch 52.06 | loss  3.83 | ppl    46.21\n",
            "| epoch  39 |   170/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.85 | ppl    46.92\n",
            "| epoch  39 |   180/  257 batches | lr 10.00 | ms/batch 52.36 | loss  3.85 | ppl    46.91\n",
            "| epoch  39 |   190/  257 batches | lr 10.00 | ms/batch 52.41 | loss  3.86 | ppl    47.29\n",
            "| epoch  39 |   200/  257 batches | lr 10.00 | ms/batch 52.56 | loss  3.83 | ppl    45.92\n",
            "| epoch  39 |   210/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.78 | ppl    43.93\n",
            "| epoch  39 |   220/  257 batches | lr 10.00 | ms/batch 52.10 | loss  3.84 | ppl    46.59\n",
            "| epoch  39 |   230/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.83 | ppl    46.12\n",
            "| epoch  39 |   240/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.84 | ppl    46.38\n",
            "| epoch  39 |   250/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.87 | ppl    47.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 15.65s | valid loss  4.19 | valid ppl    66.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |    10/  257 batches | lr 10.00 | ms/batch 56.20 | loss  4.27 | ppl    71.44\n",
            "| epoch  40 |    20/  257 batches | lr 10.00 | ms/batch 53.22 | loss  3.86 | ppl    47.38\n",
            "| epoch  40 |    30/  257 batches | lr 10.00 | ms/batch 52.13 | loss  3.85 | ppl    46.99\n",
            "| epoch  40 |    40/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.84 | ppl    46.62\n",
            "| epoch  40 |    50/  257 batches | lr 10.00 | ms/batch 52.09 | loss  3.85 | ppl    47.13\n",
            "| epoch  40 |    60/  257 batches | lr 10.00 | ms/batch 52.55 | loss  3.82 | ppl    45.78\n",
            "| epoch  40 |    70/  257 batches | lr 10.00 | ms/batch 52.62 | loss  3.82 | ppl    45.75\n",
            "| epoch  40 |    80/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.82 | ppl    45.38\n",
            "| epoch  40 |    90/  257 batches | lr 10.00 | ms/batch 52.28 | loss  3.86 | ppl    47.52\n",
            "| epoch  40 |   100/  257 batches | lr 10.00 | ms/batch 52.89 | loss  3.86 | ppl    47.67\n",
            "| epoch  40 |   110/  257 batches | lr 10.00 | ms/batch 51.97 | loss  3.82 | ppl    45.82\n",
            "| epoch  40 |   120/  257 batches | lr 10.00 | ms/batch 52.94 | loss  3.84 | ppl    46.64\n",
            "| epoch  40 |   130/  257 batches | lr 10.00 | ms/batch 52.07 | loss  3.86 | ppl    47.53\n",
            "| epoch  40 |   140/  257 batches | lr 10.00 | ms/batch 53.13 | loss  3.81 | ppl    45.24\n",
            "| epoch  40 |   150/  257 batches | lr 10.00 | ms/batch 52.19 | loss  3.81 | ppl    45.12\n",
            "| epoch  40 |   160/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.83 | ppl    46.08\n",
            "| epoch  40 |   170/  257 batches | lr 10.00 | ms/batch 51.76 | loss  3.85 | ppl    47.12\n",
            "| epoch  40 |   180/  257 batches | lr 10.00 | ms/batch 51.96 | loss  3.84 | ppl    46.75\n",
            "| epoch  40 |   190/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.85 | ppl    46.79\n",
            "| epoch  40 |   200/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.82 | ppl    45.69\n",
            "| epoch  40 |   210/  257 batches | lr 10.00 | ms/batch 52.26 | loss  3.77 | ppl    43.58\n",
            "| epoch  40 |   220/  257 batches | lr 10.00 | ms/batch 52.05 | loss  3.83 | ppl    46.00\n",
            "| epoch  40 |   230/  257 batches | lr 10.00 | ms/batch 52.58 | loss  3.82 | ppl    45.59\n",
            "| epoch  40 |   240/  257 batches | lr 10.00 | ms/batch 52.35 | loss  3.83 | ppl    46.09\n",
            "| epoch  40 |   250/  257 batches | lr 10.00 | ms/batch 52.19 | loss  3.86 | ppl    47.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 15.65s | valid loss  4.19 | valid ppl    65.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  41 |    10/  257 batches | lr 10.00 | ms/batch 56.35 | loss  4.26 | ppl    70.84\n",
            "| epoch  41 |    20/  257 batches | lr 10.00 | ms/batch 53.52 | loss  3.86 | ppl    47.44\n",
            "| epoch  41 |    30/  257 batches | lr 10.00 | ms/batch 51.78 | loss  3.84 | ppl    46.65\n",
            "| epoch  41 |    40/  257 batches | lr 10.00 | ms/batch 52.82 | loss  3.84 | ppl    46.31\n",
            "| epoch  41 |    50/  257 batches | lr 10.00 | ms/batch 52.32 | loss  3.84 | ppl    46.59\n",
            "| epoch  41 |    60/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.82 | ppl    45.45\n",
            "| epoch  41 |    70/  257 batches | lr 10.00 | ms/batch 51.69 | loss  3.82 | ppl    45.66\n",
            "| epoch  41 |    80/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.81 | ppl    44.97\n",
            "| epoch  41 |    90/  257 batches | lr 10.00 | ms/batch 52.02 | loss  3.85 | ppl    47.11\n",
            "| epoch  41 |   100/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.86 | ppl    47.61\n",
            "| epoch  41 |   110/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.81 | ppl    45.28\n",
            "| epoch  41 |   120/  257 batches | lr 10.00 | ms/batch 51.92 | loss  3.84 | ppl    46.46\n",
            "| epoch  41 |   130/  257 batches | lr 10.00 | ms/batch 52.29 | loss  3.84 | ppl    46.59\n",
            "| epoch  41 |   140/  257 batches | lr 10.00 | ms/batch 51.65 | loss  3.80 | ppl    44.59\n",
            "| epoch  41 |   150/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.80 | ppl    44.76\n",
            "| epoch  41 |   160/  257 batches | lr 10.00 | ms/batch 51.99 | loss  3.82 | ppl    45.50\n",
            "| epoch  41 |   170/  257 batches | lr 10.00 | ms/batch 52.24 | loss  3.83 | ppl    46.20\n",
            "| epoch  41 |   180/  257 batches | lr 10.00 | ms/batch 51.77 | loss  3.84 | ppl    46.65\n",
            "| epoch  41 |   190/  257 batches | lr 10.00 | ms/batch 52.50 | loss  3.84 | ppl    46.44\n",
            "| epoch  41 |   200/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.82 | ppl    45.56\n",
            "| epoch  41 |   210/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.77 | ppl    43.42\n",
            "| epoch  41 |   220/  257 batches | lr 10.00 | ms/batch 52.00 | loss  3.82 | ppl    45.39\n",
            "| epoch  41 |   230/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.81 | ppl    45.33\n",
            "| epoch  41 |   240/  257 batches | lr 10.00 | ms/batch 52.17 | loss  3.81 | ppl    45.26\n",
            "| epoch  41 |   250/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.85 | ppl    47.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 15.62s | valid loss  4.18 | valid ppl    65.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |    10/  257 batches | lr 10.00 | ms/batch 55.94 | loss  4.25 | ppl    70.37\n",
            "| epoch  42 |    20/  257 batches | lr 10.00 | ms/batch 52.98 | loss  3.83 | ppl    46.20\n",
            "| epoch  42 |    30/  257 batches | lr 10.00 | ms/batch 51.74 | loss  3.82 | ppl    45.56\n",
            "| epoch  42 |    40/  257 batches | lr 10.00 | ms/batch 52.90 | loss  3.82 | ppl    45.71\n",
            "| epoch  42 |    50/  257 batches | lr 10.00 | ms/batch 52.55 | loss  3.84 | ppl    46.50\n",
            "| epoch  42 |    60/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.82 | ppl    45.42\n",
            "| epoch  42 |    70/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.81 | ppl    45.30\n",
            "| epoch  42 |    80/  257 batches | lr 10.00 | ms/batch 52.73 | loss  3.80 | ppl    44.68\n",
            "| epoch  42 |    90/  257 batches | lr 10.00 | ms/batch 51.66 | loss  3.85 | ppl    47.15\n",
            "| epoch  42 |   100/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.84 | ppl    46.73\n",
            "| epoch  42 |   110/  257 batches | lr 10.00 | ms/batch 52.02 | loss  3.80 | ppl    44.75\n",
            "| epoch  42 |   120/  257 batches | lr 10.00 | ms/batch 52.27 | loss  3.83 | ppl    46.06\n",
            "| epoch  42 |   130/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.84 | ppl    46.41\n",
            "| epoch  42 |   140/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.79 | ppl    44.45\n",
            "| epoch  42 |   150/  257 batches | lr 10.00 | ms/batch 52.29 | loss  3.80 | ppl    44.70\n",
            "| epoch  42 |   160/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.81 | ppl    45.32\n",
            "| epoch  42 |   170/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.83 | ppl    46.05\n",
            "| epoch  42 |   180/  257 batches | lr 10.00 | ms/batch 51.85 | loss  3.82 | ppl    45.48\n",
            "| epoch  42 |   190/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.83 | ppl    46.14\n",
            "| epoch  42 |   200/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.81 | ppl    44.94\n",
            "| epoch  42 |   210/  257 batches | lr 10.00 | ms/batch 52.41 | loss  3.76 | ppl    42.86\n",
            "| epoch  42 |   220/  257 batches | lr 10.00 | ms/batch 52.02 | loss  3.82 | ppl    45.51\n",
            "| epoch  42 |   230/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.81 | ppl    44.97\n",
            "| epoch  42 |   240/  257 batches | lr 10.00 | ms/batch 52.30 | loss  3.81 | ppl    45.33\n",
            "| epoch  42 |   250/  257 batches | lr 10.00 | ms/batch 51.81 | loss  3.83 | ppl    46.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 15.63s | valid loss  4.18 | valid ppl    65.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |    10/  257 batches | lr 10.00 | ms/batch 55.68 | loss  4.23 | ppl    69.02\n",
            "| epoch  43 |    20/  257 batches | lr 10.00 | ms/batch 53.60 | loss  3.85 | ppl    46.82\n",
            "| epoch  43 |    30/  257 batches | lr 10.00 | ms/batch 51.48 | loss  3.82 | ppl    45.81\n",
            "| epoch  43 |    40/  257 batches | lr 10.00 | ms/batch 52.83 | loss  3.82 | ppl    45.67\n",
            "| epoch  43 |    50/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.83 | ppl    46.18\n",
            "| epoch  43 |    60/  257 batches | lr 10.00 | ms/batch 52.62 | loss  3.81 | ppl    45.09\n",
            "| epoch  43 |    70/  257 batches | lr 10.00 | ms/batch 51.89 | loss  3.80 | ppl    44.77\n",
            "| epoch  43 |    80/  257 batches | lr 10.00 | ms/batch 52.93 | loss  3.78 | ppl    43.96\n",
            "| epoch  43 |    90/  257 batches | lr 10.00 | ms/batch 52.02 | loss  3.84 | ppl    46.52\n",
            "| epoch  43 |   100/  257 batches | lr 10.00 | ms/batch 52.65 | loss  3.84 | ppl    46.74\n",
            "| epoch  43 |   110/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.80 | ppl    44.80\n",
            "| epoch  43 |   120/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.81 | ppl    45.28\n",
            "| epoch  43 |   130/  257 batches | lr 10.00 | ms/batch 52.14 | loss  3.83 | ppl    46.22\n",
            "| epoch  43 |   140/  257 batches | lr 10.00 | ms/batch 52.70 | loss  3.78 | ppl    43.98\n",
            "| epoch  43 |   150/  257 batches | lr 10.00 | ms/batch 52.37 | loss  3.79 | ppl    44.41\n",
            "| epoch  43 |   160/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.79 | ppl    44.47\n",
            "| epoch  43 |   170/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.82 | ppl    45.78\n",
            "| epoch  43 |   180/  257 batches | lr 10.00 | ms/batch 52.78 | loss  3.83 | ppl    45.90\n",
            "| epoch  43 |   190/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.83 | ppl    45.84\n",
            "| epoch  43 |   200/  257 batches | lr 10.00 | ms/batch 52.63 | loss  3.81 | ppl    45.06\n",
            "| epoch  43 |   210/  257 batches | lr 10.00 | ms/batch 52.10 | loss  3.76 | ppl    42.83\n",
            "| epoch  43 |   220/  257 batches | lr 10.00 | ms/batch 52.42 | loss  3.80 | ppl    44.86\n",
            "| epoch  43 |   230/  257 batches | lr 10.00 | ms/batch 52.38 | loss  3.81 | ppl    44.95\n",
            "| epoch  43 |   240/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.82 | ppl    45.47\n",
            "| epoch  43 |   250/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.84 | ppl    46.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 15.66s | valid loss  4.18 | valid ppl    65.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |    10/  257 batches | lr 10.00 | ms/batch 56.53 | loss  4.24 | ppl    69.10\n",
            "| epoch  44 |    20/  257 batches | lr 10.00 | ms/batch 53.92 | loss  3.83 | ppl    46.13\n",
            "| epoch  44 |    30/  257 batches | lr 10.00 | ms/batch 51.63 | loss  3.82 | ppl    45.64\n",
            "| epoch  44 |    40/  257 batches | lr 10.00 | ms/batch 53.06 | loss  3.81 | ppl    45.33\n",
            "| epoch  44 |    50/  257 batches | lr 10.00 | ms/batch 52.33 | loss  3.82 | ppl    45.46\n",
            "| epoch  44 |    60/  257 batches | lr 10.00 | ms/batch 52.87 | loss  3.80 | ppl    44.85\n",
            "| epoch  44 |    70/  257 batches | lr 10.00 | ms/batch 52.45 | loss  3.80 | ppl    44.86\n",
            "| epoch  44 |    80/  257 batches | lr 10.00 | ms/batch 52.78 | loss  3.79 | ppl    44.30\n",
            "| epoch  44 |    90/  257 batches | lr 10.00 | ms/batch 52.39 | loss  3.83 | ppl    45.87\n",
            "| epoch  44 |   100/  257 batches | lr 10.00 | ms/batch 52.21 | loss  3.84 | ppl    46.44\n",
            "| epoch  44 |   110/  257 batches | lr 10.00 | ms/batch 52.41 | loss  3.79 | ppl    44.48\n",
            "| epoch  44 |   120/  257 batches | lr 10.00 | ms/batch 52.39 | loss  3.81 | ppl    45.10\n",
            "| epoch  44 |   130/  257 batches | lr 10.00 | ms/batch 51.94 | loss  3.82 | ppl    45.50\n",
            "| epoch  44 |   140/  257 batches | lr 10.00 | ms/batch 52.73 | loss  3.78 | ppl    43.78\n",
            "| epoch  44 |   150/  257 batches | lr 10.00 | ms/batch 52.32 | loss  3.78 | ppl    43.98\n",
            "| epoch  44 |   160/  257 batches | lr 10.00 | ms/batch 52.08 | loss  3.80 | ppl    44.70\n",
            "| epoch  44 |   170/  257 batches | lr 10.00 | ms/batch 52.73 | loss  3.81 | ppl    45.17\n",
            "| epoch  44 |   180/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.81 | ppl    45.27\n",
            "| epoch  44 |   190/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.81 | ppl    45.19\n",
            "| epoch  44 |   200/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.80 | ppl    44.75\n",
            "| epoch  44 |   210/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.74 | ppl    42.22\n",
            "| epoch  44 |   220/  257 batches | lr 10.00 | ms/batch 52.30 | loss  3.80 | ppl    44.81\n",
            "| epoch  44 |   230/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.79 | ppl    44.27\n",
            "| epoch  44 |   240/  257 batches | lr 10.00 | ms/batch 52.08 | loss  3.79 | ppl    44.40\n",
            "| epoch  44 |   250/  257 batches | lr 10.00 | ms/batch 52.48 | loss  3.83 | ppl    46.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 15.69s | valid loss  4.18 | valid ppl    65.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |    10/  257 batches | lr 10.00 | ms/batch 56.08 | loss  4.23 | ppl    68.81\n",
            "| epoch  45 |    20/  257 batches | lr 10.00 | ms/batch 54.18 | loss  3.82 | ppl    45.80\n",
            "| epoch  45 |    30/  257 batches | lr 10.00 | ms/batch 51.92 | loss  3.81 | ppl    45.37\n",
            "| epoch  45 |    40/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.81 | ppl    45.00\n",
            "| epoch  45 |    50/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.81 | ppl    45.21\n",
            "| epoch  45 |    60/  257 batches | lr 10.00 | ms/batch 52.61 | loss  3.80 | ppl    44.53\n",
            "| epoch  45 |    70/  257 batches | lr 10.00 | ms/batch 52.59 | loss  3.80 | ppl    44.79\n",
            "| epoch  45 |    80/  257 batches | lr 10.00 | ms/batch 51.88 | loss  3.78 | ppl    43.76\n",
            "| epoch  45 |    90/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.83 | ppl    45.99\n",
            "| epoch  45 |   100/  257 batches | lr 10.00 | ms/batch 52.47 | loss  3.84 | ppl    46.33\n",
            "| epoch  45 |   110/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.78 | ppl    43.92\n",
            "| epoch  45 |   120/  257 batches | lr 10.00 | ms/batch 52.17 | loss  3.80 | ppl    44.92\n",
            "| epoch  45 |   130/  257 batches | lr 10.00 | ms/batch 52.31 | loss  3.81 | ppl    45.33\n",
            "| epoch  45 |   140/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.77 | ppl    43.59\n",
            "| epoch  45 |   150/  257 batches | lr 10.00 | ms/batch 52.51 | loss  3.77 | ppl    43.41\n",
            "| epoch  45 |   160/  257 batches | lr 10.00 | ms/batch 52.53 | loss  3.80 | ppl    44.61\n",
            "| epoch  45 |   170/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.80 | ppl    44.82\n",
            "| epoch  45 |   180/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.80 | ppl    44.71\n",
            "| epoch  45 |   190/  257 batches | lr 10.00 | ms/batch 52.25 | loss  3.81 | ppl    45.28\n",
            "| epoch  45 |   200/  257 batches | lr 10.00 | ms/batch 52.32 | loss  3.80 | ppl    44.48\n",
            "| epoch  45 |   210/  257 batches | lr 10.00 | ms/batch 52.71 | loss  3.74 | ppl    42.29\n",
            "| epoch  45 |   220/  257 batches | lr 10.00 | ms/batch 52.34 | loss  3.79 | ppl    44.37\n",
            "| epoch  45 |   230/  257 batches | lr 10.00 | ms/batch 52.01 | loss  3.79 | ppl    44.17\n",
            "| epoch  45 |   240/  257 batches | lr 10.00 | ms/batch 52.18 | loss  3.80 | ppl    44.51\n",
            "| epoch  45 |   250/  257 batches | lr 10.00 | ms/batch 52.52 | loss  3.81 | ppl    45.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 15.68s | valid loss  4.17 | valid ppl    64.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |    10/  257 batches | lr 10.00 | ms/batch 56.73 | loss  4.22 | ppl    68.11\n",
            "| epoch  46 |    20/  257 batches | lr 10.00 | ms/batch 52.80 | loss  3.82 | ppl    45.40\n",
            "| epoch  46 |    30/  257 batches | lr 10.00 | ms/batch 51.99 | loss  3.80 | ppl    44.83\n",
            "| epoch  46 |    40/  257 batches | lr 10.00 | ms/batch 53.05 | loss  3.80 | ppl    44.74\n",
            "| epoch  46 |    50/  257 batches | lr 10.00 | ms/batch 51.96 | loss  3.81 | ppl    45.31\n",
            "| epoch  46 |    60/  257 batches | lr 10.00 | ms/batch 53.31 | loss  3.78 | ppl    43.92\n",
            "| epoch  46 |    70/  257 batches | lr 10.00 | ms/batch 51.89 | loss  3.79 | ppl    44.20\n",
            "| epoch  46 |    80/  257 batches | lr 10.00 | ms/batch 53.00 | loss  3.77 | ppl    43.55\n",
            "| epoch  46 |    90/  257 batches | lr 10.00 | ms/batch 52.04 | loss  3.82 | ppl    45.41\n",
            "| epoch  46 |   100/  257 batches | lr 10.00 | ms/batch 52.48 | loss  3.83 | ppl    45.94\n",
            "| epoch  46 |   110/  257 batches | lr 10.00 | ms/batch 51.94 | loss  3.78 | ppl    43.77\n",
            "| epoch  46 |   120/  257 batches | lr 10.00 | ms/batch 52.49 | loss  3.80 | ppl    44.70\n",
            "| epoch  46 |   130/  257 batches | lr 10.00 | ms/batch 52.60 | loss  3.81 | ppl    45.14\n",
            "| epoch  46 |   140/  257 batches | lr 10.00 | ms/batch 52.64 | loss  3.77 | ppl    43.27\n",
            "| epoch  46 |   150/  257 batches | lr 10.00 | ms/batch 52.45 | loss  3.78 | ppl    43.94\n",
            "| epoch  46 |   160/  257 batches | lr 10.00 | ms/batch 52.67 | loss  3.78 | ppl    43.94\n",
            "| epoch  46 |   170/  257 batches | lr 10.00 | ms/batch 52.14 | loss  3.79 | ppl    44.39\n",
            "| epoch  46 |   180/  257 batches | lr 10.00 | ms/batch 52.44 | loss  3.80 | ppl    44.62\n",
            "| epoch  46 |   190/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.80 | ppl    44.88\n",
            "| epoch  46 |   200/  257 batches | lr 10.00 | ms/batch 52.09 | loss  3.79 | ppl    44.21\n",
            "| epoch  46 |   210/  257 batches | lr 10.00 | ms/batch 53.02 | loss  3.73 | ppl    41.86\n",
            "| epoch  46 |   220/  257 batches | lr 10.00 | ms/batch 52.40 | loss  3.78 | ppl    43.81\n",
            "| epoch  46 |   230/  257 batches | lr 10.00 | ms/batch 51.88 | loss  3.77 | ppl    43.54\n",
            "| epoch  46 |   240/  257 batches | lr 10.00 | ms/batch 52.54 | loss  3.78 | ppl    43.76\n",
            "| epoch  46 |   250/  257 batches | lr 10.00 | ms/batch 52.57 | loss  3.81 | ppl    45.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 15.64s | valid loss  4.17 | valid ppl    65.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |    10/  257 batches | lr 2.50 | ms/batch 59.14 | loss  4.21 | ppl    67.62\n",
            "| epoch  47 |    20/  257 batches | lr 2.50 | ms/batch 52.44 | loss  3.80 | ppl    44.76\n",
            "| epoch  47 |    30/  257 batches | lr 2.50 | ms/batch 52.80 | loss  3.79 | ppl    44.34\n",
            "| epoch  47 |    40/  257 batches | lr 2.50 | ms/batch 52.53 | loss  3.79 | ppl    44.33\n",
            "| epoch  47 |    50/  257 batches | lr 2.50 | ms/batch 52.66 | loss  3.79 | ppl    44.46\n",
            "| epoch  47 |    60/  257 batches | lr 2.50 | ms/batch 52.19 | loss  3.78 | ppl    43.87\n",
            "| epoch  47 |    70/  257 batches | lr 2.50 | ms/batch 52.31 | loss  3.78 | ppl    43.94\n",
            "| epoch  47 |    80/  257 batches | lr 2.50 | ms/batch 52.62 | loss  3.77 | ppl    43.29\n",
            "| epoch  47 |    90/  257 batches | lr 2.50 | ms/batch 52.50 | loss  3.81 | ppl    45.12\n",
            "| epoch  47 |   100/  257 batches | lr 2.50 | ms/batch 52.57 | loss  3.82 | ppl    45.59\n",
            "| epoch  47 |   110/  257 batches | lr 2.50 | ms/batch 52.60 | loss  3.77 | ppl    43.26\n",
            "| epoch  47 |   120/  257 batches | lr 2.50 | ms/batch 52.01 | loss  3.79 | ppl    44.34\n",
            "| epoch  47 |   130/  257 batches | lr 2.50 | ms/batch 52.68 | loss  3.80 | ppl    44.71\n",
            "| epoch  47 |   140/  257 batches | lr 2.50 | ms/batch 52.40 | loss  3.76 | ppl    42.94\n",
            "| epoch  47 |   150/  257 batches | lr 2.50 | ms/batch 52.77 | loss  3.76 | ppl    43.06\n",
            "| epoch  47 |   160/  257 batches | lr 2.50 | ms/batch 51.68 | loss  3.77 | ppl    43.46\n",
            "| epoch  47 |   170/  257 batches | lr 2.50 | ms/batch 53.03 | loss  3.79 | ppl    44.35\n",
            "| epoch  47 |   180/  257 batches | lr 2.50 | ms/batch 52.11 | loss  3.79 | ppl    44.46\n",
            "| epoch  47 |   190/  257 batches | lr 2.50 | ms/batch 52.64 | loss  3.79 | ppl    44.48\n",
            "| epoch  47 |   200/  257 batches | lr 2.50 | ms/batch 52.59 | loss  3.78 | ppl    43.80\n",
            "| epoch  47 |   210/  257 batches | lr 2.50 | ms/batch 52.21 | loss  3.73 | ppl    41.71\n",
            "| epoch  47 |   220/  257 batches | lr 2.50 | ms/batch 52.56 | loss  3.78 | ppl    43.96\n",
            "| epoch  47 |   230/  257 batches | lr 2.50 | ms/batch 52.57 | loss  3.77 | ppl    43.40\n",
            "| epoch  47 |   240/  257 batches | lr 2.50 | ms/batch 52.76 | loss  3.78 | ppl    43.92\n",
            "| epoch  47 |   250/  257 batches | lr 2.50 | ms/batch 52.16 | loss  3.81 | ppl    45.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 15.70s | valid loss  4.17 | valid ppl    64.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |    10/  257 batches | lr 2.50 | ms/batch 55.94 | loss  4.20 | ppl    66.50\n",
            "| epoch  48 |    20/  257 batches | lr 2.50 | ms/batch 54.37 | loss  3.80 | ppl    44.84\n",
            "| epoch  48 |    30/  257 batches | lr 2.50 | ms/batch 52.39 | loss  3.79 | ppl    44.44\n",
            "| epoch  48 |    40/  257 batches | lr 2.50 | ms/batch 52.73 | loss  3.78 | ppl    44.02\n",
            "| epoch  48 |    50/  257 batches | lr 2.50 | ms/batch 52.35 | loss  3.80 | ppl    44.74\n",
            "| epoch  48 |    60/  257 batches | lr 2.50 | ms/batch 52.90 | loss  3.78 | ppl    43.79\n",
            "| epoch  48 |    70/  257 batches | lr 2.50 | ms/batch 52.78 | loss  3.77 | ppl    43.36\n",
            "| epoch  48 |    80/  257 batches | lr 2.50 | ms/batch 52.56 | loss  3.76 | ppl    42.89\n",
            "| epoch  48 |    90/  257 batches | lr 2.50 | ms/batch 52.61 | loss  3.82 | ppl    45.38\n",
            "| epoch  48 |   100/  257 batches | lr 2.50 | ms/batch 52.66 | loss  3.80 | ppl    44.82\n",
            "| epoch  48 |   110/  257 batches | lr 2.50 | ms/batch 52.14 | loss  3.76 | ppl    43.10\n",
            "| epoch  48 |   120/  257 batches | lr 2.50 | ms/batch 52.64 | loss  3.79 | ppl    44.35\n",
            "| epoch  48 |   130/  257 batches | lr 2.50 | ms/batch 52.10 | loss  3.78 | ppl    43.71\n",
            "| epoch  48 |   140/  257 batches | lr 2.50 | ms/batch 52.56 | loss  3.76 | ppl    42.95\n",
            "| epoch  48 |   150/  257 batches | lr 2.50 | ms/batch 52.29 | loss  3.75 | ppl    42.65\n",
            "| epoch  48 |   160/  257 batches | lr 2.50 | ms/batch 52.46 | loss  3.77 | ppl    43.50\n",
            "| epoch  48 |   170/  257 batches | lr 2.50 | ms/batch 52.31 | loss  3.78 | ppl    43.75\n",
            "| epoch  48 |   180/  257 batches | lr 2.50 | ms/batch 52.43 | loss  3.79 | ppl    44.16\n",
            "| epoch  48 |   190/  257 batches | lr 2.50 | ms/batch 52.35 | loss  3.79 | ppl    44.21\n",
            "| epoch  48 |   200/  257 batches | lr 2.50 | ms/batch 52.42 | loss  3.77 | ppl    43.44\n",
            "| epoch  48 |   210/  257 batches | lr 2.50 | ms/batch 52.26 | loss  3.72 | ppl    41.13\n",
            "| epoch  48 |   220/  257 batches | lr 2.50 | ms/batch 52.38 | loss  3.77 | ppl    43.42\n",
            "| epoch  48 |   230/  257 batches | lr 2.50 | ms/batch 52.11 | loss  3.77 | ppl    43.33\n",
            "| epoch  48 |   240/  257 batches | lr 2.50 | ms/batch 52.45 | loss  3.78 | ppl    43.76\n",
            "| epoch  48 |   250/  257 batches | lr 2.50 | ms/batch 52.60 | loss  3.79 | ppl    44.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 15.67s | valid loss  4.17 | valid ppl    64.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |    10/  257 batches | lr 2.50 | ms/batch 56.47 | loss  4.20 | ppl    66.38\n",
            "| epoch  49 |    20/  257 batches | lr 2.50 | ms/batch 53.90 | loss  3.79 | ppl    44.45\n",
            "| epoch  49 |    30/  257 batches | lr 2.50 | ms/batch 52.42 | loss  3.78 | ppl    43.88\n",
            "| epoch  49 |    40/  257 batches | lr 2.50 | ms/batch 52.72 | loss  3.79 | ppl    44.15\n",
            "| epoch  49 |    50/  257 batches | lr 2.50 | ms/batch 52.45 | loss  3.79 | ppl    44.35\n",
            "| epoch  49 |    60/  257 batches | lr 2.50 | ms/batch 52.80 | loss  3.77 | ppl    43.28\n",
            "| epoch  49 |    70/  257 batches | lr 2.50 | ms/batch 51.85 | loss  3.78 | ppl    43.74\n",
            "| epoch  49 |    80/  257 batches | lr 2.50 | ms/batch 52.77 | loss  3.76 | ppl    42.86\n",
            "| epoch  49 |    90/  257 batches | lr 2.50 | ms/batch 52.25 | loss  3.79 | ppl    44.31\n",
            "| epoch  49 |   100/  257 batches | lr 2.50 | ms/batch 52.82 | loss  3.80 | ppl    44.69\n",
            "| epoch  49 |   110/  257 batches | lr 2.50 | ms/batch 52.98 | loss  3.76 | ppl    42.90\n",
            "| epoch  49 |   120/  257 batches | lr 2.50 | ms/batch 52.38 | loss  3.78 | ppl    43.65\n",
            "| epoch  49 |   130/  257 batches | lr 2.50 | ms/batch 52.31 | loss  3.78 | ppl    43.92\n",
            "| epoch  49 |   140/  257 batches | lr 2.50 | ms/batch 52.58 | loss  3.76 | ppl    42.84\n",
            "| epoch  49 |   150/  257 batches | lr 2.50 | ms/batch 52.22 | loss  3.75 | ppl    42.73\n",
            "| epoch  49 |   160/  257 batches | lr 2.50 | ms/batch 52.50 | loss  3.76 | ppl    42.86\n",
            "| epoch  49 |   170/  257 batches | lr 2.50 | ms/batch 52.64 | loss  3.77 | ppl    43.24\n",
            "| epoch  49 |   180/  257 batches | lr 2.50 | ms/batch 52.82 | loss  3.78 | ppl    43.98\n",
            "| epoch  49 |   190/  257 batches | lr 2.50 | ms/batch 52.24 | loss  3.79 | ppl    44.23\n",
            "| epoch  49 |   200/  257 batches | lr 2.50 | ms/batch 52.48 | loss  3.77 | ppl    43.54\n",
            "| epoch  49 |   210/  257 batches | lr 2.50 | ms/batch 52.75 | loss  3.71 | ppl    40.88\n",
            "| epoch  49 |   220/  257 batches | lr 2.50 | ms/batch 52.45 | loss  3.77 | ppl    43.33\n",
            "| epoch  49 |   230/  257 batches | lr 2.50 | ms/batch 52.18 | loss  3.76 | ppl    43.02\n",
            "| epoch  49 |   240/  257 batches | lr 2.50 | ms/batch 52.55 | loss  3.77 | ppl    43.56\n",
            "| epoch  49 |   250/  257 batches | lr 2.50 | ms/batch 52.53 | loss  3.80 | ppl    44.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 15.70s | valid loss  4.17 | valid ppl    64.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |    10/  257 batches | lr 2.50 | ms/batch 56.85 | loss  4.19 | ppl    65.74\n",
            "| epoch  50 |    20/  257 batches | lr 2.50 | ms/batch 53.47 | loss  3.79 | ppl    44.44\n",
            "| epoch  50 |    30/  257 batches | lr 2.50 | ms/batch 51.93 | loss  3.78 | ppl    43.81\n",
            "| epoch  50 |    40/  257 batches | lr 2.50 | ms/batch 53.26 | loss  3.77 | ppl    43.60\n",
            "| epoch  50 |    50/  257 batches | lr 2.50 | ms/batch 52.36 | loss  3.77 | ppl    43.54\n",
            "| epoch  50 |    60/  257 batches | lr 2.50 | ms/batch 52.77 | loss  3.76 | ppl    42.90\n",
            "| epoch  50 |    70/  257 batches | lr 2.50 | ms/batch 52.29 | loss  3.76 | ppl    42.94\n",
            "| epoch  50 |    80/  257 batches | lr 2.50 | ms/batch 52.64 | loss  3.76 | ppl    42.74\n",
            "| epoch  50 |    90/  257 batches | lr 2.50 | ms/batch 52.53 | loss  3.79 | ppl    44.09\n",
            "| epoch  50 |   100/  257 batches | lr 2.50 | ms/batch 52.26 | loss  3.80 | ppl    44.81\n",
            "| epoch  50 |   110/  257 batches | lr 2.50 | ms/batch 52.44 | loss  3.75 | ppl    42.53\n",
            "| epoch  50 |   120/  257 batches | lr 2.50 | ms/batch 52.60 | loss  3.78 | ppl    43.73\n",
            "| epoch  50 |   130/  257 batches | lr 2.50 | ms/batch 52.70 | loss  3.78 | ppl    43.87\n",
            "| epoch  50 |   140/  257 batches | lr 2.50 | ms/batch 52.60 | loss  3.74 | ppl    42.10\n",
            "| epoch  50 |   150/  257 batches | lr 2.50 | ms/batch 52.60 | loss  3.74 | ppl    42.26\n",
            "| epoch  50 |   160/  257 batches | lr 2.50 | ms/batch 52.71 | loss  3.76 | ppl    42.86\n",
            "| epoch  50 |   170/  257 batches | lr 2.50 | ms/batch 52.47 | loss  3.78 | ppl    43.86\n",
            "| epoch  50 |   180/  257 batches | lr 2.50 | ms/batch 52.56 | loss  3.78 | ppl    43.71\n",
            "| epoch  50 |   190/  257 batches | lr 2.50 | ms/batch 52.56 | loss  3.78 | ppl    43.84\n",
            "| epoch  50 |   200/  257 batches | lr 2.50 | ms/batch 51.77 | loss  3.76 | ppl    42.91\n",
            "| epoch  50 |   210/  257 batches | lr 2.50 | ms/batch 52.34 | loss  3.71 | ppl    41.05\n",
            "| epoch  50 |   220/  257 batches | lr 2.50 | ms/batch 52.31 | loss  3.77 | ppl    43.32\n",
            "| epoch  50 |   230/  257 batches | lr 2.50 | ms/batch 52.53 | loss  3.75 | ppl    42.66\n",
            "| epoch  50 |   240/  257 batches | lr 2.50 | ms/batch 52.56 | loss  3.78 | ppl    43.71\n",
            "| epoch  50 |   250/  257 batches | lr 2.50 | ms/batch 52.41 | loss  3.79 | ppl    44.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 15.68s | valid loss  4.16 | valid ppl    64.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  51 |    10/  257 batches | lr 2.50 | ms/batch 55.93 | loss  4.18 | ppl    65.56\n",
            "| epoch  51 |    20/  257 batches | lr 2.50 | ms/batch 54.47 | loss  3.79 | ppl    44.28\n",
            "| epoch  51 |    30/  257 batches | lr 2.50 | ms/batch 51.62 | loss  3.78 | ppl    43.67\n",
            "| epoch  51 |    40/  257 batches | lr 2.50 | ms/batch 53.04 | loss  3.76 | ppl    43.11\n",
            "| epoch  51 |    50/  257 batches | lr 2.50 | ms/batch 52.14 | loss  3.77 | ppl    43.30\n",
            "| epoch  51 |    60/  257 batches | lr 2.50 | ms/batch 53.16 | loss  3.76 | ppl    42.96\n",
            "| epoch  51 |    70/  257 batches | lr 2.50 | ms/batch 52.28 | loss  3.75 | ppl    42.49\n",
            "| epoch  51 |    80/  257 batches | lr 2.50 | ms/batch 53.13 | loss  3.74 | ppl    42.18\n",
            "| epoch  51 |    90/  257 batches | lr 2.50 | ms/batch 52.10 | loss  3.78 | ppl    43.80\n",
            "| epoch  51 |   100/  257 batches | lr 2.50 | ms/batch 53.26 | loss  3.79 | ppl    44.30\n",
            "| epoch  51 |   110/  257 batches | lr 2.50 | ms/batch 51.37 | loss  3.75 | ppl    42.32\n",
            "| epoch  51 |   120/  257 batches | lr 2.50 | ms/batch 53.15 | loss  3.76 | ppl    43.16\n",
            "| epoch  51 |   130/  257 batches | lr 2.50 | ms/batch 51.97 | loss  3.78 | ppl    43.78\n",
            "| epoch  51 |   140/  257 batches | lr 2.50 | ms/batch 52.68 | loss  3.74 | ppl    41.98\n",
            "| epoch  51 |   150/  257 batches | lr 2.50 | ms/batch 52.02 | loss  3.74 | ppl    42.10\n",
            "| epoch  51 |   160/  257 batches | lr 2.50 | ms/batch 52.71 | loss  3.76 | ppl    42.96\n",
            "| epoch  51 |   170/  257 batches | lr 2.50 | ms/batch 52.40 | loss  3.76 | ppl    43.03\n",
            "| epoch  51 |   180/  257 batches | lr 2.50 | ms/batch 52.70 | loss  3.77 | ppl    43.46\n",
            "| epoch  51 |   190/  257 batches | lr 2.50 | ms/batch 52.41 | loss  3.77 | ppl    43.50\n",
            "| epoch  51 |   200/  257 batches | lr 2.50 | ms/batch 52.63 | loss  3.75 | ppl    42.66\n",
            "| epoch  51 |   210/  257 batches | lr 2.50 | ms/batch 52.61 | loss  3.70 | ppl    40.38\n",
            "| epoch  51 |   220/  257 batches | lr 2.50 | ms/batch 52.45 | loss  3.76 | ppl    42.75\n",
            "| epoch  51 |   230/  257 batches | lr 2.50 | ms/batch 52.78 | loss  3.75 | ppl    42.58\n",
            "| epoch  51 |   240/  257 batches | lr 2.50 | ms/batch 52.32 | loss  3.76 | ppl    42.82\n",
            "| epoch  51 |   250/  257 batches | lr 2.50 | ms/batch 52.45 | loss  3.78 | ppl    43.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 15.69s | valid loss  4.17 | valid ppl    64.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |    10/  257 batches | lr 0.62 | ms/batch 58.85 | loss  4.18 | ppl    65.30\n",
            "| epoch  52 |    20/  257 batches | lr 0.62 | ms/batch 52.83 | loss  3.78 | ppl    43.67\n",
            "| epoch  52 |    30/  257 batches | lr 0.62 | ms/batch 52.79 | loss  3.76 | ppl    43.15\n",
            "| epoch  52 |    40/  257 batches | lr 0.62 | ms/batch 52.20 | loss  3.77 | ppl    43.27\n",
            "| epoch  52 |    50/  257 batches | lr 0.62 | ms/batch 52.20 | loss  3.78 | ppl    43.95\n",
            "| epoch  52 |    60/  257 batches | lr 0.62 | ms/batch 52.96 | loss  3.75 | ppl    42.59\n",
            "| epoch  52 |    70/  257 batches | lr 0.62 | ms/batch 52.83 | loss  3.75 | ppl    42.37\n",
            "| epoch  52 |    80/  257 batches | lr 0.62 | ms/batch 52.88 | loss  3.74 | ppl    41.99\n",
            "| epoch  52 |    90/  257 batches | lr 0.62 | ms/batch 52.54 | loss  3.77 | ppl    43.49\n",
            "| epoch  52 |   100/  257 batches | lr 0.62 | ms/batch 52.74 | loss  3.78 | ppl    43.88\n",
            "| epoch  52 |   110/  257 batches | lr 0.62 | ms/batch 52.58 | loss  3.75 | ppl    42.37\n",
            "| epoch  52 |   120/  257 batches | lr 0.62 | ms/batch 52.54 | loss  3.77 | ppl    43.33\n",
            "| epoch  52 |   130/  257 batches | lr 0.62 | ms/batch 52.66 | loss  3.78 | ppl    43.70\n",
            "| epoch  52 |   140/  257 batches | lr 0.62 | ms/batch 52.62 | loss  3.73 | ppl    41.84\n",
            "| epoch  52 |   150/  257 batches | lr 0.62 | ms/batch 52.62 | loss  3.73 | ppl    41.85\n",
            "| epoch  52 |   160/  257 batches | lr 0.62 | ms/batch 52.21 | loss  3.76 | ppl    42.75\n",
            "| epoch  52 |   170/  257 batches | lr 0.62 | ms/batch 52.42 | loss  3.76 | ppl    42.87\n",
            "| epoch  52 |   180/  257 batches | lr 0.62 | ms/batch 52.29 | loss  3.76 | ppl    42.78\n",
            "| epoch  52 |   190/  257 batches | lr 0.62 | ms/batch 52.48 | loss  3.77 | ppl    43.51\n",
            "| epoch  52 |   200/  257 batches | lr 0.62 | ms/batch 52.54 | loss  3.76 | ppl    42.99\n",
            "| epoch  52 |   210/  257 batches | lr 0.62 | ms/batch 52.63 | loss  3.70 | ppl    40.46\n",
            "| epoch  52 |   220/  257 batches | lr 0.62 | ms/batch 52.63 | loss  3.76 | ppl    42.74\n",
            "| epoch  52 |   230/  257 batches | lr 0.62 | ms/batch 52.50 | loss  3.75 | ppl    42.71\n",
            "| epoch  52 |   240/  257 batches | lr 0.62 | ms/batch 52.72 | loss  3.75 | ppl    42.45\n",
            "| epoch  52 |   250/  257 batches | lr 0.62 | ms/batch 52.43 | loss  3.77 | ppl    43.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 15.74s | valid loss  4.16 | valid ppl    64.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |    10/  257 batches | lr 0.62 | ms/batch 56.08 | loss  4.18 | ppl    65.07\n",
            "| epoch  53 |    20/  257 batches | lr 0.62 | ms/batch 53.64 | loss  3.78 | ppl    43.84\n",
            "| epoch  53 |    30/  257 batches | lr 0.62 | ms/batch 51.73 | loss  3.75 | ppl    42.53\n",
            "| epoch  53 |    40/  257 batches | lr 0.62 | ms/batch 53.12 | loss  3.75 | ppl    42.71\n",
            "| epoch  53 |    50/  257 batches | lr 0.62 | ms/batch 52.31 | loss  3.77 | ppl    43.29\n",
            "| epoch  53 |    60/  257 batches | lr 0.62 | ms/batch 52.79 | loss  3.75 | ppl    42.66\n",
            "| epoch  53 |    70/  257 batches | lr 0.62 | ms/batch 52.64 | loss  3.73 | ppl    41.80\n",
            "| epoch  53 |    80/  257 batches | lr 0.62 | ms/batch 52.69 | loss  3.73 | ppl    41.63\n",
            "| epoch  53 |    90/  257 batches | lr 0.62 | ms/batch 52.36 | loss  3.78 | ppl    43.98\n",
            "| epoch  53 |   100/  257 batches | lr 0.62 | ms/batch 52.37 | loss  3.78 | ppl    43.90\n",
            "| epoch  53 |   110/  257 batches | lr 0.62 | ms/batch 52.46 | loss  3.74 | ppl    42.05\n",
            "| epoch  53 |   120/  257 batches | lr 0.62 | ms/batch 52.48 | loss  3.75 | ppl    42.71\n",
            "| epoch  53 |   130/  257 batches | lr 0.62 | ms/batch 52.35 | loss  3.76 | ppl    43.14\n",
            "| epoch  53 |   140/  257 batches | lr 0.62 | ms/batch 52.73 | loss  3.74 | ppl    41.91\n",
            "| epoch  53 |   150/  257 batches | lr 0.62 | ms/batch 52.13 | loss  3.73 | ppl    41.54\n",
            "| epoch  53 |   160/  257 batches | lr 0.62 | ms/batch 52.30 | loss  3.74 | ppl    42.11\n",
            "| epoch  53 |   170/  257 batches | lr 0.62 | ms/batch 52.84 | loss  3.75 | ppl    42.59\n",
            "| epoch  53 |   180/  257 batches | lr 0.62 | ms/batch 52.21 | loss  3.75 | ppl    42.43\n",
            "| epoch  53 |   190/  257 batches | lr 0.62 | ms/batch 52.59 | loss  3.75 | ppl    42.60\n",
            "| epoch  53 |   200/  257 batches | lr 0.62 | ms/batch 52.69 | loss  3.75 | ppl    42.41\n",
            "| epoch  53 |   210/  257 batches | lr 0.62 | ms/batch 52.68 | loss  3.70 | ppl    40.39\n",
            "| epoch  53 |   220/  257 batches | lr 0.62 | ms/batch 52.69 | loss  3.75 | ppl    42.67\n",
            "| epoch  53 |   230/  257 batches | lr 0.62 | ms/batch 52.51 | loss  3.75 | ppl    42.34\n",
            "| epoch  53 |   240/  257 batches | lr 0.62 | ms/batch 52.46 | loss  3.74 | ppl    42.20\n",
            "| epoch  53 |   250/  257 batches | lr 0.62 | ms/batch 52.56 | loss  3.77 | ppl    43.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 15.67s | valid loss  4.16 | valid ppl    64.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |    10/  257 batches | lr 0.62 | ms/batch 56.20 | loss  4.17 | ppl    64.55\n",
            "| epoch  54 |    20/  257 batches | lr 0.62 | ms/batch 53.00 | loss  3.77 | ppl    43.20\n",
            "| epoch  54 |    30/  257 batches | lr 0.62 | ms/batch 51.92 | loss  3.76 | ppl    42.87\n",
            "| epoch  54 |    40/  257 batches | lr 0.62 | ms/batch 52.99 | loss  3.76 | ppl    42.74\n",
            "| epoch  54 |    50/  257 batches | lr 0.62 | ms/batch 51.69 | loss  3.76 | ppl    42.74\n",
            "| epoch  54 |    60/  257 batches | lr 0.62 | ms/batch 52.28 | loss  3.74 | ppl    42.18\n",
            "| epoch  54 |    70/  257 batches | lr 0.62 | ms/batch 51.90 | loss  3.74 | ppl    42.15\n",
            "| epoch  54 |    80/  257 batches | lr 0.62 | ms/batch 52.56 | loss  3.72 | ppl    41.45\n",
            "| epoch  54 |    90/  257 batches | lr 0.62 | ms/batch 51.86 | loss  3.78 | ppl    43.63\n",
            "| epoch  54 |   100/  257 batches | lr 0.62 | ms/batch 52.46 | loss  3.78 | ppl    43.82\n",
            "| epoch  54 |   110/  257 batches | lr 0.62 | ms/batch 52.46 | loss  3.73 | ppl    41.68\n",
            "| epoch  54 |   120/  257 batches | lr 0.62 | ms/batch 52.32 | loss  3.75 | ppl    42.55\n",
            "| epoch  54 |   130/  257 batches | lr 0.62 | ms/batch 52.56 | loss  3.75 | ppl    42.63\n",
            "| epoch  54 |   140/  257 batches | lr 0.62 | ms/batch 52.58 | loss  3.73 | ppl    41.47\n",
            "| epoch  54 |   150/  257 batches | lr 0.62 | ms/batch 52.74 | loss  3.71 | ppl    41.05\n",
            "| epoch  54 |   160/  257 batches | lr 0.62 | ms/batch 52.39 | loss  3.74 | ppl    42.15\n",
            "| epoch  54 |   170/  257 batches | lr 0.62 | ms/batch 52.42 | loss  3.75 | ppl    42.48\n",
            "| epoch  54 |   180/  257 batches | lr 0.62 | ms/batch 52.39 | loss  3.75 | ppl    42.56\n",
            "| epoch  54 |   190/  257 batches | lr 0.62 | ms/batch 52.39 | loss  3.75 | ppl    42.55\n",
            "| epoch  54 |   200/  257 batches | lr 0.62 | ms/batch 52.50 | loss  3.74 | ppl    42.17\n",
            "| epoch  54 |   210/  257 batches | lr 0.62 | ms/batch 52.60 | loss  3.69 | ppl    40.02\n",
            "| epoch  54 |   220/  257 batches | lr 0.62 | ms/batch 52.34 | loss  3.75 | ppl    42.39\n",
            "| epoch  54 |   230/  257 batches | lr 0.62 | ms/batch 52.05 | loss  3.74 | ppl    42.06\n",
            "| epoch  54 |   240/  257 batches | lr 0.62 | ms/batch 52.45 | loss  3.74 | ppl    41.92\n",
            "| epoch  54 |   250/  257 batches | lr 0.62 | ms/batch 52.71 | loss  3.76 | ppl    43.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 15.63s | valid loss  4.16 | valid ppl    64.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |    10/  257 batches | lr 0.16 | ms/batch 58.83 | loss  4.16 | ppl    63.92\n",
            "| epoch  55 |    20/  257 batches | lr 0.16 | ms/batch 52.21 | loss  3.76 | ppl    43.14\n",
            "| epoch  55 |    30/  257 batches | lr 0.16 | ms/batch 52.46 | loss  3.74 | ppl    42.26\n",
            "| epoch  55 |    40/  257 batches | lr 0.16 | ms/batch 51.69 | loss  3.74 | ppl    42.25\n",
            "| epoch  55 |    50/  257 batches | lr 0.16 | ms/batch 52.65 | loss  3.75 | ppl    42.47\n",
            "| epoch  55 |    60/  257 batches | lr 0.16 | ms/batch 52.44 | loss  3.73 | ppl    41.64\n",
            "| epoch  55 |    70/  257 batches | lr 0.16 | ms/batch 52.29 | loss  3.73 | ppl    41.58\n",
            "| epoch  55 |    80/  257 batches | lr 0.16 | ms/batch 52.04 | loss  3.73 | ppl    41.61\n",
            "| epoch  55 |    90/  257 batches | lr 0.16 | ms/batch 51.93 | loss  3.75 | ppl    42.69\n",
            "| epoch  55 |   100/  257 batches | lr 0.16 | ms/batch 52.43 | loss  3.77 | ppl    43.33\n",
            "| epoch  55 |   110/  257 batches | lr 0.16 | ms/batch 52.60 | loss  3.73 | ppl    41.79\n",
            "| epoch  55 |   120/  257 batches | lr 0.16 | ms/batch 52.36 | loss  3.74 | ppl    42.23\n",
            "| epoch  55 |   130/  257 batches | lr 0.16 | ms/batch 52.43 | loss  3.76 | ppl    43.12\n",
            "| epoch  55 |   140/  257 batches | lr 0.16 | ms/batch 52.16 | loss  3.72 | ppl    41.45\n",
            "| epoch  55 |   150/  257 batches | lr 0.16 | ms/batch 52.39 | loss  3.72 | ppl    41.16\n",
            "| epoch  55 |   160/  257 batches | lr 0.16 | ms/batch 52.48 | loss  3.73 | ppl    41.57\n",
            "| epoch  55 |   170/  257 batches | lr 0.16 | ms/batch 52.51 | loss  3.75 | ppl    42.40\n",
            "| epoch  55 |   180/  257 batches | lr 0.16 | ms/batch 51.75 | loss  3.75 | ppl    42.35\n",
            "| epoch  55 |   190/  257 batches | lr 0.16 | ms/batch 52.44 | loss  3.75 | ppl    42.65\n",
            "| epoch  55 |   200/  257 batches | lr 0.16 | ms/batch 52.14 | loss  3.72 | ppl    41.46\n",
            "| epoch  55 |   210/  257 batches | lr 0.16 | ms/batch 52.16 | loss  3.69 | ppl    39.96\n",
            "| epoch  55 |   220/  257 batches | lr 0.16 | ms/batch 52.56 | loss  3.74 | ppl    41.96\n",
            "| epoch  55 |   230/  257 batches | lr 0.16 | ms/batch 52.13 | loss  3.73 | ppl    41.52\n",
            "| epoch  55 |   240/  257 batches | lr 0.16 | ms/batch 52.41 | loss  3.74 | ppl    42.01\n",
            "| epoch  55 |   250/  257 batches | lr 0.16 | ms/batch 52.30 | loss  3.76 | ppl    42.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 15.66s | valid loss  4.16 | valid ppl    64.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |    10/  257 batches | lr 0.16 | ms/batch 56.09 | loss  4.15 | ppl    63.31\n",
            "| epoch  56 |    20/  257 batches | lr 0.16 | ms/batch 53.92 | loss  3.75 | ppl    42.61\n",
            "| epoch  56 |    30/  257 batches | lr 0.16 | ms/batch 52.05 | loss  3.74 | ppl    42.08\n",
            "| epoch  56 |    40/  257 batches | lr 0.16 | ms/batch 52.22 | loss  3.74 | ppl    42.25\n",
            "| epoch  56 |    50/  257 batches | lr 0.16 | ms/batch 51.75 | loss  3.75 | ppl    42.39\n",
            "| epoch  56 |    60/  257 batches | lr 0.16 | ms/batch 52.55 | loss  3.73 | ppl    41.51\n",
            "| epoch  56 |    70/  257 batches | lr 0.16 | ms/batch 52.30 | loss  3.73 | ppl    41.59\n",
            "| epoch  56 |    80/  257 batches | lr 0.16 | ms/batch 52.65 | loss  3.71 | ppl    40.97\n",
            "| epoch  56 |    90/  257 batches | lr 0.16 | ms/batch 51.91 | loss  3.76 | ppl    42.84\n",
            "| epoch  56 |   100/  257 batches | lr 0.16 | ms/batch 52.58 | loss  3.76 | ppl    42.90\n",
            "| epoch  56 |   110/  257 batches | lr 0.16 | ms/batch 52.52 | loss  3.72 | ppl    41.16\n",
            "| epoch  56 |   120/  257 batches | lr 0.16 | ms/batch 51.95 | loss  3.74 | ppl    42.13\n",
            "| epoch  56 |   130/  257 batches | lr 0.16 | ms/batch 52.47 | loss  3.75 | ppl    42.52\n",
            "| epoch  56 |   140/  257 batches | lr 0.16 | ms/batch 52.42 | loss  3.71 | ppl    40.91\n",
            "| epoch  56 |   150/  257 batches | lr 0.16 | ms/batch 52.33 | loss  3.71 | ppl    41.05\n",
            "| epoch  56 |   160/  257 batches | lr 0.16 | ms/batch 51.93 | loss  3.72 | ppl    41.30\n",
            "| epoch  56 |   170/  257 batches | lr 0.16 | ms/batch 52.71 | loss  3.74 | ppl    42.01\n",
            "| epoch  56 |   180/  257 batches | lr 0.16 | ms/batch 52.53 | loss  3.74 | ppl    42.08\n",
            "| epoch  56 |   190/  257 batches | lr 0.16 | ms/batch 52.59 | loss  3.74 | ppl    42.09\n",
            "| epoch  56 |   200/  257 batches | lr 0.16 | ms/batch 52.21 | loss  3.73 | ppl    41.49\n",
            "| epoch  56 |   210/  257 batches | lr 0.16 | ms/batch 52.31 | loss  3.68 | ppl    39.80\n",
            "| epoch  56 |   220/  257 batches | lr 0.16 | ms/batch 52.66 | loss  3.73 | ppl    41.48\n",
            "| epoch  56 |   230/  257 batches | lr 0.16 | ms/batch 52.20 | loss  3.72 | ppl    41.38\n",
            "| epoch  56 |   240/  257 batches | lr 0.16 | ms/batch 52.04 | loss  3.74 | ppl    42.09\n",
            "| epoch  56 |   250/  257 batches | lr 0.16 | ms/batch 52.53 | loss  3.76 | ppl    42.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 15.63s | valid loss  4.16 | valid ppl    63.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |    10/  257 batches | lr 0.16 | ms/batch 56.40 | loss  4.15 | ppl    63.33\n",
            "| epoch  57 |    20/  257 batches | lr 0.16 | ms/batch 54.08 | loss  3.75 | ppl    42.67\n",
            "| epoch  57 |    30/  257 batches | lr 0.16 | ms/batch 52.31 | loss  3.74 | ppl    42.21\n",
            "| epoch  57 |    40/  257 batches | lr 0.16 | ms/batch 53.20 | loss  3.75 | ppl    42.39\n",
            "| epoch  57 |    50/  257 batches | lr 0.16 | ms/batch 52.08 | loss  3.74 | ppl    41.97\n",
            "| epoch  57 |    60/  257 batches | lr 0.16 | ms/batch 52.69 | loss  3.72 | ppl    41.37\n",
            "| epoch  57 |    70/  257 batches | lr 0.16 | ms/batch 52.51 | loss  3.72 | ppl    41.30\n",
            "| epoch  57 |    80/  257 batches | lr 0.16 | ms/batch 52.57 | loss  3.71 | ppl    40.97\n",
            "| epoch  57 |    90/  257 batches | lr 0.16 | ms/batch 51.98 | loss  3.75 | ppl    42.34\n",
            "| epoch  57 |   100/  257 batches | lr 0.16 | ms/batch 52.95 | loss  3.75 | ppl    42.47\n",
            "| epoch  57 |   110/  257 batches | lr 0.16 | ms/batch 52.17 | loss  3.72 | ppl    41.08\n",
            "| epoch  57 |   120/  257 batches | lr 0.16 | ms/batch 52.36 | loss  3.74 | ppl    42.08\n",
            "| epoch  57 |   130/  257 batches | lr 0.16 | ms/batch 52.16 | loss  3.75 | ppl    42.52\n",
            "| epoch  57 |   140/  257 batches | lr 0.16 | ms/batch 52.67 | loss  3.70 | ppl    40.55\n",
            "| epoch  57 |   150/  257 batches | lr 0.16 | ms/batch 52.37 | loss  3.71 | ppl    40.69\n",
            "| epoch  57 |   160/  257 batches | lr 0.16 | ms/batch 52.25 | loss  3.73 | ppl    41.69\n",
            "| epoch  57 |   170/  257 batches | lr 0.16 | ms/batch 52.27 | loss  3.74 | ppl    42.18\n",
            "| epoch  57 |   180/  257 batches | lr 0.16 | ms/batch 52.28 | loss  3.73 | ppl    41.71\n",
            "| epoch  57 |   190/  257 batches | lr 0.16 | ms/batch 52.82 | loss  3.74 | ppl    42.15\n",
            "| epoch  57 |   200/  257 batches | lr 0.16 | ms/batch 52.21 | loss  3.72 | ppl    41.42\n",
            "| epoch  57 |   210/  257 batches | lr 0.16 | ms/batch 52.24 | loss  3.67 | ppl    39.40\n",
            "| epoch  57 |   220/  257 batches | lr 0.16 | ms/batch 52.56 | loss  3.73 | ppl    41.70\n",
            "| epoch  57 |   230/  257 batches | lr 0.16 | ms/batch 52.74 | loss  3.72 | ppl    41.13\n",
            "| epoch  57 |   240/  257 batches | lr 0.16 | ms/batch 52.18 | loss  3.73 | ppl    41.81\n",
            "| epoch  57 |   250/  257 batches | lr 0.16 | ms/batch 52.39 | loss  3.74 | ppl    42.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 15.66s | valid loss  4.16 | valid ppl    63.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |    10/  257 batches | lr 0.04 | ms/batch 58.90 | loss  4.14 | ppl    63.04\n",
            "| epoch  58 |    20/  257 batches | lr 0.04 | ms/batch 51.33 | loss  3.75 | ppl    42.49\n",
            "| epoch  58 |    30/  257 batches | lr 0.04 | ms/batch 53.10 | loss  3.73 | ppl    41.65\n",
            "| epoch  58 |    40/  257 batches | lr 0.04 | ms/batch 52.00 | loss  3.72 | ppl    41.47\n",
            "| epoch  58 |    50/  257 batches | lr 0.04 | ms/batch 52.53 | loss  3.74 | ppl    42.01\n",
            "| epoch  58 |    60/  257 batches | lr 0.04 | ms/batch 51.81 | loss  3.72 | ppl    41.21\n",
            "| epoch  58 |    70/  257 batches | lr 0.04 | ms/batch 52.54 | loss  3.71 | ppl    40.78\n",
            "| epoch  58 |    80/  257 batches | lr 0.04 | ms/batch 52.41 | loss  3.70 | ppl    40.49\n",
            "| epoch  58 |    90/  257 batches | lr 0.04 | ms/batch 52.62 | loss  3.75 | ppl    42.50\n",
            "| epoch  58 |   100/  257 batches | lr 0.04 | ms/batch 52.54 | loss  3.74 | ppl    42.10\n",
            "| epoch  58 |   110/  257 batches | lr 0.04 | ms/batch 52.48 | loss  3.71 | ppl    40.71\n",
            "| epoch  58 |   120/  257 batches | lr 0.04 | ms/batch 52.29 | loss  3.73 | ppl    41.69\n",
            "| epoch  58 |   130/  257 batches | lr 0.04 | ms/batch 52.21 | loss  3.74 | ppl    42.27\n",
            "| epoch  58 |   140/  257 batches | lr 0.04 | ms/batch 52.58 | loss  3.71 | ppl    40.81\n",
            "| epoch  58 |   150/  257 batches | lr 0.04 | ms/batch 52.33 | loss  3.71 | ppl    40.72\n",
            "| epoch  58 |   160/  257 batches | lr 0.04 | ms/batch 52.61 | loss  3.72 | ppl    41.21\n",
            "| epoch  58 |   170/  257 batches | lr 0.04 | ms/batch 52.14 | loss  3.73 | ppl    41.55\n",
            "| epoch  58 |   180/  257 batches | lr 0.04 | ms/batch 52.28 | loss  3.73 | ppl    41.74\n",
            "| epoch  58 |   190/  257 batches | lr 0.04 | ms/batch 52.56 | loss  3.73 | ppl    41.70\n",
            "| epoch  58 |   200/  257 batches | lr 0.04 | ms/batch 52.46 | loss  3.72 | ppl    41.08\n",
            "| epoch  58 |   210/  257 batches | lr 0.04 | ms/batch 52.00 | loss  3.67 | ppl    39.40\n",
            "| epoch  58 |   220/  257 batches | lr 0.04 | ms/batch 52.60 | loss  3.72 | ppl    41.24\n",
            "| epoch  58 |   230/  257 batches | lr 0.04 | ms/batch 52.29 | loss  3.72 | ppl    41.19\n",
            "| epoch  58 |   240/  257 batches | lr 0.04 | ms/batch 52.16 | loss  3.72 | ppl    41.07\n",
            "| epoch  58 |   250/  257 batches | lr 0.04 | ms/batch 52.29 | loss  3.75 | ppl    42.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 15.64s | valid loss  4.16 | valid ppl    63.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |    10/  257 batches | lr 0.04 | ms/batch 56.47 | loss  4.13 | ppl    62.16\n",
            "| epoch  59 |    20/  257 batches | lr 0.04 | ms/batch 53.95 | loss  3.75 | ppl    42.42\n",
            "| epoch  59 |    30/  257 batches | lr 0.04 | ms/batch 51.56 | loss  3.73 | ppl    41.55\n",
            "| epoch  59 |    40/  257 batches | lr 0.04 | ms/batch 53.01 | loss  3.72 | ppl    41.17\n",
            "| epoch  59 |    50/  257 batches | lr 0.04 | ms/batch 52.03 | loss  3.73 | ppl    41.73\n",
            "| epoch  59 |    60/  257 batches | lr 0.04 | ms/batch 52.89 | loss  3.72 | ppl    41.33\n",
            "| epoch  59 |    70/  257 batches | lr 0.04 | ms/batch 51.90 | loss  3.72 | ppl    41.07\n",
            "| epoch  59 |    80/  257 batches | lr 0.04 | ms/batch 53.43 | loss  3.70 | ppl    40.59\n",
            "| epoch  59 |    90/  257 batches | lr 0.04 | ms/batch 52.54 | loss  3.76 | ppl    42.75\n",
            "| epoch  59 |   100/  257 batches | lr 0.04 | ms/batch 52.50 | loss  3.75 | ppl    42.48\n",
            "| epoch  59 |   110/  257 batches | lr 0.04 | ms/batch 52.24 | loss  3.70 | ppl    40.34\n",
            "| epoch  59 |   120/  257 batches | lr 0.04 | ms/batch 52.67 | loss  3.73 | ppl    41.59\n",
            "| epoch  59 |   130/  257 batches | lr 0.04 | ms/batch 52.35 | loss  3.73 | ppl    41.56\n",
            "| epoch  59 |   140/  257 batches | lr 0.04 | ms/batch 52.51 | loss  3.70 | ppl    40.40\n",
            "| epoch  59 |   150/  257 batches | lr 0.04 | ms/batch 52.08 | loss  3.70 | ppl    40.28\n",
            "| epoch  59 |   160/  257 batches | lr 0.04 | ms/batch 52.45 | loss  3.72 | ppl    41.12\n",
            "| epoch  59 |   170/  257 batches | lr 0.04 | ms/batch 52.45 | loss  3.72 | ppl    41.34\n",
            "| epoch  59 |   180/  257 batches | lr 0.04 | ms/batch 52.55 | loss  3.72 | ppl    41.35\n",
            "| epoch  59 |   190/  257 batches | lr 0.04 | ms/batch 53.06 | loss  3.73 | ppl    41.85\n",
            "| epoch  59 |   200/  257 batches | lr 0.04 | ms/batch 52.17 | loss  3.71 | ppl    40.98\n",
            "| epoch  59 |   210/  257 batches | lr 0.04 | ms/batch 52.40 | loss  3.68 | ppl    39.50\n",
            "| epoch  59 |   220/  257 batches | lr 0.04 | ms/batch 52.62 | loss  3.72 | ppl    41.30\n",
            "| epoch  59 |   230/  257 batches | lr 0.04 | ms/batch 52.64 | loss  3.71 | ppl    40.68\n",
            "| epoch  59 |   240/  257 batches | lr 0.04 | ms/batch 52.60 | loss  3.72 | ppl    41.18\n",
            "| epoch  59 |   250/  257 batches | lr 0.04 | ms/batch 52.55 | loss  3.74 | ppl    42.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 15.66s | valid loss  4.15 | valid ppl    63.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |    10/  257 batches | lr 0.04 | ms/batch 56.46 | loss  4.13 | ppl    62.32\n",
            "| epoch  60 |    20/  257 batches | lr 0.04 | ms/batch 53.55 | loss  3.74 | ppl    42.12\n",
            "| epoch  60 |    30/  257 batches | lr 0.04 | ms/batch 52.17 | loss  3.72 | ppl    41.12\n",
            "| epoch  60 |    40/  257 batches | lr 0.04 | ms/batch 53.21 | loss  3.73 | ppl    41.50\n",
            "| epoch  60 |    50/  257 batches | lr 0.04 | ms/batch 52.00 | loss  3.72 | ppl    41.43\n",
            "| epoch  60 |    60/  257 batches | lr 0.04 | ms/batch 52.73 | loss  3.71 | ppl    40.68\n",
            "| epoch  60 |    70/  257 batches | lr 0.04 | ms/batch 52.44 | loss  3.71 | ppl    40.98\n",
            "| epoch  60 |    80/  257 batches | lr 0.04 | ms/batch 52.50 | loss  3.70 | ppl    40.25\n",
            "| epoch  60 |    90/  257 batches | lr 0.04 | ms/batch 52.66 | loss  3.74 | ppl    42.30\n",
            "| epoch  60 |   100/  257 batches | lr 0.04 | ms/batch 52.51 | loss  3.73 | ppl    41.87\n",
            "| epoch  60 |   110/  257 batches | lr 0.04 | ms/batch 52.38 | loss  3.70 | ppl    40.27\n",
            "| epoch  60 |   120/  257 batches | lr 0.04 | ms/batch 52.61 | loss  3.72 | ppl    41.27\n",
            "| epoch  60 |   130/  257 batches | lr 0.04 | ms/batch 52.58 | loss  3.73 | ppl    41.69\n",
            "| epoch  60 |   140/  257 batches | lr 0.04 | ms/batch 52.02 | loss  3.69 | ppl    40.03\n",
            "| epoch  60 |   150/  257 batches | lr 0.04 | ms/batch 52.63 | loss  3.70 | ppl    40.26\n",
            "| epoch  60 |   160/  257 batches | lr 0.04 | ms/batch 52.36 | loss  3.71 | ppl    41.04\n",
            "| epoch  60 |   170/  257 batches | lr 0.04 | ms/batch 52.51 | loss  3.72 | ppl    41.42\n",
            "| epoch  60 |   180/  257 batches | lr 0.04 | ms/batch 52.09 | loss  3.72 | ppl    41.44\n",
            "| epoch  60 |   190/  257 batches | lr 0.04 | ms/batch 52.65 | loss  3.72 | ppl    41.25\n",
            "| epoch  60 |   200/  257 batches | lr 0.04 | ms/batch 52.50 | loss  3.71 | ppl    40.86\n",
            "| epoch  60 |   210/  257 batches | lr 0.04 | ms/batch 52.58 | loss  3.67 | ppl    39.06\n",
            "| epoch  60 |   220/  257 batches | lr 0.04 | ms/batch 52.19 | loss  3.71 | ppl    41.01\n",
            "| epoch  60 |   230/  257 batches | lr 0.04 | ms/batch 52.27 | loss  3.71 | ppl    40.83\n",
            "| epoch  60 |   240/  257 batches | lr 0.04 | ms/batch 52.39 | loss  3.72 | ppl    41.14\n",
            "| epoch  60 |   250/  257 batches | lr 0.04 | ms/batch 51.83 | loss  3.73 | ppl    41.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time: 15.65s | valid loss  4.16 | valid ppl    63.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  61 |    10/  257 batches | lr 0.01 | ms/batch 59.46 | loss  4.13 | ppl    62.23\n",
            "| epoch  61 |    20/  257 batches | lr 0.01 | ms/batch 52.50 | loss  3.73 | ppl    41.68\n",
            "| epoch  61 |    30/  257 batches | lr 0.01 | ms/batch 52.52 | loss  3.72 | ppl    41.43\n",
            "| epoch  61 |    40/  257 batches | lr 0.01 | ms/batch 52.11 | loss  3.72 | ppl    41.33\n",
            "| epoch  61 |    50/  257 batches | lr 0.01 | ms/batch 52.37 | loss  3.72 | ppl    41.06\n",
            "| epoch  61 |    60/  257 batches | lr 0.01 | ms/batch 52.58 | loss  3.70 | ppl    40.53\n",
            "| epoch  61 |    70/  257 batches | lr 0.01 | ms/batch 52.50 | loss  3.70 | ppl    40.62\n",
            "| epoch  61 |    80/  257 batches | lr 0.01 | ms/batch 52.63 | loss  3.70 | ppl    40.40\n",
            "| epoch  61 |    90/  257 batches | lr 0.01 | ms/batch 52.62 | loss  3.73 | ppl    41.66\n",
            "| epoch  61 |   100/  257 batches | lr 0.01 | ms/batch 52.16 | loss  3.74 | ppl    42.12\n",
            "| epoch  61 |   110/  257 batches | lr 0.01 | ms/batch 52.49 | loss  3.69 | ppl    40.06\n",
            "| epoch  61 |   120/  257 batches | lr 0.01 | ms/batch 52.94 | loss  3.72 | ppl    41.14\n",
            "| epoch  61 |   130/  257 batches | lr 0.01 | ms/batch 52.80 | loss  3.73 | ppl    41.55\n",
            "| epoch  61 |   140/  257 batches | lr 0.01 | ms/batch 51.82 | loss  3.68 | ppl    39.75\n",
            "| epoch  61 |   150/  257 batches | lr 0.01 | ms/batch 52.80 | loss  3.69 | ppl    39.98\n",
            "| epoch  61 |   160/  257 batches | lr 0.01 | ms/batch 52.56 | loss  3.70 | ppl    40.49\n",
            "| epoch  61 |   170/  257 batches | lr 0.01 | ms/batch 52.61 | loss  3.71 | ppl    41.02\n",
            "| epoch  61 |   180/  257 batches | lr 0.01 | ms/batch 52.58 | loss  3.72 | ppl    41.22\n",
            "| epoch  61 |   190/  257 batches | lr 0.01 | ms/batch 52.64 | loss  3.72 | ppl    41.25\n",
            "| epoch  61 |   200/  257 batches | lr 0.01 | ms/batch 52.56 | loss  3.71 | ppl    40.71\n",
            "| epoch  61 |   210/  257 batches | lr 0.01 | ms/batch 52.78 | loss  3.66 | ppl    38.83\n",
            "| epoch  61 |   220/  257 batches | lr 0.01 | ms/batch 52.72 | loss  3.70 | ppl    40.60\n",
            "| epoch  61 |   230/  257 batches | lr 0.01 | ms/batch 52.63 | loss  3.70 | ppl    40.61\n",
            "| epoch  61 |   240/  257 batches | lr 0.01 | ms/batch 52.12 | loss  3.71 | ppl    40.66\n",
            "| epoch  61 |   250/  257 batches | lr 0.01 | ms/batch 52.43 | loss  3.73 | ppl    41.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time: 15.68s | valid loss  4.15 | valid ppl    63.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |    10/  257 batches | lr 0.01 | ms/batch 56.37 | loss  4.12 | ppl    61.47\n",
            "| epoch  62 |    20/  257 batches | lr 0.01 | ms/batch 53.73 | loss  3.74 | ppl    41.95\n",
            "| epoch  62 |    30/  257 batches | lr 0.01 | ms/batch 51.84 | loss  3.71 | ppl    40.67\n",
            "| epoch  62 |    40/  257 batches | lr 0.01 | ms/batch 52.48 | loss  3.71 | ppl    40.94\n",
            "| epoch  62 |    50/  257 batches | lr 0.01 | ms/batch 52.08 | loss  3.72 | ppl    41.18\n",
            "| epoch  62 |    60/  257 batches | lr 0.01 | ms/batch 52.60 | loss  3.70 | ppl    40.28\n",
            "| epoch  62 |    70/  257 batches | lr 0.01 | ms/batch 52.43 | loss  3.70 | ppl    40.44\n",
            "| epoch  62 |    80/  257 batches | lr 0.01 | ms/batch 52.57 | loss  3.69 | ppl    39.95\n",
            "| epoch  62 |    90/  257 batches | lr 0.01 | ms/batch 52.07 | loss  3.73 | ppl    41.59\n",
            "| epoch  62 |   100/  257 batches | lr 0.01 | ms/batch 52.90 | loss  3.73 | ppl    41.77\n",
            "| epoch  62 |   110/  257 batches | lr 0.01 | ms/batch 52.06 | loss  3.69 | ppl    39.97\n",
            "| epoch  62 |   120/  257 batches | lr 0.01 | ms/batch 52.66 | loss  3.72 | ppl    41.43\n",
            "| epoch  62 |   130/  257 batches | lr 0.01 | ms/batch 52.57 | loss  3.71 | ppl    40.88\n",
            "| epoch  62 |   140/  257 batches | lr 0.01 | ms/batch 52.61 | loss  3.68 | ppl    39.76\n",
            "| epoch  62 |   150/  257 batches | lr 0.01 | ms/batch 52.55 | loss  3.68 | ppl    39.57\n",
            "| epoch  62 |   160/  257 batches | lr 0.01 | ms/batch 52.37 | loss  3.69 | ppl    40.19\n",
            "| epoch  62 |   170/  257 batches | lr 0.01 | ms/batch 52.49 | loss  3.70 | ppl    40.45\n",
            "| epoch  62 |   180/  257 batches | lr 0.01 | ms/batch 52.50 | loss  3.72 | ppl    41.07\n",
            "| epoch  62 |   190/  257 batches | lr 0.01 | ms/batch 52.37 | loss  3.72 | ppl    41.09\n",
            "| epoch  62 |   200/  257 batches | lr 0.01 | ms/batch 52.67 | loss  3.70 | ppl    40.36\n",
            "| epoch  62 |   210/  257 batches | lr 0.01 | ms/batch 52.58 | loss  3.66 | ppl    38.88\n",
            "| epoch  62 |   220/  257 batches | lr 0.01 | ms/batch 52.28 | loss  3.71 | ppl    40.88\n",
            "| epoch  62 |   230/  257 batches | lr 0.01 | ms/batch 52.68 | loss  3.70 | ppl    40.33\n",
            "| epoch  62 |   240/  257 batches | lr 0.01 | ms/batch 52.53 | loss  3.70 | ppl    40.46\n",
            "| epoch  62 |   250/  257 batches | lr 0.01 | ms/batch 52.49 | loss  3.73 | ppl    41.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time: 15.65s | valid loss  4.15 | valid ppl    63.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |    10/  257 batches | lr 0.01 | ms/batch 56.15 | loss  4.11 | ppl    60.76\n",
            "| epoch  63 |    20/  257 batches | lr 0.01 | ms/batch 54.17 | loss  3.73 | ppl    41.50\n",
            "| epoch  63 |    30/  257 batches | lr 0.01 | ms/batch 51.77 | loss  3.71 | ppl    40.95\n",
            "| epoch  63 |    40/  257 batches | lr 0.01 | ms/batch 53.27 | loss  3.71 | ppl    40.90\n",
            "| epoch  63 |    50/  257 batches | lr 0.01 | ms/batch 52.62 | loss  3.71 | ppl    40.94\n",
            "| epoch  63 |    60/  257 batches | lr 0.01 | ms/batch 52.10 | loss  3.70 | ppl    40.46\n",
            "| epoch  63 |    70/  257 batches | lr 0.01 | ms/batch 52.45 | loss  3.70 | ppl    40.42\n",
            "| epoch  63 |    80/  257 batches | lr 0.01 | ms/batch 52.57 | loss  3.69 | ppl    39.90\n",
            "| epoch  63 |    90/  257 batches | lr 0.01 | ms/batch 52.72 | loss  3.73 | ppl    41.49\n",
            "| epoch  63 |   100/  257 batches | lr 0.01 | ms/batch 52.44 | loss  3.72 | ppl    41.46\n",
            "| epoch  63 |   110/  257 batches | lr 0.01 | ms/batch 52.02 | loss  3.68 | ppl    39.60\n",
            "| epoch  63 |   120/  257 batches | lr 0.01 | ms/batch 52.02 | loss  3.71 | ppl    40.88\n",
            "| epoch  63 |   130/  257 batches | lr 0.01 | ms/batch 52.87 | loss  3.71 | ppl    40.95\n",
            "| epoch  63 |   140/  257 batches | lr 0.01 | ms/batch 52.21 | loss  3.67 | ppl    39.37\n",
            "| epoch  63 |   150/  257 batches | lr 0.01 | ms/batch 52.29 | loss  3.68 | ppl    39.84\n",
            "| epoch  63 |   160/  257 batches | lr 0.01 | ms/batch 52.32 | loss  3.70 | ppl    40.36\n",
            "| epoch  63 |   170/  257 batches | lr 0.01 | ms/batch 52.42 | loss  3.71 | ppl    40.78\n",
            "| epoch  63 |   180/  257 batches | lr 0.01 | ms/batch 52.66 | loss  3.71 | ppl    40.71\n",
            "| epoch  63 |   190/  257 batches | lr 0.01 | ms/batch 52.50 | loss  3.72 | ppl    41.18\n",
            "| epoch  63 |   200/  257 batches | lr 0.01 | ms/batch 52.52 | loss  3.70 | ppl    40.41\n",
            "| epoch  63 |   210/  257 batches | lr 0.01 | ms/batch 52.61 | loss  3.65 | ppl    38.61\n",
            "| epoch  63 |   220/  257 batches | lr 0.01 | ms/batch 52.24 | loss  3.70 | ppl    40.47\n",
            "| epoch  63 |   230/  257 batches | lr 0.01 | ms/batch 52.83 | loss  3.69 | ppl    40.21\n",
            "| epoch  63 |   240/  257 batches | lr 0.01 | ms/batch 52.36 | loss  3.70 | ppl    40.51\n",
            "| epoch  63 |   250/  257 batches | lr 0.01 | ms/batch 52.63 | loss  3.72 | ppl    41.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time: 15.65s | valid loss  4.15 | valid ppl    63.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |    10/  257 batches | lr 0.01 | ms/batch 56.32 | loss  4.10 | ppl    60.36\n",
            "| epoch  64 |    20/  257 batches | lr 0.01 | ms/batch 54.41 | loss  3.72 | ppl    41.34\n",
            "| epoch  64 |    30/  257 batches | lr 0.01 | ms/batch 51.78 | loss  3.71 | ppl    40.67\n",
            "| epoch  64 |    40/  257 batches | lr 0.01 | ms/batch 52.70 | loss  3.70 | ppl    40.43\n",
            "| epoch  64 |    50/  257 batches | lr 0.01 | ms/batch 52.27 | loss  3.71 | ppl    40.90\n",
            "| epoch  64 |    60/  257 batches | lr 0.01 | ms/batch 52.96 | loss  3.69 | ppl    40.24\n",
            "| epoch  64 |    70/  257 batches | lr 0.01 | ms/batch 52.41 | loss  3.69 | ppl    39.93\n",
            "| epoch  64 |    80/  257 batches | lr 0.01 | ms/batch 52.66 | loss  3.68 | ppl    39.69\n",
            "| epoch  64 |    90/  257 batches | lr 0.01 | ms/batch 52.69 | loss  3.72 | ppl    41.33\n",
            "| epoch  64 |   100/  257 batches | lr 0.01 | ms/batch 52.35 | loss  3.73 | ppl    41.71\n",
            "| epoch  64 |   110/  257 batches | lr 0.01 | ms/batch 52.09 | loss  3.67 | ppl    39.40\n",
            "| epoch  64 |   120/  257 batches | lr 0.01 | ms/batch 52.60 | loss  3.70 | ppl    40.63\n",
            "| epoch  64 |   130/  257 batches | lr 0.01 | ms/batch 52.54 | loss  3.71 | ppl    40.76\n",
            "| epoch  64 |   140/  257 batches | lr 0.01 | ms/batch 52.55 | loss  3.68 | ppl    39.50\n",
            "| epoch  64 |   150/  257 batches | lr 0.01 | ms/batch 52.57 | loss  3.67 | ppl    39.28\n",
            "| epoch  64 |   160/  257 batches | lr 0.01 | ms/batch 51.72 | loss  3.68 | ppl    39.78\n",
            "| epoch  64 |   170/  257 batches | lr 0.01 | ms/batch 52.69 | loss  3.71 | ppl    40.77\n",
            "| epoch  64 |   180/  257 batches | lr 0.01 | ms/batch 52.14 | loss  3.70 | ppl    40.51\n",
            "| epoch  64 |   190/  257 batches | lr 0.01 | ms/batch 53.05 | loss  3.70 | ppl    40.57\n",
            "| epoch  64 |   200/  257 batches | lr 0.01 | ms/batch 52.06 | loss  3.69 | ppl    40.13\n",
            "| epoch  64 |   210/  257 batches | lr 0.01 | ms/batch 52.68 | loss  3.65 | ppl    38.31\n",
            "| epoch  64 |   220/  257 batches | lr 0.01 | ms/batch 52.50 | loss  3.69 | ppl    40.24\n",
            "| epoch  64 |   230/  257 batches | lr 0.01 | ms/batch 52.33 | loss  3.69 | ppl    39.93\n",
            "| epoch  64 |   240/  257 batches | lr 0.01 | ms/batch 52.64 | loss  3.69 | ppl    40.07\n",
            "| epoch  64 |   250/  257 batches | lr 0.01 | ms/batch 52.62 | loss  3.72 | ppl    41.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time: 15.65s | valid loss  4.15 | valid ppl    63.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |    10/  257 batches | lr 0.00 | ms/batch 58.84 | loss  4.11 | ppl    61.19\n",
            "| epoch  65 |    20/  257 batches | lr 0.00 | ms/batch 52.24 | loss  3.73 | ppl    41.58\n",
            "| epoch  65 |    30/  257 batches | lr 0.00 | ms/batch 52.24 | loss  3.71 | ppl    40.81\n",
            "| epoch  65 |    40/  257 batches | lr 0.00 | ms/batch 52.56 | loss  3.70 | ppl    40.56\n",
            "| epoch  65 |    50/  257 batches | lr 0.00 | ms/batch 52.48 | loss  3.71 | ppl    40.71\n",
            "| epoch  65 |    60/  257 batches | lr 0.00 | ms/batch 52.57 | loss  3.69 | ppl    39.99\n",
            "| epoch  65 |    70/  257 batches | lr 0.00 | ms/batch 52.60 | loss  3.70 | ppl    40.46\n",
            "| epoch  65 |    80/  257 batches | lr 0.00 | ms/batch 52.40 | loss  3.68 | ppl    39.49\n",
            "| epoch  65 |    90/  257 batches | lr 0.00 | ms/batch 52.27 | loss  3.73 | ppl    41.63\n",
            "| epoch  65 |   100/  257 batches | lr 0.00 | ms/batch 52.63 | loss  3.72 | ppl    41.32\n",
            "| epoch  65 |   110/  257 batches | lr 0.00 | ms/batch 52.66 | loss  3.67 | ppl    39.30\n",
            "| epoch  65 |   120/  257 batches | lr 0.00 | ms/batch 52.37 | loss  3.70 | ppl    40.44\n",
            "| epoch  65 |   130/  257 batches | lr 0.00 | ms/batch 52.42 | loss  3.70 | ppl    40.52\n",
            "| epoch  65 |   140/  257 batches | lr 0.00 | ms/batch 52.80 | loss  3.68 | ppl    39.51\n",
            "| epoch  65 |   150/  257 batches | lr 0.00 | ms/batch 52.64 | loss  3.67 | ppl    39.35\n",
            "| epoch  65 |   160/  257 batches | lr 0.00 | ms/batch 52.49 | loss  3.68 | ppl    39.73\n",
            "| epoch  65 |   170/  257 batches | lr 0.00 | ms/batch 52.74 | loss  3.70 | ppl    40.37\n",
            "| epoch  65 |   180/  257 batches | lr 0.00 | ms/batch 52.50 | loss  3.70 | ppl    40.63\n",
            "| epoch  65 |   190/  257 batches | lr 0.00 | ms/batch 52.25 | loss  3.70 | ppl    40.30\n",
            "| epoch  65 |   200/  257 batches | lr 0.00 | ms/batch 52.54 | loss  3.70 | ppl    40.53\n",
            "| epoch  65 |   210/  257 batches | lr 0.00 | ms/batch 52.70 | loss  3.64 | ppl    38.14\n",
            "| epoch  65 |   220/  257 batches | lr 0.00 | ms/batch 52.46 | loss  3.69 | ppl    40.15\n",
            "| epoch  65 |   230/  257 batches | lr 0.00 | ms/batch 52.24 | loss  3.69 | ppl    39.92\n",
            "| epoch  65 |   240/  257 batches | lr 0.00 | ms/batch 52.76 | loss  3.69 | ppl    39.85\n",
            "| epoch  65 |   250/  257 batches | lr 0.00 | ms/batch 52.48 | loss  3.73 | ppl    41.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time: 15.68s | valid loss  4.15 | valid ppl    63.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |    10/  257 batches | lr 0.00 | ms/batch 59.48 | loss  4.11 | ppl    60.67\n",
            "| epoch  66 |    20/  257 batches | lr 0.00 | ms/batch 52.12 | loss  3.72 | ppl    41.07\n",
            "| epoch  66 |    30/  257 batches | lr 0.00 | ms/batch 53.06 | loss  3.71 | ppl    40.67\n",
            "| epoch  66 |    40/  257 batches | lr 0.00 | ms/batch 52.14 | loss  3.70 | ppl    40.55\n",
            "| epoch  66 |    50/  257 batches | lr 0.00 | ms/batch 53.03 | loss  3.70 | ppl    40.36\n",
            "| epoch  66 |    60/  257 batches | lr 0.00 | ms/batch 52.22 | loss  3.69 | ppl    40.05\n",
            "| epoch  66 |    70/  257 batches | lr 0.00 | ms/batch 52.71 | loss  3.68 | ppl    39.75\n",
            "| epoch  66 |    80/  257 batches | lr 0.00 | ms/batch 52.41 | loss  3.67 | ppl    39.33\n",
            "| epoch  66 |    90/  257 batches | lr 0.00 | ms/batch 52.85 | loss  3.72 | ppl    41.07\n",
            "| epoch  66 |   100/  257 batches | lr 0.00 | ms/batch 52.37 | loss  3.72 | ppl    41.07\n",
            "| epoch  66 |   110/  257 batches | lr 0.00 | ms/batch 52.45 | loss  3.68 | ppl    39.54\n",
            "| epoch  66 |   120/  257 batches | lr 0.00 | ms/batch 52.62 | loss  3.71 | ppl    40.75\n",
            "| epoch  66 |   130/  257 batches | lr 0.00 | ms/batch 53.09 | loss  3.71 | ppl    40.66\n",
            "| epoch  66 |   140/  257 batches | lr 0.00 | ms/batch 52.38 | loss  3.67 | ppl    39.34\n",
            "| epoch  66 |   150/  257 batches | lr 0.00 | ms/batch 52.58 | loss  3.66 | ppl    38.89\n",
            "| epoch  66 |   160/  257 batches | lr 0.00 | ms/batch 52.32 | loss  3.69 | ppl    39.95\n",
            "| epoch  66 |   170/  257 batches | lr 0.00 | ms/batch 52.86 | loss  3.70 | ppl    40.46\n",
            "| epoch  66 |   180/  257 batches | lr 0.00 | ms/batch 52.47 | loss  3.69 | ppl    40.18\n",
            "| epoch  66 |   190/  257 batches | lr 0.00 | ms/batch 52.60 | loss  3.70 | ppl    40.52\n",
            "| epoch  66 |   200/  257 batches | lr 0.00 | ms/batch 52.29 | loss  3.69 | ppl    39.86\n",
            "| epoch  66 |   210/  257 batches | lr 0.00 | ms/batch 52.34 | loss  3.64 | ppl    37.92\n",
            "| epoch  66 |   220/  257 batches | lr 0.00 | ms/batch 52.33 | loss  3.69 | ppl    39.87\n",
            "| epoch  66 |   230/  257 batches | lr 0.00 | ms/batch 52.71 | loss  3.68 | ppl    39.60\n",
            "| epoch  66 |   240/  257 batches | lr 0.00 | ms/batch 52.43 | loss  3.70 | ppl    40.28\n",
            "| epoch  66 |   250/  257 batches | lr 0.00 | ms/batch 52.61 | loss  3.71 | ppl    40.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time: 15.69s | valid loss  4.15 | valid ppl    63.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |    10/  257 batches | lr 0.00 | ms/batch 60.06 | loss  4.10 | ppl    60.15\n",
            "| epoch  67 |    20/  257 batches | lr 0.00 | ms/batch 52.75 | loss  3.71 | ppl    40.82\n",
            "| epoch  67 |    30/  257 batches | lr 0.00 | ms/batch 52.70 | loss  3.70 | ppl    40.47\n",
            "| epoch  67 |    40/  257 batches | lr 0.00 | ms/batch 52.61 | loss  3.70 | ppl    40.33\n",
            "| epoch  67 |    50/  257 batches | lr 0.00 | ms/batch 52.96 | loss  3.71 | ppl    40.67\n",
            "| epoch  67 |    60/  257 batches | lr 0.00 | ms/batch 52.29 | loss  3.67 | ppl    39.40\n",
            "| epoch  67 |    70/  257 batches | lr 0.00 | ms/batch 52.71 | loss  3.68 | ppl    39.79\n",
            "| epoch  67 |    80/  257 batches | lr 0.00 | ms/batch 52.51 | loss  3.68 | ppl    39.46\n",
            "| epoch  67 |    90/  257 batches | lr 0.00 | ms/batch 52.63 | loss  3.71 | ppl    40.72\n",
            "| epoch  67 |   100/  257 batches | lr 0.00 | ms/batch 52.36 | loss  3.71 | ppl    40.94\n",
            "| epoch  67 |   110/  257 batches | lr 0.00 | ms/batch 52.85 | loss  3.67 | ppl    39.06\n",
            "| epoch  67 |   120/  257 batches | lr 0.00 | ms/batch 52.07 | loss  3.70 | ppl    40.49\n",
            "| epoch  67 |   130/  257 batches | lr 0.00 | ms/batch 52.95 | loss  3.70 | ppl    40.43\n",
            "| epoch  67 |   140/  257 batches | lr 0.00 | ms/batch 52.28 | loss  3.67 | ppl    39.29\n",
            "| epoch  67 |   150/  257 batches | lr 0.00 | ms/batch 52.78 | loss  3.66 | ppl    38.95\n",
            "| epoch  67 |   160/  257 batches | lr 0.00 | ms/batch 52.40 | loss  3.67 | ppl    39.41\n",
            "| epoch  67 |   170/  257 batches | lr 0.00 | ms/batch 52.72 | loss  3.69 | ppl    39.91\n",
            "| epoch  67 |   180/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.70 | ppl    40.33\n",
            "| epoch  67 |   190/  257 batches | lr 0.00 | ms/batch 52.59 | loss  3.70 | ppl    40.27\n",
            "| epoch  67 |   200/  257 batches | lr 0.00 | ms/batch 52.07 | loss  3.69 | ppl    39.94\n",
            "| epoch  67 |   210/  257 batches | lr 0.00 | ms/batch 52.67 | loss  3.63 | ppl    37.89\n",
            "| epoch  67 |   220/  257 batches | lr 0.00 | ms/batch 52.74 | loss  3.68 | ppl    39.73\n",
            "| epoch  67 |   230/  257 batches | lr 0.00 | ms/batch 52.28 | loss  3.68 | ppl    39.65\n",
            "| epoch  67 |   240/  257 batches | lr 0.00 | ms/batch 52.59 | loss  3.69 | ppl    39.85\n",
            "| epoch  67 |   250/  257 batches | lr 0.00 | ms/batch 52.59 | loss  3.71 | ppl    40.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time: 15.71s | valid loss  4.15 | valid ppl    63.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |    10/  257 batches | lr 0.00 | ms/batch 59.15 | loss  4.10 | ppl    60.16\n",
            "| epoch  68 |    20/  257 batches | lr 0.00 | ms/batch 52.58 | loss  3.71 | ppl    40.86\n",
            "| epoch  68 |    30/  257 batches | lr 0.00 | ms/batch 53.16 | loss  3.69 | ppl    40.14\n",
            "| epoch  68 |    40/  257 batches | lr 0.00 | ms/batch 52.33 | loss  3.70 | ppl    40.26\n",
            "| epoch  68 |    50/  257 batches | lr 0.00 | ms/batch 52.90 | loss  3.69 | ppl    39.91\n",
            "| epoch  68 |    60/  257 batches | lr 0.00 | ms/batch 52.12 | loss  3.68 | ppl    39.64\n",
            "| epoch  68 |    70/  257 batches | lr 0.00 | ms/batch 52.83 | loss  3.67 | ppl    39.36\n",
            "| epoch  68 |    80/  257 batches | lr 0.00 | ms/batch 52.14 | loss  3.67 | ppl    39.26\n",
            "| epoch  68 |    90/  257 batches | lr 0.00 | ms/batch 52.85 | loss  3.71 | ppl    40.71\n",
            "| epoch  68 |   100/  257 batches | lr 0.00 | ms/batch 52.33 | loss  3.71 | ppl    40.72\n",
            "| epoch  68 |   110/  257 batches | lr 0.00 | ms/batch 52.33 | loss  3.67 | ppl    39.18\n",
            "| epoch  68 |   120/  257 batches | lr 0.00 | ms/batch 52.55 | loss  3.69 | ppl    39.91\n",
            "| epoch  68 |   130/  257 batches | lr 0.00 | ms/batch 52.58 | loss  3.71 | ppl    40.90\n",
            "| epoch  68 |   140/  257 batches | lr 0.00 | ms/batch 52.33 | loss  3.66 | ppl    38.70\n",
            "| epoch  68 |   150/  257 batches | lr 0.00 | ms/batch 52.63 | loss  3.66 | ppl    38.87\n",
            "| epoch  68 |   160/  257 batches | lr 0.00 | ms/batch 52.62 | loss  3.67 | ppl    39.43\n",
            "| epoch  68 |   170/  257 batches | lr 0.00 | ms/batch 52.62 | loss  3.68 | ppl    39.68\n",
            "| epoch  68 |   180/  257 batches | lr 0.00 | ms/batch 52.77 | loss  3.68 | ppl    39.76\n",
            "| epoch  68 |   190/  257 batches | lr 0.00 | ms/batch 52.67 | loss  3.69 | ppl    40.19\n",
            "| epoch  68 |   200/  257 batches | lr 0.00 | ms/batch 52.31 | loss  3.68 | ppl    39.58\n",
            "| epoch  68 |   210/  257 batches | lr 0.00 | ms/batch 52.61 | loss  3.63 | ppl    37.81\n",
            "| epoch  68 |   220/  257 batches | lr 0.00 | ms/batch 52.47 | loss  3.68 | ppl    39.65\n",
            "| epoch  68 |   230/  257 batches | lr 0.00 | ms/batch 52.68 | loss  3.67 | ppl    39.31\n",
            "| epoch  68 |   240/  257 batches | lr 0.00 | ms/batch 52.50 | loss  3.67 | ppl    39.44\n",
            "| epoch  68 |   250/  257 batches | lr 0.00 | ms/batch 52.70 | loss  3.71 | ppl    40.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time: 15.70s | valid loss  4.15 | valid ppl    63.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |    10/  257 batches | lr 0.00 | ms/batch 55.96 | loss  4.09 | ppl    59.83\n",
            "| epoch  69 |    20/  257 batches | lr 0.00 | ms/batch 53.14 | loss  3.70 | ppl    40.35\n",
            "| epoch  69 |    30/  257 batches | lr 0.00 | ms/batch 51.93 | loss  3.70 | ppl    40.32\n",
            "| epoch  69 |    40/  257 batches | lr 0.00 | ms/batch 53.00 | loss  3.69 | ppl    40.01\n",
            "| epoch  69 |    50/  257 batches | lr 0.00 | ms/batch 52.02 | loss  3.69 | ppl    39.99\n",
            "| epoch  69 |    60/  257 batches | lr 0.00 | ms/batch 52.61 | loss  3.66 | ppl    38.97\n",
            "| epoch  69 |    70/  257 batches | lr 0.00 | ms/batch 52.29 | loss  3.68 | ppl    39.64\n",
            "| epoch  69 |    80/  257 batches | lr 0.00 | ms/batch 53.05 | loss  3.67 | ppl    39.11\n",
            "| epoch  69 |    90/  257 batches | lr 0.00 | ms/batch 52.05 | loss  3.70 | ppl    40.57\n",
            "| epoch  69 |   100/  257 batches | lr 0.00 | ms/batch 52.24 | loss  3.71 | ppl    40.93\n",
            "| epoch  69 |   110/  257 batches | lr 0.00 | ms/batch 52.15 | loss  3.66 | ppl    38.70\n",
            "| epoch  69 |   120/  257 batches | lr 0.00 | ms/batch 53.10 | loss  3.69 | ppl    39.89\n",
            "| epoch  69 |   130/  257 batches | lr 0.00 | ms/batch 52.61 | loss  3.69 | ppl    40.12\n",
            "| epoch  69 |   140/  257 batches | lr 0.00 | ms/batch 52.52 | loss  3.65 | ppl    38.65\n",
            "| epoch  69 |   150/  257 batches | lr 0.00 | ms/batch 52.24 | loss  3.65 | ppl    38.49\n",
            "| epoch  69 |   160/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.67 | ppl    39.12\n",
            "| epoch  69 |   170/  257 batches | lr 0.00 | ms/batch 52.60 | loss  3.68 | ppl    39.84\n",
            "| epoch  69 |   180/  257 batches | lr 0.00 | ms/batch 52.42 | loss  3.68 | ppl    39.59\n",
            "| epoch  69 |   190/  257 batches | lr 0.00 | ms/batch 52.65 | loss  3.69 | ppl    39.94\n",
            "| epoch  69 |   200/  257 batches | lr 0.00 | ms/batch 52.24 | loss  3.68 | ppl    39.47\n",
            "| epoch  69 |   210/  257 batches | lr 0.00 | ms/batch 52.59 | loss  3.63 | ppl    37.53\n",
            "| epoch  69 |   220/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.67 | ppl    39.40\n",
            "| epoch  69 |   230/  257 batches | lr 0.00 | ms/batch 52.56 | loss  3.67 | ppl    39.12\n",
            "| epoch  69 |   240/  257 batches | lr 0.00 | ms/batch 52.31 | loss  3.68 | ppl    39.51\n",
            "| epoch  69 |   250/  257 batches | lr 0.00 | ms/batch 52.75 | loss  3.69 | ppl    40.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time: 15.67s | valid loss  4.15 | valid ppl    63.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |    10/  257 batches | lr 0.00 | ms/batch 59.52 | loss  4.08 | ppl    59.25\n",
            "| epoch  70 |    20/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.70 | ppl    40.57\n",
            "| epoch  70 |    30/  257 batches | lr 0.00 | ms/batch 52.71 | loss  3.68 | ppl    39.71\n",
            "| epoch  70 |    40/  257 batches | lr 0.00 | ms/batch 52.54 | loss  3.69 | ppl    39.89\n",
            "| epoch  70 |    50/  257 batches | lr 0.00 | ms/batch 52.68 | loss  3.69 | ppl    39.90\n",
            "| epoch  70 |    60/  257 batches | lr 0.00 | ms/batch 52.74 | loss  3.66 | ppl    39.02\n",
            "| epoch  70 |    70/  257 batches | lr 0.00 | ms/batch 52.72 | loss  3.67 | ppl    39.06\n",
            "| epoch  70 |    80/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.66 | ppl    38.96\n",
            "| epoch  70 |    90/  257 batches | lr 0.00 | ms/batch 52.25 | loss  3.70 | ppl    40.33\n",
            "| epoch  70 |   100/  257 batches | lr 0.00 | ms/batch 52.20 | loss  3.69 | ppl    40.13\n",
            "| epoch  70 |   110/  257 batches | lr 0.00 | ms/batch 52.12 | loss  3.66 | ppl    38.90\n",
            "| epoch  70 |   120/  257 batches | lr 0.00 | ms/batch 52.39 | loss  3.69 | ppl    39.89\n",
            "| epoch  70 |   130/  257 batches | lr 0.00 | ms/batch 52.45 | loss  3.69 | ppl    39.93\n",
            "| epoch  70 |   140/  257 batches | lr 0.00 | ms/batch 52.07 | loss  3.66 | ppl    38.77\n",
            "| epoch  70 |   150/  257 batches | lr 0.00 | ms/batch 52.60 | loss  3.65 | ppl    38.54\n",
            "| epoch  70 |   160/  257 batches | lr 0.00 | ms/batch 51.90 | loss  3.66 | ppl    39.02\n",
            "| epoch  70 |   170/  257 batches | lr 0.00 | ms/batch 52.18 | loss  3.68 | ppl    39.50\n",
            "| epoch  70 |   180/  257 batches | lr 0.00 | ms/batch 52.46 | loss  3.67 | ppl    39.18\n",
            "| epoch  70 |   190/  257 batches | lr 0.00 | ms/batch 52.32 | loss  3.69 | ppl    40.13\n",
            "| epoch  70 |   200/  257 batches | lr 0.00 | ms/batch 52.34 | loss  3.67 | ppl    39.20\n",
            "| epoch  70 |   210/  257 batches | lr 0.00 | ms/batch 52.75 | loss  3.62 | ppl    37.27\n",
            "| epoch  70 |   220/  257 batches | lr 0.00 | ms/batch 52.03 | loss  3.67 | ppl    39.08\n",
            "| epoch  70 |   230/  257 batches | lr 0.00 | ms/batch 52.18 | loss  3.66 | ppl    39.00\n",
            "| epoch  70 |   240/  257 batches | lr 0.00 | ms/batch 52.69 | loss  3.67 | ppl    39.29\n",
            "| epoch  70 |   250/  257 batches | lr 0.00 | ms/batch 52.46 | loss  3.70 | ppl    40.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time: 15.68s | valid loss  4.15 | valid ppl    63.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  71 |    10/  257 batches | lr 0.00 | ms/batch 56.81 | loss  4.08 | ppl    59.28\n",
            "| epoch  71 |    20/  257 batches | lr 0.00 | ms/batch 53.25 | loss  3.69 | ppl    40.08\n",
            "| epoch  71 |    30/  257 batches | lr 0.00 | ms/batch 51.05 | loss  3.68 | ppl    39.71\n",
            "| epoch  71 |    40/  257 batches | lr 0.00 | ms/batch 52.88 | loss  3.68 | ppl    39.56\n",
            "| epoch  71 |    50/  257 batches | lr 0.00 | ms/batch 52.17 | loss  3.69 | ppl    39.92\n",
            "| epoch  71 |    60/  257 batches | lr 0.00 | ms/batch 52.28 | loss  3.67 | ppl    39.12\n",
            "| epoch  71 |    70/  257 batches | lr 0.00 | ms/batch 52.12 | loss  3.67 | ppl    39.27\n",
            "| epoch  71 |    80/  257 batches | lr 0.00 | ms/batch 52.19 | loss  3.65 | ppl    38.38\n",
            "| epoch  71 |    90/  257 batches | lr 0.00 | ms/batch 52.06 | loss  3.68 | ppl    39.72\n",
            "| epoch  71 |   100/  257 batches | lr 0.00 | ms/batch 51.69 | loss  3.70 | ppl    40.30\n",
            "| epoch  71 |   110/  257 batches | lr 0.00 | ms/batch 52.45 | loss  3.65 | ppl    38.65\n",
            "| epoch  71 |   120/  257 batches | lr 0.00 | ms/batch 52.06 | loss  3.68 | ppl    39.61\n",
            "| epoch  71 |   130/  257 batches | lr 0.00 | ms/batch 52.32 | loss  3.69 | ppl    40.14\n",
            "| epoch  71 |   140/  257 batches | lr 0.00 | ms/batch 52.79 | loss  3.65 | ppl    38.63\n",
            "| epoch  71 |   150/  257 batches | lr 0.00 | ms/batch 52.47 | loss  3.64 | ppl    38.19\n",
            "| epoch  71 |   160/  257 batches | lr 0.00 | ms/batch 52.45 | loss  3.66 | ppl    38.92\n",
            "| epoch  71 |   170/  257 batches | lr 0.00 | ms/batch 52.56 | loss  3.67 | ppl    39.21\n",
            "| epoch  71 |   180/  257 batches | lr 0.00 | ms/batch 51.87 | loss  3.68 | ppl    39.53\n",
            "| epoch  71 |   190/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.68 | ppl    39.81\n",
            "| epoch  71 |   200/  257 batches | lr 0.00 | ms/batch 52.36 | loss  3.67 | ppl    39.21\n",
            "| epoch  71 |   210/  257 batches | lr 0.00 | ms/batch 52.59 | loss  3.61 | ppl    37.06\n",
            "| epoch  71 |   220/  257 batches | lr 0.00 | ms/batch 52.55 | loss  3.66 | ppl    39.04\n",
            "| epoch  71 |   230/  257 batches | lr 0.00 | ms/batch 52.03 | loss  3.65 | ppl    38.53\n",
            "| epoch  71 |   240/  257 batches | lr 0.00 | ms/batch 52.68 | loss  3.67 | ppl    39.15\n",
            "| epoch  71 |   250/  257 batches | lr 0.00 | ms/batch 52.26 | loss  3.68 | ppl    39.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time: 15.63s | valid loss  4.15 | valid ppl    63.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |    10/  257 batches | lr 0.00 | ms/batch 58.23 | loss  4.09 | ppl    59.45\n",
            "| epoch  72 |    20/  257 batches | lr 0.00 | ms/batch 52.34 | loss  3.69 | ppl    40.07\n",
            "| epoch  72 |    30/  257 batches | lr 0.00 | ms/batch 52.58 | loss  3.68 | ppl    39.55\n",
            "| epoch  72 |    40/  257 batches | lr 0.00 | ms/batch 52.55 | loss  3.67 | ppl    39.30\n",
            "| epoch  72 |    50/  257 batches | lr 0.00 | ms/batch 52.37 | loss  3.67 | ppl    39.39\n",
            "| epoch  72 |    60/  257 batches | lr 0.00 | ms/batch 52.33 | loss  3.66 | ppl    38.74\n",
            "| epoch  72 |    70/  257 batches | lr 0.00 | ms/batch 52.59 | loss  3.66 | ppl    38.80\n",
            "| epoch  72 |    80/  257 batches | lr 0.00 | ms/batch 52.20 | loss  3.66 | ppl    38.81\n",
            "| epoch  72 |    90/  257 batches | lr 0.00 | ms/batch 52.37 | loss  3.69 | ppl    39.86\n",
            "| epoch  72 |   100/  257 batches | lr 0.00 | ms/batch 52.93 | loss  3.70 | ppl    40.46\n",
            "| epoch  72 |   110/  257 batches | lr 0.00 | ms/batch 52.10 | loss  3.65 | ppl    38.33\n",
            "| epoch  72 |   120/  257 batches | lr 0.00 | ms/batch 52.53 | loss  3.67 | ppl    39.39\n",
            "| epoch  72 |   130/  257 batches | lr 0.00 | ms/batch 52.38 | loss  3.68 | ppl    39.72\n",
            "| epoch  72 |   140/  257 batches | lr 0.00 | ms/batch 52.50 | loss  3.65 | ppl    38.30\n",
            "| epoch  72 |   150/  257 batches | lr 0.00 | ms/batch 52.65 | loss  3.64 | ppl    38.24\n",
            "| epoch  72 |   160/  257 batches | lr 0.00 | ms/batch 52.55 | loss  3.65 | ppl    38.60\n",
            "| epoch  72 |   170/  257 batches | lr 0.00 | ms/batch 52.16 | loss  3.68 | ppl    39.56\n",
            "| epoch  72 |   180/  257 batches | lr 0.00 | ms/batch 52.64 | loss  3.68 | ppl    39.47\n",
            "| epoch  72 |   190/  257 batches | lr 0.00 | ms/batch 52.62 | loss  3.67 | ppl    39.23\n",
            "| epoch  72 |   200/  257 batches | lr 0.00 | ms/batch 52.41 | loss  3.67 | ppl    39.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "Exiting from training early\n",
            "=========================================================================================\n",
            "| End of training | test loss  3.97 | test ppl    53.03\n",
            "=========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikajkc9I3Sl2"
      },
      "source": [
        "def beam_search_decode(device, net, words, vocab_to_int, int_to_vocab, top_k):\n",
        "  net.eval()\n",
        "  words = words.split(' ')\n",
        "  state_h, state_c = net.init_hidden(len(words))\n",
        "  state_h = state_h.to(device)\n",
        "  state_c = state_c.to(device)\n",
        "  ix = torch.tensor([[vocab_to_int[w] for w in words]]).to(device)\n",
        "  output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "  prob, top_ix = torch.topk(nn.functional.softmax(output[0][-1], dim=0), k=top_k)\n",
        "  #print(top_ix)\n",
        "  list_ids = [[vocab_to_int[w] for w in words] + [id] for id in top_ix.tolist()]\n",
        "  outputs = [output for _ in range(top_k)]\n",
        "  hiddens = [(state_h, state_c) for _ in range(top_k)] \n",
        "  #print(\"avant beam search, top indices : \",top_ix.tolist(), \"de proba\", prob.tolist())\n",
        "  #print(list_ids)\n",
        "  for i in range(50):\n",
        "    probas = torch.tensor([[0 for i in range(top_k)] for k in range(top_k)]).float().to(device)\n",
        "    indxes = torch.tensor([[0 for i in range(top_k)] for k in range(top_k)]).to(device)\n",
        "    for k in range(top_k):\n",
        "      ix = torch.tensor([list_ids[k][i+1:]]).to(device)\n",
        "      output, hiddens[k] = net(ix, hiddens[k])\n",
        "      pro, indxes[k] = torch.topk(nn.functional.softmax(output[0][-1], dim=0), k=top_k)\n",
        "      #print(\"probas du choix \", k+1,\" : \", pro.tolist())\n",
        "      probas[k] = pro * prob[k]\n",
        "    #print(indxes.tolist())\n",
        "    #print(list_ids)\n",
        "    prob, indices = torch.topk(probas.flatten(), top_k)\n",
        "    for k in range(top_k):\n",
        "      top_ix[k] = indxes.flatten()[indices[k]]\n",
        "    indices = indices // top_k\n",
        "    temp1 = []\n",
        "    temp2 = []\n",
        "    for k in range(top_k):\n",
        "      temp1.append(hiddens[indices.tolist()[k]])\n",
        "      temp2.append(list_ids[indices.tolist()[k]] + [top_ix.tolist()[k]])\n",
        "    hiddens = temp1\n",
        "    list_ids = temp2\n",
        "    print(\"top indices : \",top_ix.tolist(), \"de proba\", prob.tolist())\n",
        "  best_branch = list_ids[torch.argmax(prob)]\n",
        "  words = []\n",
        "  for id in best_branch:\n",
        "    words.append(int_to_vocab[id])\n",
        "  print(' '.join(words))"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLCMetacxM6v"
      },
      "source": [
        "def predict(device, net, words, vocab_to_int, int_to_vocab, top_k):\n",
        "  net.eval()\n",
        "  words = words.split(' ')\n",
        "  state_h, state_c = net.init_hidden(len(words))\n",
        "  state_h = state_h.to(device)\n",
        "  state_c = state_c.to(device)\n",
        "  for i in range(50):\n",
        "      ix = torch.tensor([[vocab_to_int[w] for w in words[i:]]]).to(device)\n",
        "      output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "      _, top_ix = torch.topk(nn.functional.softmax(output[0][-1], dim=0), k=1)\n",
        "      words.append(int_to_vocab[top_ix[0]])\n",
        "  print(' '.join(words))"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V_Q2YLG0qCB",
        "outputId": "63cf0bf6-3e37-4b0b-88d5-3dafe613d1a6"
      },
      "source": [
        "predict(device, model, 'Ce grand jour où l’ hymen étouffant la vengeance <eos> Entre le Parthe et nous remet l’ intelligence , <eos> Affranchit', corpus.dictionary.word2idx, corpus.dictionary.idx2word,10)\n",
        "beam_search_decode(device, model, 'Ce grand jour où l’ hymen étouffant la vengeance <eos> Entre le Parthe et nous remet l’ intelligence , <eos> Affranchit', corpus.dictionary.word2idx, corpus.dictionary.idx2word,10)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ce grand jour où l’ hymen étouffant la vengeance <eos> Entre le Parthe et nous remet l’ intelligence , <eos> Affranchit , <eos> Et je vous ai promis , et je vous ai promis . <eos> Je vous ai vu , Madame , et je vous ai promis . <eos> Je vous ai vu , Madame , et je vous ai promis . <eos> Je vous ai vu , Madame ,\n",
            "top indices :  [11, 11, 11, 11, 10, 11, 11, 16, 33, 2] de proba [0.31770649552345276, 0.2779606282711029, 0.07023846358060837, 0.03300094231963158, 0.02745000645518303, 0.024644888937473297, 0.012532630935311317, 0.009786729700863361, 0.005823318846523762, 0.003604043507948518]\n",
            "top indices :  [61, 10, 12, 33, 141, 12, 61, 141, 245, 245] de proba [0.07251192629337311, 0.027372043579816818, 0.026348581537604332, 0.01595715805888176, 0.015921423211693764, 0.015702245756983757, 0.012015080079436302, 0.009843970648944378, 0.00969643983989954, 0.00937218964099884]\n",
            "top indices :  [11, 2, 20, 20, 41, 288, 40, 115, 82, 299] de proba [0.005344506818801165, 0.004971526097506285, 0.003905557096004486, 0.0032687592320144176, 0.0030449044425040483, 0.0029449977446347475, 0.0028743750881403685, 0.0026743668131530285, 0.0026571988128125668, 0.0018574311397969723]\n",
            "top indices :  [334, 20, 12, 237, 20, 82, 796, 2, 20, 334] de proba [0.0009182525682263076, 0.0005460018874146044, 0.00048733886796981096, 0.00043684730189852417, 0.00043444495531730354, 0.0004140253586228937, 0.0004001632914878428, 0.00039903310243971646, 0.00035908157587982714, 0.00031617426429875195]\n",
            "top indices :  [334, 641, 20, 238, 1402, 303, 641, 57, 40, 20] de proba [0.00025799308787100017, 0.0001152368204202503, 8.95220146048814e-05, 8.524692384526134e-05, 6.706490967189893e-05, 6.487928476417437e-05, 5.724108632421121e-05, 5.688110468327068e-05, 5.6624834542162716e-05, 5.4691481636837125e-05]\n",
            "top indices :  [669, 238, 139, 298, 480, 1969, 1, 2144, 1, 40] de proba [6.847662734799087e-05, 6.165691593196243e-05, 2.5435032512177713e-05, 2.444465644657612e-05, 1.7408307030564174e-05, 1.1630888366198633e-05, 1.1064159480156377e-05, 1.0500069947738666e-05, 8.401314516959246e-06, 8.028876436583232e-06]\n",
            "top indices :  [104, 428, 89, 5610, 41, 5610, 89, 41, 115, 104] de proba [5.0193270908494014e-06, 3.7858992527617374e-06, 3.5976606795884436e-06, 3.5755508633883437e-06, 3.4935526400659e-06, 3.4611102819326334e-06, 3.3013498068612535e-06, 3.2655309496476548e-06, 3.0900225738150766e-06, 2.9006851036683656e-06]\n",
            "top indices :  [41, 20, 20, 89, 20, 41, 1638, 297, 41, 89] de proba [1.4999833410911378e-06, 1.1404213182686362e-06, 1.0261691159030306e-06, 1.0048788681160659e-06, 8.353929388249526e-07, 7.554314152002917e-07, 7.125665320018015e-07, 6.430911412280693e-07, 6.282248250499833e-07, 5.274902719065722e-07]\n",
            "top indices :  [1, 20, 1, 106, 1, 90, 57, 408, 162, 104] de proba [4.386267846712144e-07, 2.508900251996238e-07, 2.3607411492321262e-07, 1.799187998585694e-07, 1.4926406777249213e-07, 1.4029419048711134e-07, 1.1506350716672387e-07, 9.56203294322222e-08, 9.45892821846428e-08, 9.069425743746251e-08]\n",
            "top indices :  [16, 40, 1861, 133, 16, 909, 568, 41, 2, 57] de proba [8.200791512535943e-08, 4.116850860214072e-08, 3.228137401833919e-08, 2.99770981371239e-08, 2.6220078552796622e-08, 2.3945728955254708e-08, 2.16108801964765e-08, 2.030521706331001e-08, 1.7441269761775402e-08, 1.6841520178445535e-08]\n",
            "top indices :  [233, 2, 2, 20, 20, 104, 780, 2147, 115, 115] de proba [9.898482922210405e-09, 6.75528610827314e-09, 5.519441348411647e-09, 4.425915189898433e-09, 4.369871575704565e-09, 3.848150242902193e-09, 3.54975426830606e-09, 3.5469305270652285e-09, 3.2253049120356536e-09, 3.202518028544432e-09]\n",
            "top indices :  [669, 82, 504, 20, 20, 237, 20, 198, 20, 1392] de proba [2.0040864523451773e-09, 1.0399024974461213e-09, 9.34062494017951e-10, 9.259483735313268e-10, 9.133869216526591e-10, 8.049273469978857e-10, 7.024559267598818e-10, 6.791399664862752e-10, 6.154365350674595e-10, 5.683977177817212e-10]\n",
            "top indices :  [198, 40, 41, 504, 20, 133, 57, 334, 115, 40] de proba [3.8884723219112516e-10, 2.893518757929314e-10, 2.132950482902629e-10, 2.0198039074603713e-10, 1.6255752299798587e-10, 1.219618156467206e-10, 1.1822018364249232e-10, 1.0664323590869884e-10, 1.0179750098426865e-10, 9.061434935730972e-11]\n",
            "top indices :  [2, 669, 298, 238, 233, 780, 2, 574, 40, 504] de proba [1.917221520431056e-10, 1.3592642289506074e-10, 6.829629223270572e-11, 5.573309522222125e-11, 4.6207943721343625e-11, 3.3319298708978096e-11, 3.2809931854727026e-11, 2.7364303531451917e-11, 2.3904987364598007e-11, 2.329424847458128e-11]\n",
            "top indices :  [20, 10, 8, 408, 41, 41, 26, 421, 1112, 89] de proba [5.7574809503302404e-11, 2.0437538814088718e-11, 1.9249038127333584e-11, 1.7246008440774396e-11, 1.6629243121402126e-11, 1.457601400689512e-11, 1.3506463308887717e-11, 1.328835392416794e-11, 1.297031058944409e-11, 1.2740030384816858e-11]\n",
            "top indices :  [11, 1644, 8023, 1563, 1704, 297, 644, 1563, 4004, 106] de proba [2.0402313519185533e-11, 1.4310910095849394e-11, 8.072389111324352e-12, 3.707897270471827e-12, 3.1399863178321885e-12, 2.902536501078745e-12, 2.869074335748456e-12, 2.2445018933725525e-12, 2.1754468886026057e-12, 2.0414735440316134e-12]\n",
            "top indices :  [10, 10, 10, 12, 10, 10, 1, 10, 10, 10] de proba [1.0090666149875638e-11, 5.00380119283772e-12, 2.646819178761528e-12, 2.5610394881192544e-12, 2.2266056186326377e-12, 1.9002919897370685e-12, 1.884683815261967e-12, 1.576164979782968e-12, 1.4825736124879363e-12, 1.4486327718984948e-12]\n",
            "top indices :  [11, 11, 11, 11, 11, 11, 11, 11, 11, 20] de proba [1.0070230239966893e-11, 4.988844407027848e-12, 2.639543965343716e-12, 2.2220313696669214e-12, 1.8936273989828e-12, 1.88446263801878e-12, 1.5719658647689316e-12, 1.4775219893056746e-12, 1.4451696133191416e-12, 4.0373363289700204e-13]\n",
            "top indices :  [12, 141, 12, 61, 141, 245, 61, 12, 1033, 356] de proba [1.1703032206517028e-12, 6.727026704775318e-13, 6.135362400419564e-13, 5.531151166422721e-13, 3.366344475310562e-13, 3.3501237266080064e-13, 3.1693934586171646e-13, 3.031343893348387e-13, 2.7014130407447545e-13, 2.664685150050722e-13]\n",
            "top indices :  [20, 82, 334, 237, 20, 40, 82, 504, 796, 1235] de proba [1.7066767920778658e-13, 1.3593221329360333e-13, 1.2069837317107979e-13, 9.604544535992549e-14, 8.767388670529591e-14, 7.361242827319883e-14, 7.08943876368863e-14, 6.273218842176367e-14, 5.746999962507812e-14, 5.63001963029431e-14]\n",
            "top indices :  [334, 796, 20, 334, 641, 1235, 57, 40, 20, 1644] de proba [5.422476229426272e-14, 2.1379845119230863e-14, 2.0729865916825803e-14, 1.772721712803814e-14, 1.5570750865425732e-14, 1.4330115260109515e-14, 1.2753555705274661e-14, 1.1586909274934054e-14, 1.0917259426394908e-14, 1.0725555541640525e-14]\n",
            "top indices :  [669, 238, 298, 238, 139, 1, 669, 238, 641, 40] de proba [1.3638848283723491e-14, 1.2596346390264263e-14, 6.407847868175566e-15, 5.545138035133483e-15, 5.276288083609073e-15, 4.752248704417098e-15, 3.979614472568406e-15, 3.8530101520082e-15, 3.331104872326832e-15, 3.20252654148305e-15]\n",
            "top indices :  [41, 16, 41, 641, 641, 104, 41, 89, 89, 104] de proba [1.1670116074199923e-15, 1.0801317556574739e-15, 1.064020659605105e-15, 1.0030908268520247e-15, 8.97583344150845e-16, 8.217227557573946e-16, 7.556246985370829e-16, 7.552462336283378e-16, 7.40870443387097e-16, 6.153550366201459e-16]\n",
            "top indices :  [2, 1211, 684, 20, 115, 299, 115, 684, 106, 106] de proba [2.1884640703954608e-16, 1.2755933697334519e-16, 1.187880858114003e-16, 9.98432211816575e-17, 9.360562423596253e-17, 8.768900645516264e-17, 7.401636605670623e-17, 7.365795200600946e-17, 7.110859459301082e-17, 7.020946911950039e-17]\n",
            "top indices :  [283, 297, 1392, 334, 297, 1235, 20, 1, 20, 796] de proba [4.7969738969166973e-17, 3.8627997882356507e-17, 3.801003109905284e-17, 3.7331977916053323e-17, 3.1168522823022706e-17, 2.9808452607528316e-17, 2.8858753311366384e-17, 2.4692496028843e-17, 2.271891587918538e-17, 1.932011180590502e-17]\n",
            "top indices :  [1, 641, 1, 40, 1, 1, 16, 10, 41, 40] de proba [1.2604567420735073e-17, 1.1282378768573162e-17, 8.483323652785599e-18, 4.9242835279154475e-18, 4.5647188689866095e-18, 4.511774760289847e-18, 3.653028521971489e-18, 3.491827150606849e-18, 3.3965398731486497e-18, 3.3412382997061108e-18]\n",
            "top indices :  [16, 16, 2, 2, 42, 16, 10, 1, 2740, 2] de proba [3.1261217096055704e-18, 2.7195384502979933e-18, 1.2764041018595243e-18, 1.196729031282651e-18, 9.22654315841781e-19, 8.533316174261619e-19, 7.422761061435941e-19, 6.181542948087738e-19, 5.929222358973977e-19, 5.913105778714147e-19]\n",
            "top indices :  [10, 2, 2, 20, 20, 20, 40, 20, 133, 299] de proba [7.398992543522113e-19, 4.925386986852593e-19, 4.460880611946143e-19, 2.9527687965485847e-19, 2.528383783278254e-19, 2.31214739742347e-19, 2.0432605778387734e-19, 1.6708928173888397e-19, 1.554885906357106e-19, 1.420158734840561e-19]\n",
            "top indices :  [2, 334, 233, 12, 20, 20, 1392, 167, 141, 20] de proba [1.0238181816395895e-19, 6.615422831567441e-20, 5.905535137404726e-20, 5.832829838970436e-20, 5.741443829624373e-20, 5.509218042528939e-20, 4.532738761110905e-20, 3.644197502977782e-20, 3.641361501322947e-20, 3.579180783713687e-20]\n",
            "top indices :  [20, 2360, 504, 1392, 303, 3, 641, 20, 334, 20] de proba [2.0100199694941606e-20, 1.7735401799164738e-20, 1.3089920743943556e-20, 9.683977106775188e-21, 8.404939391092266e-21, 8.312296778073461e-21, 8.061007547474234e-21, 6.68050813250537e-21, 5.760310090718474e-21, 5.568752347633525e-21]\n",
            "top indices :  [2360, 40, 334, 504, 41, 89, 133, 1535, 6516, 20] de proba [5.4970271451340115e-21, 3.556805144247344e-21, 2.7800227723360972e-21, 2.6622111293067705e-21, 2.6143253286065846e-21, 2.1523849422772825e-21, 2.1083345454329577e-21, 1.274884445058468e-21, 1.1221536026913816e-21, 1.067808684629893e-21]\n",
            "top indices :  [2, 1181, 794, 233, 2212, 568, 1181, 1181, 780, 10] de proba [2.6258493116326407e-21, 2.61894853313861e-21, 1.4480926523992516e-21, 9.700471847515449e-22, 9.1611030341556e-22, 9.142147148365246e-22, 7.296191425566946e-22, 7.163336646837162e-22, 7.104479292936515e-22, 5.08381094825319e-22]\n",
            "top indices :  [1, 10, 10, 11, 1, 1, 1, 10, 1392, 10] de proba [1.0391651325395436e-21, 9.53364228110186e-22, 5.100789759288443e-22, 5.05568256651016e-22, 5.025253992585251e-22, 3.9404869441947687e-22, 3.525767998843937e-22, 3.3980528066838484e-22, 3.2578231251233337e-22, 3.1250039397975927e-22]\n",
            "top indices :  [11, 11, 11, 11, 11, 11, 11, 11, 1, 10] de proba [1.0391288828032269e-21, 9.488521961678116e-22, 5.070519714851047e-22, 5.025068704935833e-22, 3.9403604740144436e-22, 3.525652383389668e-22, 3.382793838639722e-22, 3.109557412184641e-22, 1.2974305693571148e-22, 1.2450382145646803e-22]\n",
            "top indices :  [61, 61, 61, 61, 11, 11, 12, 141, 33, 12] de proba [3.9013256169401906e-22, 1.9128498653835934e-22, 1.52429762558556e-22, 1.3438898066180735e-22, 1.2973770530333046e-22, 1.2402125315263899e-22, 1.0624888591205722e-22, 7.137739057095826e-23, 5.739772141227256e-23, 5.668250856116298e-23]\n",
            "top indices :  [2, 61, 2, 20, 2, 2, 299, 20, 20, 12] de proba [6.95501930769619e-23, 4.9677426878244013e-23, 3.4193740761212895e-23, 3.1760212153689184e-23, 2.3686533177670595e-23, 2.2536882004281322e-23, 1.8320934803185218e-23, 1.6556047854370458e-23, 1.610735481553342e-23, 1.4164669662734515e-23]\n",
            "top indices :  [20, 334, 2, 237, 82, 20, 1235, 1392, 20, 20] de proba [9.238736602886828e-24, 8.868924921406459e-24, 6.3899243991535454e-24, 5.622365499386669e-24, 5.5493635223566116e-24, 4.6572770122438095e-24, 4.025341445885245e-24, 3.676113906435261e-24, 3.495458053821955e-24, 3.115317224863849e-24]\n",
            "top indices :  [334, 303, 641, 20, 1235, 334, 57, 1402, 40, 796] de proba [3.329282531984886e-24, 9.380612250614695e-25, 9.198004756121872e-25, 7.796352755420652e-25, 7.358343161215409e-25, 7.192975728768125e-25, 6.969482559633829e-25, 5.906601944299115e-25, 5.795315364247324e-25, 5.631280120653732e-25]\n",
            "top indices :  [669, 238, 298, 139, 669, 2144, 480, 1969, 40, 133] de proba [9.675481554453389e-25, 8.284421983557024e-25, 3.04512068373179e-25, 2.7241100086082695e-25, 2.2651748928159072e-25, 1.756859426287522e-25, 1.6669121500195414e-25, 1.233656675363419e-25, 1.129993942922523e-25, 1.0415612795925668e-25]\n",
            "top indices :  [428, 115, 104, 115, 1402, 492, 428, 40, 41, 89] de proba [8.581500097930336e-26, 6.196787139994026e-26, 5.993641282055225e-26, 5.567052421605318e-26, 5.182806902838315e-26, 5.01234700346928e-26, 4.5708418926372926e-26, 4.0783942399579115e-26, 4.024598240304914e-26, 3.987592960130271e-26]\n",
            "top indices :  [41, 20, 20, 297, 297, 89, 41, 89, 926, 1] de proba [3.0787866787167776e-26, 2.2875064973368243e-26, 1.943537104087615e-26, 1.932485501769139e-26, 1.7543029314719028e-26, 1.7191339099434364e-26, 1.670205582669081e-26, 9.37288243063454e-27, 7.011354125517554e-27, 5.929133645237534e-27]\n",
            "top indices :  [106, 90, 20, 41, 41, 408, 106, 41, 90, 41] de proba [3.255069665791266e-27, 3.2538101076076364e-27, 3.1163961616335738e-27, 2.340778143303163e-27, 2.081980344061156e-27, 2.0423406613527835e-27, 1.9557500806811556e-27, 1.8994980966444766e-27, 1.864858898443711e-27, 1.8476158550586177e-27]\n",
            "top indices :  [3490, 568, 568, 492, 3490, 57, 288, 1181, 1057, 1057] de proba [3.9567051075344823e-28, 3.740190618739011e-28, 2.8823840696626097e-28, 2.179982733728759e-28, 2.177720729009076e-28, 1.9782256831321547e-28, 1.9107670979350751e-28, 1.9101930504410262e-28, 1.4067176480855303e-28, 1.383743711261421e-28]\n",
            "top indices :  [857, 857, 195, 20, 568, 106, 20, 2453, 2453, 2331] de proba [5.360383036314662e-29, 4.434657725155094e-29, 3.1175810418836094e-29, 2.642637689801103e-29, 2.483482901705418e-29, 2.2823264403249089e-29, 2.281694193635353e-29, 2.1698459625783412e-29, 2.0989720415514447e-29, 2.0578626154986684e-29]\n",
            "top indices :  [10, 10, 1, 10, 1, 10, 1, 10, 212, 1] de proba [2.796960349758975e-29, 2.3199476762291906e-29, 1.1110312938661316e-29, 1.0087074634688607e-29, 9.89433644318767e-30, 9.827627797055342e-30, 6.924944425778891e-30, 6.653203986106082e-30, 5.745097924672119e-30, 5.247078395968846e-30]\n",
            "top indices :  [11, 11, 11, 11, 11, 11, 11, 11, 11, 11] de proba [2.789015587811824e-29, 2.3138895733111545e-29, 1.1110148933689489e-29, 1.0047508811393602e-29, 9.894157391888153e-30, 9.788159774890325e-30, 6.924875212671514e-30, 6.622721630837846e-30, 5.744700701621089e-30, 5.246894454612829e-30]\n",
            "top indices :  [12, 61, 61, 12, 61, 141, 61, 141, 61, 33] de proba [3.182296801913328e-30, 2.8020012456934935e-30, 2.6469334163567477e-30, 2.5961390829435918e-30, 2.1625975822925267e-30, 2.0680088432660396e-30, 1.9159815005973567e-30, 1.7765797195728897e-30, 1.1932875737118143e-30, 1.0784056644500196e-30]\n",
            "top indices :  [20, 20, 82, 2, 2, 82, 2, 2, 288, 237] de proba [5.386528889479211e-31, 4.444182558396756e-31, 3.7288448751586596e-31, 3.637529417701472e-31, 3.5892443415493556e-31, 3.040262383740759e-31, 2.9847096962152486e-31, 2.8944897994930275e-31, 2.7287502682022286e-31, 2.621716570483586e-31]\n",
            "top indices :  [334, 20, 796, 334, 20, 2, 20, 20, 796, 20] de proba [1.3959385680139137e-31, 6.209771076651039e-32, 5.801240357713437e-32, 5.340665801887528e-32, 5.060795878383302e-32, 5.054841999496388e-32, 5.050034227601524e-32, 4.8637357115378665e-32, 4.8202938484352903e-32, 4.735421099190807e-32]\n",
            "top indices :  [669, 238, 298, 20, 139, 238, 641, 238, 40, 794] de proba [3.816153072373894e-32, 3.1590226367790523e-32, 1.6906595989843522e-32, 1.5155390056394572e-32, 1.413917078200489e-32, 1.0356101557324507e-32, 8.697506211621122e-33, 8.59437201069982e-33, 8.459386320975051e-33, 8.422494900142432e-33]\n",
            "Ce grand jour où l’ hymen étouffant la vengeance <eos> Entre le Parthe et nous remet l’ intelligence , <eos> Affranchit , <eos> Et je n’ ai rien à vous , qu’ il faut que je vous aime . <eos> Je vous aime , et j’ ai vu ce que je vous dois dire , <eos> Et je n’ ai pas besoin de me faire justice . <eos> Je n’ ai pas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsbqFQLTH5iV",
        "outputId": "4db7f3c9-d3c5-48f1-db64-c8a85f10a3f5"
      },
      "source": [
        "a = [[1],[2]]\n",
        "b = []\n",
        "b.append(a[1])\n",
        "b.append(a[1])\n",
        "print(b)\n",
        "print(a)\n",
        "a = b\n"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2], [2]]\n",
            "[[1], [2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it6lUAwIXOcO"
      },
      "source": [
        "Je veux , et l’ en a vu . . Mais il faut à l’ entendre : . . ; <eos> \n",
        "\n",
        "Je vous dois voir à vous . Et que j’ ai su l’ attendre <eos> \n",
        "\n",
        "Ce que j’ avais pu voir , et l’ autre à l’ honneur ; <eos> \n",
        "\n",
        "Il n’ a rien dit qu’ en ce mot je n’ en dois point de rien"
      ]
    }
  ]
}