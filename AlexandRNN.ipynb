{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexandRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PJ7zEIWRw2"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5UvM7SZ9-hZ"
      },
      "source": [
        "with open('corpus.txt') as f:\n",
        "    mylist = f.read().splitlines()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-bWG8b1TJsR"
      },
      "source": [
        "for i in range(len(mylist)):\n",
        "  mylist[i] += ' <e>'"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnMv3uNuNQ92",
        "outputId": "40e8c085-c702-4e81-a1a9-991ae311a4e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = Tokenizer(filters='', lower=False)\n",
        "tokenizer.fit_on_texts(mylist)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)\n",
        "input_sequences = []\n",
        "incr = 0\n",
        "for line in mylist:\n",
        "  if incr % 2 == 0:\n",
        "    temp_seq = line\n",
        "  else :\n",
        "    token_list = tokenizer.texts_to_sequences([temp_seq + ' '+line])[0]\n",
        "    input_sequences.append(token_list)\n",
        "  incr+=1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEbNmdjFOou1",
        "outputId": "b9ae9dc0-c6a7-4d5c-cae5-e74137a696c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "input_sequences = np.asarray(input_sequences)\n",
        "X_train_list = []\n",
        "Y_train_list = []\n",
        "for j in range(len(input_sequences)):\n",
        "  for i in range(len(input_sequences[j])-1):\n",
        "    X_train_list.append(input_sequences[j][:i+1])\n",
        "    Y_train_list.append(input_sequences[j][i+1])\n",
        "maxlen = 0\n",
        "for seq in X_train_list:\n",
        "  if len(seq)>maxlen: maxlen = len(seq)\n",
        "X_train_list = sequence.pad_sequences(X_train_list, maxlen = maxlen)\n",
        "X_test_list = X_train_list[320003:]\n",
        "Y_test_list = Y_train_list[320003:]\n",
        "X_train_list = X_train_list[:320003]\n",
        "Y_train_list = Y_train_list[:320003]\n",
        "predictors, label = np.asarray(X_train_list), np.asarray(Y_train_list)\n",
        "X_test, Y_test = np.asarray(X_test_list), np.asarray(Y_test_list)\n",
        "print(predictors.shape)\n",
        "print(label.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320003, 28)\n",
            "(320003,)\n",
            "(51252, 28)\n",
            "(51252,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcAU2GUsGkXv",
        "outputId": "370344c8-e693-4a20-f092-d4f7277d4f08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential(\n",
        "        [\n",
        "         Embedding(total_words, 64, input_length=maxlen),\n",
        "         LSTM(256, return_sequences=True), Dropout(0.2),\n",
        "         LSTM(256),\n",
        "         Dense(total_words, activation='softmax')\n",
        "        ]\n",
        "    )\n",
        "print(model.summary())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 28, 64)            2190272   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 28, 256)           328704    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 28, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 34223)             8795311   \n",
            "=================================================================\n",
            "Total params: 11,839,599\n",
            "Trainable params: 11,839,599\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmB-X3PnIhB8",
        "outputId": "52e02a0b-455a-4964-9206-d9efbdf19b3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(predictors, label, batch_size=64, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "5001/5001 [==============================] - 160s 32ms/step - loss: 6.8037 - accuracy: 0.1370 - val_loss: 6.4772 - val_accuracy: 0.1663\n",
            "Epoch 2/6\n",
            "5001/5001 [==============================] - 160s 32ms/step - loss: 5.8170 - accuracy: 0.1689 - val_loss: 6.2964 - val_accuracy: 0.1741\n",
            "Epoch 3/6\n",
            "5001/5001 [==============================] - 160s 32ms/step - loss: 5.3147 - accuracy: 0.1818 - val_loss: 6.2563 - val_accuracy: 0.1768\n",
            "Epoch 4/6\n",
            "5001/5001 [==============================] - 161s 32ms/step - loss: 4.9662 - accuracy: 0.1932 - val_loss: 6.2948 - val_accuracy: 0.1853\n",
            "Epoch 5/6\n",
            "5001/5001 [==============================] - 160s 32ms/step - loss: 4.6962 - accuracy: 0.2018 - val_loss: 6.4092 - val_accuracy: 0.1837\n",
            "Epoch 6/6\n",
            "5001/5001 [==============================] - 160s 32ms/step - loss: 4.4676 - accuracy: 0.2092 - val_loss: 6.5294 - val_accuracy: 0.1862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa923106748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5fHP83kMyEK"
      },
      "source": [
        "pattern = predictors[946]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmbH7P5RNKEM"
      },
      "source": [
        "# --- note_l: is the list of notes (integer number) over time\n",
        "note_l = [k for k in pattern]\n",
        "# --- prediction_l: is the list of output-vectors (float numbers \\in [0,1]) of the network over time\n",
        "prediction_l = []\n",
        "# --- Generate T_y_generated notes\n",
        "for note_index in range(50):\n",
        "        # --- START CODE HERE (03)\n",
        "        prediction = model.predict(np.expand_dims(pattern, 0))\n",
        "        prediction_l.append(prediction)\n",
        "        index = np.argmax(prediction[0])\n",
        "        note_l.append(index)\n",
        "        pattern = np.concatenate((pattern[1:],[index]), axis=0)\n",
        "        # --- END CODE HERE"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUUb5YAWO5cR",
        "outputId": "352022c5-8e9e-4624-968f-d5689ea0d250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tokenizer.sequences_to_texts([note_l]))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['L’impie Achab détruit, et de votre propre <e> Que le ciel est pour moi que je vous ai passé. <e> Et je ne veux pas que je ne puis souffrir. <e> Et je ne veux pas que je ne puis souffrir. <e> Et je ne veux pas que je ne puis souffrir. <e> Et je']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyWlCGz3Ro21"
      },
      "source": [
        "**Nouvelle méthode, 10 epochs, pas de batchs**\n",
        "\n",
        "Oui, je ne puis savoir que vous ne régnez pas.\n",
        "\n",
        "Ah ! Si vous le croyez, et vous ne pouvez douter,\n",
        "\n",
        "De ce que je vous plaît, que je vous ai donné ?\n",
        "\n",
        "Mais je ne puis pas voir un autre que je meure.\n",
        "\n",
        "Ah ! Si vous le croyez, et vous ne pouvez pas ?\n",
        "\n",
        "Célébrer à mes yeux la fortune éternelle ?\n",
        "\n",
        "Mais je ne puis savoir que vous ne régnez pas.\n",
        "\n",
        "Ah ! Si vous le croyez, et vous ne pouvez rien croire,\n",
        "\n",
        "Et je ne puis plus voir un autre que je crains.\n",
        "\n",
        "Je ne vous pas pas dit que je vous ai donné ?\n",
        "\n",
        "**batch-size 64**\n",
        "\n",
        "Célébrer en mourant je ferais l’équité.\n",
        "\n",
        "Je ne sais que je hais que je suis élevé,\n",
        "\n",
        "Que vous ne l’attaquiez qu’afin de sa vengeance. \n",
        "\n",
        "Et je ne puis plus de vaincre et de la ville ; \n",
        "\n",
        "Mais je ne veux pas que je ne puis comprendre\n",
        "\n",
        "Que vous ne craindrons point de ce que je désire ?\n",
        "\n",
        "Oui, je ne puis souffrir que je suis outragé.\n",
        "\n",
        "Que je suis redevable à ce triste soupir.\n",
        "\n",
        "Et je ne veux pas que je vous veux régner.\n",
        "\n",
        "Je ne sais que vous ne me verra plus rien.\n",
        "\n",
        "Je ne puis que trop, je ne puis que je hais.\n",
        "\n",
        "Que je ne veux pas que je vous dois régner.\n",
        "\n",
        "**20 epochs**\n",
        "\n",
        "Oui, je ne puis souffrir que je vous ai parlé,\n",
        "\n",
        "Et je ne savais pas que je doive survivre.\n",
        "\n",
        "Non non, je voudrai, le soin de mon époux ?\n",
        "\n",
        "Et je ne savais pas que je vous le promets.\n",
        "\n",
        "Célébrer en ces lieux le pontife inspiré\n",
        "\n",
        "De la terre, d’Amurat cache son ombre,\n",
        "\n",
        "Et je fuirai les jours de Parjure, et de gloire,\n",
        "\n",
        "Et je ne voudrais pas de ce complot funeste,\n",
        "\n",
        "Je ne puis que mon coeur teint de ce côté."
      ]
    }
  ]
}