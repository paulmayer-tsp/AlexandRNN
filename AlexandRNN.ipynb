{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexandRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PJ7zEIWRw2"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5UvM7SZ9-hZ",
        "outputId": "bbdab91a-971a-4646-8bb7-a9357284b5f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open('moliere.txt') as f:\n",
        "    mylist = f.read().splitlines()\n",
        "print(mylist[:10])\n",
        "print(len(mylist))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Veux-tu que je te dise ? une atteinte secrète', 'Ne laisse point mon âme en une bonne assiette :', 'Oui, quoi qu’à mon amour tu puisses repartir,', 'Il craint d’être la dupe, à ne te point mentir :', 'Qu’en faveur d’un rival ta foi ne se corrompe,', 'Ou du moins, qu’avec moi, toi-même on ne te trompe.', 'Pour moi, me soupçonner de quelque mauvais tour,', 'Je dirai, n’en déplaise à monsieur votre amour,', 'Que c’est injustement blesser ma prud’homie', 'Et se connaître mal en physionomie.']\n",
            "15462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnMv3uNuNQ92",
        "outputId": "9399f2d6-f236-46be-9836-2aa5c1b164b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = Tokenizer(filters='', lower=False)\n",
        "tokenizer.fit_on_texts(mylist)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)\n",
        "input_sequences = []\n",
        "for line in mylist:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  input_sequences.append(token_list)\n",
        "print(input_sequences[0])\n",
        "print(tokenizer.sequences_to_texts([input_sequences[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18069\n",
            "[1166, 4, 6, 101, 2759, 10, 44, 1167, 1286]\n",
            "['Veux-tu que je te dise ? une atteinte secrète']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEbNmdjFOou1",
        "outputId": "f8f08505-608a-4a38-dd3c-a664aef8da4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "input_sequences = np.asarray(input_sequences) \n",
        "quatrains = []\n",
        "cur_quat = []\n",
        "incr = 0\n",
        "for line in input_sequences:\n",
        "  cur_quat.append(line)\n",
        "  if (incr > 0) & (incr%2 ==1):\n",
        "    quatrains.append(cur_quat)\n",
        "    cur_quat = [] \n",
        "  incr +=1\n",
        "print(quatrains[:4])\n",
        "X_train = quatrains[:][0]\n",
        "Y_train = quatrains[:][1]\n",
        "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
        "maxlength_x = 0\n",
        "for x in X_train:\n",
        "  if len(x) > maxlength_x:\n",
        "    maxlength_x = len(x)\n",
        "print(maxlength_x)\n",
        "maxlength_y = 0\n",
        "for x in Y_train:\n",
        "  if len(x) > maxlength_y:\n",
        "    maxlength_y = len(x)\n",
        "print(maxlength_y)\n",
        "'''sequence_length = 20\n",
        "predictors, label = [], []\n",
        "for t in range(len(input_sequences1D) - sequence_length):\n",
        "  predictors.append(input_sequences1D[t: t+sequence_length])\n",
        "  label.append(input_sequences1D[t+sequence_length])\n",
        "label = ku.to_categorical(label, num_classes=total_words)\n",
        "predictors, label = np.asarray(predictors), np.asarray(label)\n",
        "print(predictors.shape)\n",
        "print(label.shape)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1166, 4, 6, 101, 2759, 10, 44, 1167, 1286], [104, 473, 36, 21, 115, 15, 44, 251, 7440, 24]], [[87, 109, 128, 21, 158, 108, 7441, 4761], [37, 1982, 221, 11, 2760, 7, 12, 101, 36, 2761, 24]], [[816, 586, 56, 587, 344, 294, 12, 47, 7442], [398, 43, 345, 387, 96, 3480, 62, 12, 101, 4762]], [[67, 96, 17, 2311, 1, 81, 444, 1983], [18, 2312, 148, 2762, 7, 2313, 26, 525]]]\n",
            "10\n",
            "11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sequence_length = 20\\npredictors, label = [], []\\nfor t in range(len(input_sequences1D) - sequence_length):\\n  predictors.append(input_sequences1D[t: t+sequence_length])\\n  label.append(input_sequences1D[t+sequence_length])\\nlabel = ku.to_categorical(label, num_classes=total_words)\\npredictors, label = np.asarray(predictors), np.asarray(label)\\nprint(predictors.shape)\\nprint(label.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXwgio6hSVHk"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = maxlength_x)\n",
        "Y_train = sequence.pad_sequences(Y_train, maxlen = maxlength_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcAU2GUsGkXv",
        "outputId": "331deb34-78c3-4e7d-c3f5-f6affd75b30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential(\n",
        "        [\n",
        "         Embedding(total_words, 64, input_length=maxlength_x),\n",
        "         LSTM(256, return_sequences=True), Dropout(0.1),\n",
        "         LSTM(256),\n",
        "         Dense(total_words, activation='softmax')\n",
        "        ]\n",
        "    )\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 64)            1156416   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 20, 256)           328704    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 18069)             4643733   \n",
            "=================================================================\n",
            "Total params: 6,654,165\n",
            "Trainable params: 6,654,165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmB-X3PnIhB8",
        "outputId": "87b3cb0e-d9dd-453b-a9c0-73be78eeba24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(predictors, label, epochs=40, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 7.6710 - accuracy: 0.0289\n",
            "Epoch 2/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 6.9945 - accuracy: 0.0446\n",
            "Epoch 3/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 6.5531 - accuracy: 0.0635\n",
            "Epoch 4/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 6.1675 - accuracy: 0.0809\n",
            "Epoch 5/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 5.8097 - accuracy: 0.0953\n",
            "Epoch 6/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 5.4658 - accuracy: 0.1059\n",
            "Epoch 7/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 5.1542 - accuracy: 0.1138\n",
            "Epoch 8/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 4.8568 - accuracy: 0.1223\n",
            "Epoch 9/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 4.5746 - accuracy: 0.1348\n",
            "Epoch 10/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 4.5695 - accuracy: 0.1429\n",
            "Epoch 11/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 4.4161 - accuracy: 0.1590\n",
            "Epoch 12/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 4.0145 - accuracy: 0.1886\n",
            "Epoch 13/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 3.7608 - accuracy: 0.2176\n",
            "Epoch 14/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 3.5762 - accuracy: 0.2442\n",
            "Epoch 15/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 3.4128 - accuracy: 0.2686\n",
            "Epoch 16/40\n",
            "2090/2090 [==============================] - 50s 24ms/step - loss: 3.2627 - accuracy: 0.2910\n",
            "Epoch 17/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 3.1252 - accuracy: 0.3139\n",
            "Epoch 18/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.9946 - accuracy: 0.3353\n",
            "Epoch 19/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 2.8731 - accuracy: 0.3537\n",
            "Epoch 20/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 2.7547 - accuracy: 0.3754\n",
            "Epoch 21/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 2.6484 - accuracy: 0.3954\n",
            "Epoch 22/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.5437 - accuracy: 0.4152\n",
            "Epoch 23/40\n",
            "2090/2090 [==============================] - 49s 24ms/step - loss: 2.4416 - accuracy: 0.4351\n",
            "Epoch 24/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.3480 - accuracy: 0.4523\n",
            "Epoch 25/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.2555 - accuracy: 0.4701\n",
            "Epoch 26/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.1706 - accuracy: 0.4866\n",
            "Epoch 27/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.0854 - accuracy: 0.5052\n",
            "Epoch 28/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 2.0032 - accuracy: 0.5214\n",
            "Epoch 29/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 1.9246 - accuracy: 0.5395\n",
            "Epoch 30/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.8489 - accuracy: 0.5541\n",
            "Epoch 31/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.7789 - accuracy: 0.5697\n",
            "Epoch 32/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.7096 - accuracy: 0.5843\n",
            "Epoch 33/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.6462 - accuracy: 0.5975\n",
            "Epoch 34/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.5808 - accuracy: 0.6133\n",
            "Epoch 35/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 1.5202 - accuracy: 0.6277\n",
            "Epoch 36/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.4635 - accuracy: 0.6388\n",
            "Epoch 37/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.4042 - accuracy: 0.6528\n",
            "Epoch 38/40\n",
            "2090/2090 [==============================] - 48s 23ms/step - loss: 1.3552 - accuracy: 0.6642\n",
            "Epoch 39/40\n",
            "2090/2090 [==============================] - 47s 22ms/step - loss: 1.3007 - accuracy: 0.6768\n",
            "Epoch 40/40\n",
            "2090/2090 [==============================] - 49s 23ms/step - loss: 1.2518 - accuracy: 0.6895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5459bd0a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5fHP83kMyEK",
        "outputId": "3e288f0d-d5b1-4e29-86e7-8e177516c46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pattern = predictors[0]\n",
        "print(pattern)\n",
        "print(pattern.shape)\n",
        "print(np.expand_dims(pattern, 0).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1166    4    6  101 2759   10   44 1167 1286  104  473   36   21  115\n",
            "   15   44  251 7440   24   87]\n",
            "(20,)\n",
            "(1, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmbH7P5RNKEM",
        "outputId": "6b641b62-eebd-4b9d-a0c3-b1c46c746c4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# --- note_l: is the list of notes (integer number) over time\n",
        "note_l = [k for k in pattern]\n",
        "# --- prediction_l: is the list of output-vectors (float numbers \\in [0,1]) of the network over time\n",
        "prediction_l = []\n",
        "# --- Generate T_y_generated notes\n",
        "for note_index in range(62):\n",
        "        # --- START CODE HERE (03)\n",
        "        prediction = model.predict(np.expand_dims(pattern, 0))\n",
        "        prediction_l.append(prediction)\n",
        "        index = np.argmax(prediction[0])\n",
        "        print(index)\n",
        "        note_l.append(index)\n",
        "        pattern = np.concatenate((pattern[1:],[index]), axis=0)\n",
        "        # --- END CODE HERE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109\n",
            "128\n",
            "35\n",
            "17881\n",
            "17882\n",
            "53\n",
            "17883\n",
            "85\n",
            "700\n",
            "22\n",
            "922\n",
            "21\n",
            "1218\n",
            "1\n",
            "8290\n",
            "5137\n",
            "170\n",
            "33\n",
            "77\n",
            "36\n",
            "1\n",
            "257\n",
            "7\n",
            "205\n",
            "113\n",
            "2097\n",
            "2752\n",
            "98\n",
            "13\n",
            "640\n",
            "1248\n",
            "10\n",
            "875\n",
            "20\n",
            "1\n",
            "174\n",
            "406\n",
            "6\n",
            "72\n",
            "743\n",
            "1\n",
            "2\n",
            "10\n",
            "18\n",
            "12\n",
            "220\n",
            "25\n",
            "712\n",
            "4517\n",
            "2533\n",
            "62\n",
            "2\n",
            "410\n",
            "29\n",
            "26\n",
            "115\n",
            "15\n",
            "158\n",
            "17\n",
            "466\n",
            "896\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUUb5YAWO5cR",
        "outputId": "4a8e7b2f-a164-4c38-a685-444e998cf337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tokenizer.sequences_to_texts([note_l]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Veux-tu que je te dise ? une atteinte secrète Ne laisse point mon âme en une bonne assiette : Oui, quoi qu’à son Crédit nuise cette Aventure, Ce chagrin est céans mon frère de sable… Quand… quand il n’est point de part à toutes deux L’autre Nymphes, Monsieur, un peu, laissons ? Las ! de leurs vœux, je suis sûr de vous ? Je ne dis pas cela. Nul obstacle, on vous plaît, Que votre âme en amour me pourra apprendre ;']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XptMkP7s9RrW"
      },
      "source": [
        "# Ponctuation et casse : entrainement par séquences de 20 tokens\n",
        "\n",
        "**2 couches LSTM, 20 epochs**\n",
        "\n",
        "Veux-tu que je te dise ? une atteinte secrète \n",
        "\n",
        "Ne laisse point mon âme en une bonne assiette : \n",
        "\n",
        "Oui, Madame, cessez de la sorte expliqués… \n",
        "\n",
        "Je ne sais pas, Monsieur, de vous le figurer ; \n",
        "\n",
        "Et que de la négliger, il faut bien vécu, \n",
        "\n",
        "Il est vrai que je vous ai rencontré la tête. \n",
        "\n",
        "Oui, oui, je vous commande avec beaucoup de colère. \n",
        "\n",
        "Oh… Non, je ne puis point séduire ? \n",
        "\n",
        "Je ne sais pas cela que je vous ai portée.\n",
        "\n",
        "**35 epochs**\n",
        "\n",
        "Oui, quoi qu’à mon cœur devrait rompre, de la répandre, \n",
        "\n",
        "Et goûtât-on cela, s’il vous plaît, que je meure. \n",
        "\n",
        "Comment ? Vous moquez-vous ? Monsieur, perdez cette matière, \n",
        "\n",
        "Je reviens de vous payer, Témoins de la fenêtre : \n",
        "\n",
        "Madame ; je suis toute ébaubie, et je vois… Franc abus. \n",
        "\n",
        "Pour le Siècle passé dans leurs productions, \n",
        "\n",
        "Vous merveilleux des plaisirs de la nature\n",
        "\n",
        "**40 epochs**\n",
        "\n",
        "Oui, quoi qu’à son Crédit nuise cette Aventure, \n",
        "\n",
        "Ce chagrin est céans mon frère de sable… \n",
        "\n",
        "Quand… quand il n’est point de part à toutes deux \n",
        "\n",
        "L’autre Nymphes, Monsieur, un peu, laissons ? \n",
        "\n",
        "Las ! de leurs vœux, je suis sûr de vous ? \n",
        "\n",
        "Je ne dis pas cela. Nul obstacle, on vous plaît, \n",
        "\n",
        "Que votre âme en amour me pourra apprendre ;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyWlCGz3Ro21"
      },
      "source": [
        "# Many-to-One\n",
        "\n",
        "**2 couches LSTM, 100 epochs**\n",
        "\n",
        "A peine les ont de leurs baisers de ces coeurs, \n",
        "\n",
        "De la seine et du plus m a mal affreux le bruit ;\n",
        "\n",
        "à chaque éternité le ciel le la ermite\n",
        "\n",
        "**2 couches LSTM, 200 epochs**\n",
        "\n",
        "Le navire glissant sur son coeur qui ne me\n",
        "\n",
        "Dit jamais bien,  beaux vie et les seins nous de\n",
        "\n",
        "Reine cette coulisse, où mon esprit n est un\n",
        "\n",
        "Cher métier comme une fleur, un pauvre qui est-il ?\n",
        "\n",
        "**3 couches LSTM, 100 epochs**\n",
        "\n",
        "Dans la maison et les soleils funèbres pour\n",
        "\n",
        "pleins en amante dans le coeur sans nuages et\n",
        "\n",
        "non où jette en volant ton cou s verse d belle je\n",
        "\n",
        "comme qu elle remue avec la main et regard le\n",
        "\n",
        "**3 couches LSTM, 200 epochs**\n",
        "\n",
        "le navire glissant sur les gouffres amers \n",
        "\n",
        "a peine les ont ils déposés sur les planches \n",
        "\n",
        "que ces rois de l azur maladroits et honteux \n",
        "\n",
        "laissent piteusement leurs grandes ailes blanches\n",
        "\n",
        "**Plus de dimensions d'embedding :**\n",
        "\n",
        "Belle comme des chairs de fleurs qui de l enfer\n",
        "\n",
        "Je suis dis dans des chansons les coeurs et des yeux\n",
        "\n",
        "Et ô ma chère sans doute et troubler en ton coeur\n",
        "\n",
        "La retrouve des ennuis l erèbe les eût pris\n",
        "\n"
      ]
    }
  ]
}